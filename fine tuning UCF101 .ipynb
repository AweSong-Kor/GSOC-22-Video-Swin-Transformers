{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices(device_type = 'GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'ucf101'\n",
    "ucf101 = tfds.builder(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## uncomment the following two lines if if not donwloaded already\n",
    "\n",
    "# config = tfds.download.DownloadConfig(verify_ssl=False) \n",
    "# ucf101.download_and_prepare(download_config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = ucf101.info.features['label'].num_classes\n",
    "num_examples = {\n",
    "    name: split.num_examples\n",
    "    for name, split in ucf101.info.splits.items()\n",
    "}\n",
    "\n",
    "print('Number of classes:', num_classes)\n",
    "print('Number of examples for train:', num_examples['train'])\n",
    "print('Number of examples for test:', num_examples['test'])\n",
    "print()\n",
    "\n",
    "# ucf101.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the training and evaluation datasets.\n",
    "batch_size = 2\n",
    "num_frames = 32\n",
    "resolution = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_features(features):\n",
    "  # print(\"features\", features)\n",
    "  video = features['video']\n",
    "\n",
    "\n",
    "  total_frames = video.shape[1]\n",
    "  if total_frames == None:\n",
    "    total_frames = num_frames\n",
    "  frames = num_frames\n",
    "\n",
    "  start_idx = random.randint(0, total_frames - frames )\n",
    "  video = video[:,start_idx:start_idx+32]\n",
    "\n",
    "  if video.shape[1] is None or video.shape[1]  < 32:\n",
    "    video = tf.random.normal((batch_size, 32, 256, 256, 3))\n",
    "    \n",
    "  video = tf.reshape(video, [-1, video.shape[2], video.shape[3], 3])\n",
    "\n",
    "  \n",
    "  video = tf.image.resize(video, (resolution, resolution))\n",
    "  video = tf.reshape(video, [-1, num_frames, resolution, resolution, 3])\n",
    "  video = tf.transpose(video, perm=(0,4,1,2,3))\n",
    "  video = tf.image.per_image_standardization(video)\n",
    "\n",
    "  \n",
    "  label = tf.one_hot(features['label'], num_classes)\n",
    "  return (video, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ucf101.as_dataset(\n",
    "    split='train',\n",
    "    batch_size=batch_size,\n",
    "    shuffle_files=True)\n",
    "train_dataset = train_dataset.map(\n",
    "    format_features,\n",
    "    num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_dataset = train_dataset.repeat()\n",
    "train_dataset = train_dataset.prefetch(2)\n",
    "\n",
    "test_dataset = ucf101.as_dataset(\n",
    "    split='test',\n",
    "    batch_size=batch_size)\n",
    "test_dataset = test_dataset.map(\n",
    "    format_features,\n",
    "    num_parallel_calls=tf.data.AUTOTUNE,\n",
    "    deterministic=True)\n",
    "test_dataset = test_dataset.prefetch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "dist_train_dataset = strategy.experimental_distribute_dataset(train_dataset)\n",
    "dist_test_dataset = strategy.experimental_distribute_dataset(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/azureuser/cloudfiles/code/Users/Mohammad.Shoaib/GSOC-22-Video-Swin-Transformers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## uncooment the following command if not converted the model already\n",
    "\n",
    "# ! python \"/home/azureuser/cloudfiles/code/Users/Mohammad.Shoaib/GSOC-22-Video-Swin-Transformers/convert.py\" -m \"swin_tiny_patch244_window877_kinetics400_1k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from VideoSwinTransformer import model_configs, SwinTransformer3D, I3DHead_tf\n",
    "\n",
    "cfg_method = model_configs.MODEL_MAP[\"swin_tiny_patch244_window877_kinetics400_1k\"]\n",
    "cfg = cfg_method()\n",
    "\n",
    "name = cfg[\"name\"]\n",
    "link = cfg['link']\n",
    "del cfg[\"name\"]\n",
    "del cfg['link']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(num_classes,cfg,backbone, shape_of_input=(10,3,32,224,224)):\n",
    "    inputs = tf.keras.Input(shape_of_input[1:])\n",
    "    \n",
    "    x = backbone(inputs, training= True)\n",
    "    outputs = I3DHead_tf(num_classes, 768, training=True)(x)\n",
    "    return tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_of_input = (batch_size, 3, num_frames, resolution,resolution)\n",
    "\n",
    "num_epochs = 3\n",
    "sample_count = num_examples['train']\n",
    "warmup_epoch = 2\n",
    "total_steps = int(num_epochs * sample_count / batch_size)\n",
    "\n",
    "# Compute the number of warmup batches.\n",
    "warmup_steps = int(warmup_epoch * sample_count / batch_size)\n",
    "\n",
    "train_steps = num_examples['train'] // batch_size\n",
    "total_train_steps = train_steps * num_epochs\n",
    "test_steps = num_examples['test'] // batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Manually implemented cosine decay with warmup for using with AdamW optimizer\n",
    "\n",
    "def cosine_decay_with_warmup(global_step,\n",
    "                             learning_rate_base,\n",
    "                             total_steps,\n",
    "                             warmup_learning_rate=0.0,\n",
    "                             warmup_steps=0,\n",
    "                             hold_base_rate_steps=0):\n",
    "\n",
    "    if total_steps < warmup_steps:\n",
    "        raise ValueError('total_steps must be larger or equal to '\n",
    "                         'warmup_steps.')\n",
    "\n",
    "    if not isinstance(global_step, int):\n",
    "      global_step = 1\n",
    "     \n",
    "    learning_rate = 0.5 * learning_rate_base * (1 + np.cos(\n",
    "        np.pi *\n",
    "        (global_step - warmup_steps - hold_base_rate_steps\n",
    "        ) / float(total_steps - warmup_steps - hold_base_rate_steps)))\n",
    "\n",
    "\n",
    "    if hold_base_rate_steps > 0:\n",
    "        learning_rate = np.where(global_step > warmup_steps + hold_base_rate_steps,\n",
    "                                 learning_rate, learning_rate_base)\n",
    "    if warmup_steps > 0:\n",
    "        if learning_rate_base < warmup_learning_rate:\n",
    "            raise ValueError('learning_rate_base must be larger or equal to '\n",
    "                             'warmup_learning_rate.')\n",
    "        slope = (learning_rate_base - warmup_learning_rate) / warmup_steps\n",
    "        warmup_rate = slope * global_step + warmup_learning_rate\n",
    "        learning_rate = np.where(global_step < warmup_steps, warmup_rate,\n",
    "                                 learning_rate)\n",
    "        \n",
    "    return np.where(global_step > total_steps, 0.0, learning_rate)\n",
    "\n",
    "\n",
    "class CosineAnnealingSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, learning_rate_base,total_steps,warmup_learning_rate=0.0,warmup_steps=0,hold_base_rate_steps=0):\n",
    "    super().__init__()\n",
    "\n",
    "    \n",
    "    self.learning_rate_base = learning_rate_base\n",
    "    self.total_steps = total_steps\n",
    "    self.warmup_learning_rate = warmup_learning_rate\n",
    "    self.warmup_steps = warmup_steps\n",
    "    self.hold_base_rate_steps = hold_base_rate_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    lr = cosine_decay_with_warmup(global_step=step,\n",
    "                                      learning_rate_base=self.learning_rate_base,\n",
    "                                      total_steps=self.total_steps,\n",
    "                                      warmup_learning_rate=self.warmup_learning_rate,\n",
    "                                      warmup_steps=self.warmup_steps,\n",
    "                                      hold_base_rate_steps=self.hold_base_rate_steps)\n",
    "    print(\"lr =\", lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "\n",
    "    backbone = tf.keras.models.load_model(\"/home/azureuser/cloudfiles/code/Users/Datasets/swin_tiny_patch244_window877_kinetics400_1k_tf\")\n",
    "    # backbone = SwinTransformer3D(**cfg, shape_of_input=shape_of_input)\n",
    "    model = get_model(num_classes, cfg, backbone,shape_of_input=shape_of_input)\n",
    "\n",
    "    ## backbone model has a multiplier of 0.1 for learning rate. To implement that MultiOptimizer is being used\n",
    "    lr_backbone = CosineAnnealingSchedule(learning_rate_base=.001,\n",
    "                                        total_steps=total_steps,\n",
    "                                        warmup_learning_rate=0.0,\n",
    "                                        warmup_steps=warmup_steps,\n",
    "                                        hold_base_rate_steps=0)\n",
    "    lr_classifier = CosineAnnealingSchedule(learning_rate_base=.01,\n",
    "                                            total_steps=total_steps,\n",
    "                                            warmup_learning_rate=0.0,\n",
    "                                            warmup_steps=warmup_steps,\n",
    "                                            hold_base_rate_steps=0)\n",
    "\n",
    "    optimizer_backbone = tfa.optimizers.AdamW(weight_decay= 0.05,learning_rate=lr_backbone, beta_1= 0.9, beta_2=0.999, epsilon=1e-8)\n",
    "    optimizer_classifier = tfa.optimizers.AdamW(weight_decay= 0.05,learning_rate=lr_classifier, beta_1= 0.9, beta_2=0.999, epsilon=1e-8)\n",
    "\n",
    "    optimizers_and_layers = [(optimizer_backbone, model.layers[1]), (optimizer_classifier, model.layers[2])]\n",
    "    optimizer = tfa.optimizers.MultiOptimizer(optimizers_and_layers)\n",
    "\n",
    "    loss_obj = tf.keras.losses.CategoricalCrossentropy(from_logits=True,label_smoothing=0.1,\n",
    "                                        reduction=tf.keras.losses.Reduction.SUM)\n",
    "\n",
    "    metrics=[\"top_k_categorical_accuracy\"] \n",
    "\n",
    "model.compile(loss=loss_obj, optimizer=optimizer, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.fit(\n",
    "    dist_train_dataset,\n",
    "    validation_data=dist_test_dataset,\n",
    "    epochs=num_epochs,\n",
    "    steps_per_epoch=train_steps,\n",
    "    validation_steps=test_steps,\n",
    "    callbacks=[],\n",
    "    validation_freq=1,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matching the shape of label and prediction\n",
    "\n",
    "for v in dist_train_dataset:\n",
    "    video = v[0]\n",
    "    label = v[1]\n",
    "    break\n",
    "\n",
    "\n",
    "pred = model.predict(video)\n",
    "\n",
    "pred.shape, label.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('azureml_py38_PT_TF')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9169f1d4e16acc976bbb73e323b0dbdf23f1c55e833fb2befffc4fb50ac2de2f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
