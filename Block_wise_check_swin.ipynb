{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "B4wc5gJHewNE"
      },
      "outputs": [],
      "source": [
        "# !pip install timm einops mmcv &> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqMzolJ8e12s",
        "outputId": "0ad2cd80-8404-4c66-82e7-8e08c30c23e6"
      },
      "outputs": [],
      "source": [
        "# import sys\n",
        "\n",
        "# ! git clone https://github.com/shoaib6174/GSOC-22-Video-Swin-Transformers\n",
        "# sys.path.append('/content/GSOC-22-Video-Swin-Transformers')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBN5ft9De4oC",
        "outputId": "0893b6e7-4d86-4b00-dd70-0912af94af54"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch.autograd.grad_mode.set_grad_enabled at 0x1de4adb7e20>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from VideoSwinTransformer import *\n",
        "import os\n",
        "from collections import OrderedDict\n",
        "\n",
        "torch.set_grad_enabled(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54cmUQqdJ2Fn"
      },
      "source": [
        "# Helper function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "b8ZssQwKCtJm"
      },
      "outputs": [],
      "source": [
        "def get_x(shape=(2,3,8,224,224)):\n",
        "    x_pt = torch.rand(shape)\n",
        "    x_np = x_pt.numpy()\n",
        "    x_tf = tf.convert_to_tensor(x_np)\n",
        "\n",
        "    return x_tf, x_pt\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qk1uNYVClUX",
        "outputId": "6d088e46-a7a0-4e5b-8e4c-c63d5b2264b7"
      },
      "outputs": [],
      "source": [
        "cfg_method = model_configs.MODEL_MAP[\"swin_tiny_patch244_window877_kinetics400_1k\"]\n",
        "cfg = cfg_method()\n",
        "\n",
        "name = cfg[\"name\"]\n",
        "link = cfg['link']\n",
        "del cfg[\"name\"]\n",
        "del cfg['link']\n",
        "del cfg[\"drop_path_rate\"]\n",
        "# download_weight_command = f\"wget {link} -O {name}.pth\"\n",
        "# os.system(download_weight_command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubVGrMTYCScw",
        "outputId": "50582595-878a-4482-cdc4-4985f41633df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BasicLayer() 96 2 3 (8, 7, 7) 4.0 True None 0.0 0.0 [0.0, 0.0181818176060915] <class 'torch.nn.modules.normalization.LayerNorm'> <class 'VideoSwinTransformer.SwinTransformer3D_pt.PatchMerging'> False\n",
            "BasicLayer() 192 2 6 (8, 7, 7) 4.0 True None 0.0 0.0 [0.036363635212183, 0.05454545468091965] <class 'torch.nn.modules.normalization.LayerNorm'> <class 'VideoSwinTransformer.SwinTransformer3D_pt.PatchMerging'> False\n",
            "BasicLayer() 384 6 12 (8, 7, 7) 4.0 True None 0.0 0.0 [0.072727270424366, 0.09090908616781235, 0.10909091681241989, 0.12727272510528564, 0.1454545557498932, 0.16363637149333954] <class 'torch.nn.modules.normalization.LayerNorm'> <class 'VideoSwinTransformer.SwinTransformer3D_pt.PatchMerging'> False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Python\\Python396\\lib\\site-packages\\torch\\functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:2895.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BasicLayer() 768 2 24 (8, 7, 7) 4.0 True None 0.0 0.0 [0.1818181872367859, 0.20000000298023224] <class 'torch.nn.modules.normalization.LayerNorm'> None False\n",
            "basic torch.Size([2, 96, 4, 56, 56])\n",
            "basic torch.Size([2, 192, 4, 28, 28])\n",
            "basic torch.Size([2, 384, 4, 14, 14])\n",
            "basic torch.Size([2, 768, 4, 7, 7])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load pt model with weights\n",
        "pt_model = SwinTransformer3D_pt(**cfg)\n",
        "x_tf, x_pt = get_x()\n",
        "\n",
        "_= pt_model(x_pt)\n",
        "\n",
        "checkpoint = torch.load(f'swin_tiny_patch244_window877_kinetics400_1k.pth')\n",
        "new_state_dict = OrderedDict()\n",
        "for k, v in checkpoint['state_dict'].items():\n",
        "    if 'backbone' in k:\n",
        "        name = k[9:]\n",
        "        new_state_dict[name] = v \n",
        "\n",
        "pt_model.load_state_dict(new_state_dict) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "cellView": "form",
        "id": "FYeulSuTJ67s"
      },
      "outputs": [],
      "source": [
        "#@title Convert functions\n",
        "def conv_transpose(w):\n",
        "    return w.transpose(2,3,4,1, 0)\n",
        "    \n",
        "def modify_tf_block( tf_component, pt_weight,  pt_bias = None, is_attn=False, **kwargs):\n",
        "    in_shape = pt_weight.shape\n",
        "    if isinstance(tf_component, tf.keras.layers.Conv3D) :\n",
        "      pt_weight = conv_transpose(pt_weight)\n",
        "    if isinstance(tf_component, tf.keras.layers.Dense) and not is_attn:\n",
        "      pt_weight =pt_weight.transpose()\n",
        "    if isinstance(tf_component, (tf.keras.layers.Dense, tf.keras.layers.Conv3D)):\n",
        "        tf_component.kernel.assign(tf.Variable(pt_weight))\n",
        "        if pt_bias is not None:\n",
        "            tf_component.bias.assign(tf.Variable(pt_bias))\n",
        "    elif isinstance(tf_component, tf.keras.layers.LayerNormalization):\n",
        "\n",
        "        tf_component.gamma.assign(tf.Variable(pt_weight))\n",
        "\n",
        "        tf_component.beta.assign(tf.Variable(pt_bias))\n",
        "\n",
        "    elif isinstance(tf_component, (tf.Variable)):\n",
        "        tf_component.assign(tf.Variable(pt_weight))\n",
        "\n",
        "    else:\n",
        "        return tf.convert_to_tensor(pt_weight)\n",
        "        \n",
        "    return tf_component\n",
        "\n",
        "def modify_swin_blocks(np_state_dict, pt_weights_prefix, tf_block):\n",
        "\n",
        "  for layer in tf_block:\n",
        "    if isinstance(layer, PatchMerging):\n",
        "      patch_merging_idx = f\"downsample\"\n",
        "\n",
        "      layer.reduction = modify_tf_block( layer.reduction,\n",
        "                          np_state_dict[f\"{patch_merging_idx}.reduction.weight\"])\n",
        "      layer.norm = modify_tf_block( layer.norm,\n",
        "                        np_state_dict[f\"{patch_merging_idx}.norm.weight\"],\n",
        "                        np_state_dict[f\"{patch_merging_idx}.norm.bias\"]\n",
        "                        )\n",
        "      \n",
        "  # Swin Layers\n",
        "  common_prefix = f\"blocks\"\n",
        "  block_idx = 0\n",
        "\n",
        "  for outer_layer in tf_block:\n",
        "\n",
        "      layernorm_idx = 1\n",
        "      mlp_layer_idx = 1\n",
        "\n",
        "      if isinstance(outer_layer, SwinTransformerBlock3D):\n",
        "          for inner_layer in outer_layer.layers:\n",
        "        \n",
        "              # Layer norm.\n",
        "              if isinstance(inner_layer, tf.keras.layers.LayerNormalization):\n",
        "                  layer_norm_prefix = (\n",
        "                      f\"norm{layernorm_idx}\"\n",
        "                  )\n",
        "                  inner_layer.gamma.assign(\n",
        "                      tf.Variable(\n",
        "                          np_state_dict[f\"{layer_norm_prefix}.weight\"]\n",
        "                      )\n",
        "                  )\n",
        "\n",
        "\n",
        "\n",
        "                  inner_layer.beta.assign(\n",
        "                      tf.Variable(np_state_dict[f\"{layer_norm_prefix}.bias\"])\n",
        "                  )\n",
        "\n",
        "                  layernorm_idx += 1\n",
        "\n",
        "              # Window attention.\n",
        "              elif isinstance(inner_layer, WindowAttention3D):\n",
        "                  attn_prefix = f\"attn\"\n",
        "\n",
        "                  # Relative position.\n",
        "                  inner_layer.relative_position_bias_table = (\n",
        "                      modify_tf_block(\n",
        "                          inner_layer.relative_position_bias_table,\n",
        "                          np_state_dict[\n",
        "                              f\"{attn_prefix}.relative_position_bias_table\"\n",
        "                          ] \n",
        "                      )\n",
        "                  )\n",
        "                  inner_layer.relative_position_index = (\n",
        "                      modify_tf_block(\n",
        "                          inner_layer.relative_position_index,\n",
        "                          np_state_dict[\n",
        "                              f\"{attn_prefix}.relative_position_index\"\n",
        "                          ]\n",
        "                      )\n",
        "                  )\n",
        "\n",
        "                  # QKV.\n",
        "                  inner_layer.qkv = modify_tf_block(\n",
        "                      inner_layer.qkv,\n",
        "                      np_state_dict[f\"{attn_prefix}.qkv.weight\"],\n",
        "                      np_state_dict[f\"{attn_prefix}.qkv.bias\"]\n",
        "                  )\n",
        "\n",
        "                  # Projection.\n",
        "                  inner_layer.proj = modify_tf_block(\n",
        "                      inner_layer.proj,\n",
        "                      np_state_dict[f\"{attn_prefix}.proj.weight\"],\n",
        "                      np_state_dict[f\"{attn_prefix}.proj.bias\"]\n",
        "                  )\n",
        "\n",
        "              # MLP.\n",
        "              elif isinstance(inner_layer, tf.keras.Model):\n",
        "                  mlp_prefix = f\"mlp\"\n",
        "                  for mlp_layer in inner_layer.layers:\n",
        "                      if isinstance(mlp_layer, tf.keras.layers.Dense):\n",
        "                          mlp_layer = modify_tf_block(\n",
        "                              mlp_layer,\n",
        "                              np_state_dict[\n",
        "                                  f\"{mlp_prefix}.fc{mlp_layer_idx}.weight\"\n",
        "                              ],\n",
        "                              np_state_dict[\n",
        "                                  f\"{mlp_prefix}.fc{mlp_layer_idx}.bias\"\n",
        "                              ]\n",
        "                          )\n",
        "                          mlp_layer_idx += 1\n",
        "\n",
        "          block_idx += 1\n",
        "  return tf_block\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "cellView": "form",
        "id": "ifb8-qAwlJMu"
      },
      "outputs": [],
      "source": [
        "#@title modify_swin_block3D\n",
        "\n",
        "def modify_swin_block3D(np_state_dict, pt_weights_prefix, tf_block):\n",
        "    layernorm_idx = 1\n",
        "    mlp_layer_idx = 1\n",
        "\n",
        "\n",
        "    if isinstance(tf_block, SwinTransformerBlock3D):\n",
        "        print(tf_block)\n",
        "        for inner_layer in tf_block.layers:\n",
        "            \n",
        "            # Layer norm.\n",
        "            if isinstance(inner_layer, tf.keras.layers.LayerNormalization):\n",
        "                layer_norm_prefix = (\n",
        "                    f\"norm{layernorm_idx}\"\n",
        "                )\n",
        "                inner_layer.gamma.assign(\n",
        "                    tf.Variable(\n",
        "                        np_state_dict[f\"{layer_norm_prefix}.weight\"]\n",
        "                    )\n",
        "                )\n",
        "\n",
        "\n",
        "\n",
        "                inner_layer.beta.assign(\n",
        "                    tf.Variable(np_state_dict[f\"{layer_norm_prefix}.bias\"])\n",
        "                )\n",
        "\n",
        "                layernorm_idx += 1\n",
        "\n",
        "            # Window attention.\n",
        "            elif isinstance(inner_layer, WindowAttention3D):\n",
        "                attn_prefix = f\"attn\"\n",
        "\n",
        "                # Relative position.\n",
        "                inner_layer.relative_position_bias_table = (\n",
        "                    modify_tf_block(\n",
        "                        inner_layer.relative_position_bias_table,\n",
        "                        np_state_dict[\n",
        "                            f\"{attn_prefix}.relative_position_bias_table\"\n",
        "                        ] \n",
        "                    )\n",
        "                )\n",
        "                inner_layer.relative_position_index = (\n",
        "                    modify_tf_block(\n",
        "                        inner_layer.relative_position_index,\n",
        "                        np_state_dict[\n",
        "                            f\"{attn_prefix}.relative_position_index\"\n",
        "                        ]\n",
        "                    )\n",
        "                )\n",
        "\n",
        "                # QKV.\n",
        "                inner_layer.qkv = modify_tf_block(\n",
        "                    inner_layer.qkv,\n",
        "                    np_state_dict[f\"{attn_prefix}.qkv.weight\"],\n",
        "                    np_state_dict[f\"{attn_prefix}.qkv.bias\"]\n",
        "                )\n",
        "\n",
        "                # Projection.\n",
        "                inner_layer.proj = modify_tf_block(\n",
        "                    inner_layer.proj,\n",
        "                    np_state_dict[f\"{attn_prefix}.proj.weight\"],\n",
        "                    np_state_dict[f\"{attn_prefix}.proj.bias\"]\n",
        "                )\n",
        "\n",
        "            # MLP.\n",
        "            elif isinstance(inner_layer, tf.keras.Model):\n",
        "                mlp_prefix = f\"mlp\"\n",
        "                for mlp_layer in inner_layer.layers:\n",
        "                    if isinstance(mlp_layer, tf.keras.layers.Dense):\n",
        "                        mlp_layer = modify_tf_block(\n",
        "                            mlp_layer,\n",
        "                            np_state_dict[\n",
        "                                f\"{mlp_prefix}.fc{mlp_layer_idx}.weight\"\n",
        "                            ],\n",
        "                            np_state_dict[\n",
        "                                f\"{mlp_prefix}.fc{mlp_layer_idx}.bias\"\n",
        "                            ]\n",
        "                        )\n",
        "                        mlp_layer_idx += 1\n",
        "\n",
        "        \n",
        "    return tf_block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "katj8-Kw8v29"
      },
      "outputs": [],
      "source": [
        "def compute_mask(D, H, W, window_size, shift_size):\n",
        "\n",
        "    img_mask = np.zeros((1, D, H, W, 1)) \n",
        "\n",
        " \n",
        "    cnt = 0\n",
        "\n",
        "    for d in slice(-window_size[0]), slice(-window_size[0], -shift_size[0]), slice(-shift_size[0],None):\n",
        "        for h in slice(-window_size[1]), slice(-window_size[1], -shift_size[1]), slice(-shift_size[1],None):\n",
        "            for w in slice(-window_size[2]), slice(-window_size[2], -shift_size[2]), slice(-shift_size[2],None):\n",
        "                img_mask[:, d, h, w, :] = cnt\n",
        "                cnt = cnt + 1\n",
        "    img_mask = tf.convert_to_tensor(img_mask, dtype=\"float32\")\n",
        "\n",
        "    # print(\"basic compute\", img_mask.shape, window_size, shift_size, D, H, W)\n",
        "\n",
        "    mask_windows = window_partition(img_mask, window_size)  # nW, ws[0]*ws[1]*ws[2], 1\n",
        "\n",
        "    mask_windows = tf.squeeze(mask_windows, axis = -1)  # nW, ws[0]*ws[1]*ws[2] ??\n",
        "    attn_mask = tf.expand_dims(mask_windows, axis=1) - tf.expand_dims(mask_windows, axis=2)\n",
        "    \n",
        "\n",
        "    attn_mask = tf.cast(attn_mask, dtype=\"float64\")\n",
        "\n",
        "    attn_mask = tf.where(attn_mask != 0, -100.0, attn_mask)\n",
        "    attn_mask = tf.where(attn_mask == 0, 0.0 , attn_mask)\n",
        "\n",
        "    return attn_mask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "tiawVJzK_2X2"
      },
      "outputs": [],
      "source": [
        "#@title pt model\n",
        "\n",
        "\n",
        "'''\n",
        "Credit to the official implementation: https://github.com/SwinTransformer/Video-Swin-Transformer\n",
        "'''\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.checkpoint as checkpoint\n",
        "import numpy as np\n",
        "from timm.models.layers import  trunc_normal_\n",
        "from timm.models.layers import DropPath as DropPath_pt\n",
        "from functools import reduce, lru_cache\n",
        "from operator import mul\n",
        "from einops import rearrange\n",
        "\n",
        "import logging\n",
        "from mmcv.utils import get_logger\n",
        "from mmcv.runner import load_checkpoint\n",
        "\n",
        "\n",
        "def get_root_logger_pt(log_file=None, log_level=logging.INFO):\n",
        "    \"\"\"Use ``get_logger`` method in mmcv to get the root logger.\n",
        "    The logger will be initialized if it has not been initialized. By default a\n",
        "    StreamHandler will be added. If ``log_file`` is specified, a FileHandler\n",
        "    will also be added. The name of the root logger is the top-level package\n",
        "    name, e.g., \"mmaction\".\n",
        "    Args:\n",
        "        log_file (str | None): The log filename. If specified, a FileHandler\n",
        "            will be added to the root logger.\n",
        "        log_level (int): The root logger level. Note that only the process of\n",
        "            rank 0 is affected, while other processes will set the level to\n",
        "            \"Error\" and be silent most of the time.\n",
        "    Returns:\n",
        "        :obj:`logging.Logger`: The root logger.\n",
        "    \"\"\"\n",
        "    return get_logger(__name__.split('.')[0], log_file, log_level)\n",
        "\n",
        "\n",
        "class Mlp_pt(nn.Module):\n",
        "    \"\"\" Multilayer perceptron.\"\"\"\n",
        "\n",
        "    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n",
        "        super().__init__()\n",
        "        out_features = out_features or in_features\n",
        "        hidden_features = hidden_features or in_features\n",
        "        # print('dense',hidden_features, in_features)\n",
        "\n",
        "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
        "        self.act = act_layer()\n",
        "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
        "        self.drop = nn.Dropout(drop)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(\"x\", x.shape)\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.drop(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def window_partition_pt(x, window_size):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        x: (B, D, H, W, C)\n",
        "        window_size (tuple[int]): window size\n",
        "    Returns:\n",
        "        windows: (B*num_windows, window_size*window_size, C)\n",
        "    \"\"\"\n",
        "    B, D, H, W, C = x.shape\n",
        "    x = x.view(B, D // window_size[0], window_size[0], H // window_size[1], window_size[1], W // window_size[2], window_size[2], C)\n",
        "    windows = x.permute(0, 1, 3, 5, 2, 4, 6, 7).contiguous().view(-1, reduce(mul, window_size), C)\n",
        "    return windows\n",
        "\n",
        "\n",
        "def window_reverse_pt(windows, window_size, B, D, H, W):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        windows: (B*num_windows, window_size, window_size, C)\n",
        "        window_size (tuple[int]): Window size\n",
        "        H (int): Height of image\n",
        "        W (int): Width of image\n",
        "    Returns:\n",
        "        x: (B, D, H, W, C)\n",
        "    \"\"\"\n",
        "    x = windows.view(B, D // window_size[0], H // window_size[1], W // window_size[2], window_size[0], window_size[1], window_size[2], -1)\n",
        "    x = x.permute(0, 1, 4, 2, 5, 3, 6, 7).contiguous().view(B, D, H, W, -1)\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_window_size_pt(x_size, window_size, shift_size=None):\n",
        "    use_window_size = list(window_size)\n",
        "    if shift_size is not None:\n",
        "        use_shift_size = list(shift_size)\n",
        "    for i in range(len(x_size)):\n",
        "        if x_size[i] <= window_size[i]:\n",
        "            use_window_size[i] = x_size[i]\n",
        "            if shift_size is not None:\n",
        "                use_shift_size[i] = 0\n",
        "\n",
        "    if shift_size is None:\n",
        "        return tuple(use_window_size)\n",
        "    else:\n",
        "        return tuple(use_window_size), tuple(use_shift_size)\n",
        "\n",
        "\n",
        "class WindowAttention3D_pt(nn.Module):\n",
        "    \"\"\" Window based multi-head self attention (W-MSA) module with relative position bias.\n",
        "    It supports both of shifted and non-shifted window.\n",
        "    Args:\n",
        "        dim (int): Number of input channels.\n",
        "        window_size (tuple[int]): The temporal length, height and width of the window.\n",
        "        num_heads (int): Number of attention heads.\n",
        "        qkv_bias (bool, optional):  If True, add a learnable bias to query, key, value. Default: True\n",
        "        qk_scale (float | None, optional): Override default qk scale of head_dim ** -0.5 if set\n",
        "        attn_drop (float, optional): Dropout ratio of attention weight. Default: 0.0\n",
        "        proj_drop (float, optional): Dropout ratio of output. Default: 0.0\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dim, window_size, num_heads, qkv_bias=False, qk_scale=None, attn_drop=0., proj_drop=0.):\n",
        "\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "        self.window_size = window_size  # Wd, Wh, Ww\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        self.scale = qk_scale or head_dim ** -0.5\n",
        "        print(\"attention=====\", dim, window_size, num_heads)\n",
        "\n",
        "        # define a parameter table of relative position bias\n",
        "        self.relative_position_bias_table = nn.Parameter(\n",
        "            torch.zeros((2 * window_size[0] - 1) * (2 * window_size[1] - 1) * (2 * window_size[2] - 1), num_heads))  # 2*Wd-1 * 2*Wh-1 * 2*Ww-1, nH\n",
        "\n",
        "        # get pair-wise relative position index for each token inside the window\n",
        "        coords_d = torch.arange(self.window_size[0])\n",
        "        coords_h = torch.arange(self.window_size[1])\n",
        "        coords_w = torch.arange(self.window_size[2])\n",
        "        coords = torch.stack(torch.meshgrid(coords_d, coords_h, coords_w))  # 3, Wd, Wh, Ww\n",
        "        coords_flatten = torch.flatten(coords, 1)  # 3, Wd*Wh*Ww\n",
        "        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]  # 3, Wd*Wh*Ww, Wd*Wh*Ww\n",
        "        relative_coords = relative_coords.permute(1, 2, 0).contiguous()  # Wd*Wh*Ww, Wd*Wh*Ww, 3\n",
        "        relative_coords[:, :, 0] += self.window_size[0] - 1  # shift to start from 0\n",
        "        relative_coords[:, :, 1] += self.window_size[1] - 1\n",
        "        relative_coords[:, :, 2] += self.window_size[2] - 1\n",
        "\n",
        "        relative_coords[:, :, 0] *= (2 * self.window_size[1] - 1) * (2 * self.window_size[2] - 1)\n",
        "        relative_coords[:, :, 1] *= (2 * self.window_size[2] - 1)\n",
        "        relative_position_index = relative_coords.sum(-1)  # Wd*Wh*Ww, Wd*Wh*Ww\n",
        "        self.register_buffer(\"relative_position_index\", relative_position_index)\n",
        "\n",
        "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
        "        self.attn_drop = nn.Dropout(attn_drop)\n",
        "        self.proj = nn.Linear(dim, dim)\n",
        "        self.proj_drop = nn.Dropout(proj_drop)\n",
        "\n",
        "        trunc_normal_(self.relative_position_bias_table, std=.02)\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        \"\"\" Forward function.\n",
        "        Args:\n",
        "            x: input features with shape of (num_windows*B, N, C)\n",
        "            mask: (0/-inf) mask with shape of (num_windows, N, N) or None\n",
        "        \"\"\"\n",
        "        B_, N, C = x.shape\n",
        "        qkv = self.qkv(x).reshape(B_, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2]  # B_, nH, N, C\n",
        "\n",
        "        q = q * self.scale\n",
        "        attn = q @ k.transpose(-2, -1)\n",
        "\n",
        "        relative_position_bias = self.relative_position_bias_table[self.relative_position_index[:N, :N].reshape(-1)].reshape(\n",
        "            N, N, -1)  # Wd*Wh*Ww,Wd*Wh*Ww,nH\n",
        "        relative_position_bias = relative_position_bias.permute(2, 0, 1).contiguous()  # nH, Wd*Wh*Ww, Wd*Wh*Ww\n",
        "        attn = attn + relative_position_bias.unsqueeze(0) # B_, nH, N, N\n",
        "\n",
        "        if mask is not None:\n",
        "            nW = mask.shape[0]\n",
        "            print(\"mask in not None\", mask)\n",
        "            attn = attn.view(B_ // nW, nW, self.num_heads, N, N) + mask.unsqueeze(1).unsqueeze(0)\n",
        "            attn = attn.view(-1, self.num_heads, N, N)\n",
        "            attn = self.softmax(attn)\n",
        "        else:\n",
        "            attn = self.softmax(attn)\n",
        "\n",
        "        attn = self.attn_drop(attn)\n",
        "\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B_, N, C)\n",
        "        x = self.proj(x)\n",
        "        x = self.proj_drop(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class SwinTransformerBlock3D_pt(nn.Module):\n",
        "\n",
        "    def __init__(self, dim, num_heads, window_size=(2,7,7), shift_size=(0,0,0),\n",
        "                 mlp_ratio=4., qkv_bias=True, qk_scale=None, drop=0., attn_drop=0., drop_path=0.,\n",
        "                 act_layer=nn.GELU, norm_layer=nn.LayerNorm, use_checkpoint=False):\n",
        "        super().__init__()\n",
        "\n",
        "        print(\"3d block\",  dim, num_heads, window_size, shift_size,\n",
        "                 mlp_ratio, qkv_bias, qk_scale, drop, attn_drop, drop_path,\n",
        "                 act_layer, norm_layer, use_checkpoint)\n",
        "        self.dim = dim\n",
        "        self.num_heads = num_heads\n",
        "        self.window_size = window_size\n",
        "        self.shift_size = shift_size\n",
        "        self.mlp_ratio = mlp_ratio\n",
        "        self.use_checkpoint=use_checkpoint\n",
        "\n",
        "        assert 0 <= self.shift_size[0] < self.window_size[0], \"shift_size must in 0-window_size\"\n",
        "        assert 0 <= self.shift_size[1] < self.window_size[1], \"shift_size must in 0-window_size\"\n",
        "        assert 0 <= self.shift_size[2] < self.window_size[2], \"shift_size must in 0-window_size\"\n",
        "\n",
        "        self.norm1 = norm_layer(dim)\n",
        "        self.attn = WindowAttention3D_pt(\n",
        "            dim, window_size=self.window_size, num_heads=num_heads,\n",
        "            qkv_bias=qkv_bias, qk_scale=qk_scale, attn_drop=attn_drop, proj_drop=drop)\n",
        "\n",
        "        self.drop_path = DropPath_pt(drop_path) if drop_path > 0. else nn.Identity()\n",
        "        self.norm2 = norm_layer(dim)\n",
        "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
        "        self.mlp = Mlp_pt(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)\n",
        "\n",
        "        self.outputs = {}\n",
        "    def forward_part1(self, x, mask_matrix):\n",
        "        B, D, H, W, C = x.shape\n",
        "        window_size, shift_size = get_window_size_pt((D, H, W), self.window_size, self.shift_size)\n",
        "        print(\"get window size\", window_size, shift_size, (D, H, W), self.window_size, self.shift_size)\n",
        "        x = self.norm1(x)\n",
        "        # pad feature maps to multiples of window size\n",
        "        pad_l = pad_t = pad_d0 = 0\n",
        "        pad_d1 = (window_size[0] - D % window_size[0]) % window_size[0]\n",
        "        pad_b = (window_size[1] - H % window_size[1]) % window_size[1]\n",
        "        pad_r = (window_size[2] - W % window_size[2]) % window_size[2]\n",
        "        x = F.pad(x, (0, 0, pad_l, pad_r, pad_t, pad_b, pad_d0, pad_d1))\n",
        "\n",
        "        self.outputs[\"paddings\"] = x\n",
        "\n",
        "        _, Dp, Hp, Wp, _ = x.shape\n",
        "        # cyclic shift\n",
        "        if any(i > 0 for i in shift_size):\n",
        "            shifted_x = torch.roll(x, shifts=(-shift_size[0], -shift_size[1], -shift_size[2]), dims=(1, 2, 3))\n",
        "            attn_mask = mask_matrix\n",
        "        else:\n",
        "            shifted_x = x\n",
        "            attn_mask = None\n",
        "        \n",
        "        print(\"attn mask\", attn_mask, shift_size)\n",
        "\n",
        "        self.outputs[\"shifted_x\"] = shifted_x\n",
        "        self.outputs[\"attn_mask\"] = attn_mask\n",
        "        # partition windows\n",
        "        x_windows = window_partition_pt(shifted_x, window_size)  # B*nW, Wd*Wh*Ww, C\n",
        "        # W-MSA/SW-MSA\n",
        "        attn_windows = self.attn(x_windows, mask=attn_mask)  # B*nW, Wd*Wh*Ww, C\n",
        "        # merge windows\n",
        "        attn_windows = attn_windows.view(-1, *(window_size+(C,)))\n",
        "        shifted_x = window_reverse_pt(attn_windows, window_size, B, Dp, Hp, Wp)  # B D' H' W' C\n",
        "\n",
        "        self.outputs[\"shifted_x final\"] = shifted_x\n",
        "        self.outputs[\"attn_windows\"] = attn_windows\n",
        "        self.outputs[\"x_windowns\"] = x_windows\n",
        "        # reverse cyclic shift\n",
        "        if any(i > 0 for i in shift_size):\n",
        "            x = torch.roll(shifted_x, shifts=(shift_size[0], shift_size[1], shift_size[2]), dims=(1, 2, 3))\n",
        "        else:\n",
        "            x = shifted_x\n",
        "\n",
        "        self.outputs[\"after roll\"] = x\n",
        "        \n",
        "\n",
        "        if pad_d1 >0 or pad_r > 0 or pad_b > 0:\n",
        "            x = x[:, :D, :H, :W, :].contiguous()\n",
        "\n",
        "        self.outputs[\"forward1 output\"] = x\n",
        "        \n",
        "        return x\n",
        "\n",
        "    def forward_part2(self, x):\n",
        "        x = self.norm2(x)\n",
        "        self.outputs[\"norm2\"] =x\n",
        "        x = self.mlp(x)\n",
        "        self.outputs[\"mlp\"] = x\n",
        "        x= self.drop_path(x)\n",
        "        self.outputs['drop_path'] = x\n",
        "        return x\n",
        "        # return self.drop_path(self.mlp(self.norm2(x)))\n",
        "\n",
        "    def forward(self, x, mask_matrix):\n",
        "\n",
        "        shortcut = x\n",
        "        if self.use_checkpoint:\n",
        "            x = checkpoint.checkpoint(self.forward_part1, x, mask_matrix)\n",
        "        else:\n",
        "            x = self.forward_part1(x, mask_matrix)\n",
        "        x = shortcut + self.drop_path(x)\n",
        "\n",
        "        if self.use_checkpoint:\n",
        "            x = x + checkpoint.checkpoint(self.forward_part2, x)\n",
        "        else:\n",
        "            x = x + self.forward_part2(x)\n",
        "\n",
        "        return x, self.outputs\n",
        "\n",
        "\n",
        "class PatchMerging_pt(nn.Module):\n",
        "    \"\"\" Patch Merging Layer\n",
        "    Args:\n",
        "        dim (int): Number of input channels.\n",
        "        norm_layer (nn.Module, optional): Normalization layer.  Default: nn.LayerNorm\n",
        "    \"\"\"\n",
        "    def __init__(self, dim, norm_layer=nn.LayerNorm):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "        self.reduction = nn.Linear(4 * dim, 2 * dim, bias=False)\n",
        "        self.norm = norm_layer(4 * dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\" Forward function.\n",
        "        Args:\n",
        "            x: Input feature, tensor size (B, D, H, W, C).\n",
        "        \"\"\"\n",
        "        B, D, H, W, C = x.shape\n",
        "\n",
        "        # padding\n",
        "        pad_input = (H % 2 == 1) or (W % 2 == 1)\n",
        "        if pad_input:\n",
        "            x = F.pad(x, (0, 0, 0, W % 2, 0, H % 2))\n",
        "\n",
        "        x0 = x[:, :, 0::2, 0::2, :]  # B D H/2 W/2 C\n",
        "        x1 = x[:, :, 1::2, 0::2, :]  # B D H/2 W/2 C\n",
        "        x2 = x[:, :, 0::2, 1::2, :]  # B D H/2 W/2 C\n",
        "        x3 = x[:, :, 1::2, 1::2, :]  # B D H/2 W/2 C\n",
        "        x = torch.cat([x0, x1, x2, x3], -1)  # B D H/2 W/2 4*C\n",
        "\n",
        "        x = self.norm(x)\n",
        "        x = self.reduction(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "# cache each stage results\n",
        "def compute_mask_pt(D, H, W, window_size, shift_size, device):\n",
        "    img_mask = torch.zeros((1, D, H, W, 1), device=device)  # 1 Dp Hp Wp 1\n",
        "    cnt = 0\n",
        "    for d in slice(-window_size[0]), slice(-window_size[0], -shift_size[0]), slice(-shift_size[0],None):\n",
        "        for h in slice(-window_size[1]), slice(-window_size[1], -shift_size[1]), slice(-shift_size[1],None):\n",
        "            for w in slice(-window_size[2]), slice(-window_size[2], -shift_size[2]), slice(-shift_size[2],None):\n",
        "                img_mask[:, d, h, w, :] = cnt\n",
        "                cnt += 1\n",
        "    mask_windows = window_partition_pt(img_mask, window_size)  # nW, ws[0]*ws[1]*ws[2], 1\n",
        "    mask_windows = mask_windows.squeeze(-1)  # nW, ws[0]*ws[1]*ws[2]\n",
        "    attn_mask = mask_windows.unsqueeze(1) - mask_windows.unsqueeze(2)\n",
        "    attn_mask = attn_mask.masked_fill(attn_mask != 0, float(-100.0)).masked_fill(attn_mask == 0, float(0.0))\n",
        "    return attn_mask\n",
        "\n",
        "\n",
        "class BasicLayer_pt(nn.Module):\n",
        "\n",
        "    def __init__(self,dim,depth,num_heads,window_size=(1,7,7), mlp_ratio=4.,qkv_bias=False,\n",
        "                 qk_scale=None,drop=0.,\n",
        "                 attn_drop=0.,\n",
        "                 drop_path=0.,\n",
        "                 norm_layer=nn.LayerNorm,\n",
        "                 downsample=None,\n",
        "                 use_checkpoint=False):\n",
        "        super().__init__()\n",
        "        print(self, dim,depth,num_heads,window_size, mlp_ratio,qkv_bias,qk_scale,drop,attn_drop,drop_path,norm_layer,downsample,use_checkpoint )\n",
        "\n",
        "        self.window_size = window_size\n",
        "        self.shift_size = tuple(i // 2 for i in window_size)\n",
        "        self.depth = depth\n",
        "        self.use_checkpoint = use_checkpoint\n",
        "\n",
        "        # build blocks\n",
        "        self.blocks = nn.ModuleList([\n",
        "            SwinTransformerBlock3D_pt(\n",
        "                dim=dim,\n",
        "                num_heads=num_heads,\n",
        "                window_size=window_size,\n",
        "                shift_size=(0,0,0) if (i % 2 == 0) else self.shift_size,\n",
        "                mlp_ratio=mlp_ratio,\n",
        "                qkv_bias=qkv_bias,\n",
        "                qk_scale=qk_scale,\n",
        "                drop=drop,\n",
        "                attn_drop=attn_drop,\n",
        "                drop_path=drop_path[i] if isinstance(drop_path, list) else drop_path,\n",
        "                norm_layer=norm_layer,\n",
        "                use_checkpoint=use_checkpoint,\n",
        "            )\n",
        "            for i in range(depth)])\n",
        "        \n",
        "        self.downsample = downsample\n",
        "        if self.downsample is not None:\n",
        "            self.downsample = downsample(dim=dim, norm_layer=norm_layer)\n",
        "\n",
        "        self.outputs= {}\n",
        "    def forward(self, x):\n",
        "        \"\"\" Forward function.\n",
        "        Args:\n",
        "            x: Input feature, tensor size (B, C, D, H, W).\n",
        "        \"\"\"\n",
        "        # calculate attention mask for SW-MSA\n",
        "        B, C, D, H, W = x.shape\n",
        "        window_size, shift_size = get_window_size_pt((D,H,W), self.window_size, self.shift_size)\n",
        "        x = rearrange(x, 'b c d h w -> b d h w c')\n",
        "        Dp = int(np.ceil(D / window_size[0])) * window_size[0]\n",
        "        Hp = int(np.ceil(H / window_size[1])) * window_size[1]\n",
        "        Wp = int(np.ceil(W / window_size[2])) * window_size[2]\n",
        "        attn_mask = compute_mask_pt(Dp, Hp, Wp, window_size, shift_size, x.device)\n",
        "        i = 1\n",
        "        self.outputs[\"attn_mask\"] = attn_mask\n",
        "        for blk in self.blocks:\n",
        "            x = blk(x, attn_mask)\n",
        "            self.outputs[f\"block_{i}\"] = x\n",
        "            i += 1\n",
        "\n",
        "\n",
        "        x = x.view(B, D, H, W, -1)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            x = self.downsample(x)\n",
        "        x = rearrange(x, 'b d h w c -> b c d h w')\n",
        "\n",
        "        \n",
        "        return x ,self.outputs\n",
        "\n",
        "\n",
        "class PatchEmbed3D_pt(nn.Module):\n",
        "\n",
        "    def __init__(self, patch_size=(2,4,4), in_chans=3, embed_dim=96, norm_layer=None):\n",
        "        super().__init__()\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "        self.in_chans = in_chans\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "        self.proj = nn.Conv3d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
        "        if norm_layer is not None:\n",
        "            self.norm = norm_layer(embed_dim)\n",
        "        else:\n",
        "            self.norm = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward function.\"\"\"\n",
        "        # padding\n",
        "        _, _, D, H, W = x.size()\n",
        "        if W % self.patch_size[2] != 0:\n",
        "            x = F.pad(x, (0, self.patch_size[2] - W % self.patch_size[2]))\n",
        "        if H % self.patch_size[1] != 0:\n",
        "            x = F.pad(x, (0, 0, 0, self.patch_size[1] - H % self.patch_size[1]))\n",
        "        if D % self.patch_size[0] != 0:\n",
        "            x = F.pad(x, (0, 0, 0, 0, 0, self.patch_size[0] - D % self.patch_size[0]))\n",
        "\n",
        "        x = self.proj(x)  # B C D Wh Ww\n",
        "        if self.norm is not None:\n",
        "            D, Wh, Ww = x.size(2), x.size(3), x.size(4)\n",
        "            x = x.flatten(2).transpose(1, 2)\n",
        "            x = self.norm(x)\n",
        "            x = x.transpose(1, 2).view(-1, self.embed_dim, D, Wh, Ww)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class SwinTransformer3D_pt(nn.Module):\n",
        "\n",
        "\n",
        "    def __init__(self,\n",
        "                 pretrained=None,\n",
        "                 pretrained2d=True,\n",
        "                 patch_size=(4,4,4),\n",
        "                 in_chans=3,\n",
        "                 embed_dim=96,\n",
        "                 depths=[2, 2, 6, 2],\n",
        "                 num_heads=[3, 6, 12, 24],\n",
        "                 window_size=(2,7,7),\n",
        "                 mlp_ratio=4.,\n",
        "                 qkv_bias=True,\n",
        "                 qk_scale=None,\n",
        "                 drop_rate=0.,\n",
        "                 attn_drop_rate=0.,\n",
        "                 drop_path_rate=0.2,\n",
        "                 norm_layer=nn.LayerNorm,\n",
        "                 patch_norm=False,\n",
        "                 frozen_stages=-1,\n",
        "                 use_checkpoint=False, \n",
        "                 isTest =False):    ## ****** remove it later\n",
        "        super().__init__()\n",
        "\n",
        "        self.pretrained = pretrained\n",
        "        self.pretrained2d = pretrained2d\n",
        "        self.num_layers = len(depths)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.patch_norm = patch_norm\n",
        "        self.frozen_stages = frozen_stages\n",
        "        self.window_size = window_size\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "        self.isTest = isTest\n",
        "\n",
        "        # split image into non-overlapping patches\n",
        "        self.patch_embed = PatchEmbed3D_pt(\n",
        "            patch_size=patch_size, in_chans=in_chans, embed_dim=embed_dim,\n",
        "            norm_layer=norm_layer if self.patch_norm else None)\n",
        "\n",
        "        self.pos_drop = nn.Dropout(p=drop_rate)\n",
        "\n",
        "        # stochastic depth\n",
        "        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))]  # stochastic depth decay rule\n",
        "\n",
        "        # build layers\n",
        "        self.layers = nn.ModuleList()\n",
        "        for i_layer in range(self.num_layers):\n",
        "            layer = BasicLayer(\n",
        "                dim=int(embed_dim * 2**i_layer),\n",
        "                depth=depths[i_layer],\n",
        "                num_heads=num_heads[i_layer],\n",
        "                window_size=window_size,\n",
        "                mlp_ratio=mlp_ratio,\n",
        "                qkv_bias=qkv_bias,\n",
        "                qk_scale=qk_scale,\n",
        "                drop=drop_rate,\n",
        "                attn_drop=attn_drop_rate,\n",
        "                drop_path=dpr[sum(depths[:i_layer]):sum(depths[:i_layer + 1])],\n",
        "                norm_layer=norm_layer,\n",
        "                downsample=PatchMerging_pt if i_layer<self.num_layers-1 else None,\n",
        "                use_checkpoint=use_checkpoint)\n",
        "            self.layers.append(layer)\n",
        "\n",
        "        self.num_features = int(embed_dim * 2**(self.num_layers-1))\n",
        "\n",
        "        # add a norm layer for each output\n",
        "        self.norm = norm_layer(self.num_features)\n",
        "\n",
        "        self._freeze_stages()\n",
        "\n",
        "    def _freeze_stages(self):\n",
        "        if self.frozen_stages >= 0:\n",
        "            self.patch_embed.eval()\n",
        "            for param in self.patch_embed.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "        if self.frozen_stages >= 1:\n",
        "            self.pos_drop.eval()\n",
        "            for i in range(0, self.frozen_stages):\n",
        "                m = self.layers[i]\n",
        "                m.eval()\n",
        "                for param in m.parameters():\n",
        "                    param.requires_grad = False\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward function.\"\"\"\n",
        "        x = self.patch_embed(x)\n",
        "        layer_out = {}\n",
        "\n",
        "        layer_out[\"PatchEmbed\"] = x\n",
        "        x = self.pos_drop(x)\n",
        "\n",
        "        i = 1\n",
        "\n",
        "        for layer in self.layers:\n",
        "            x = layer(x.contiguous())\n",
        "            layer_out[f\"basic layer{i}\"] = x\n",
        "            i+=1\n",
        "\n",
        "        x = rearrange(x, 'n c d h w -> n d h w c')\n",
        "        x = self.norm(x)\n",
        "        x = rearrange(x, 'n d h w c -> n c d h w')\n",
        "        \n",
        "        layer_out[\"Final Output\"] = x\n",
        "\n",
        "        if self.isTest:                 # remove later\n",
        "            return layer_out, x\n",
        "        else:\n",
        "            return x\n",
        "\n",
        "    def train(self, mode=True):\n",
        "        \"\"\"Convert the model into training mode while keep layers freezed.\"\"\"\n",
        "        super(SwinTransformer3D_pt, self).train(mode)\n",
        "        self._freeze_stages()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Swin Block3d (b4,3d_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import LayerNormalization\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "from functools import  lru_cache\n",
        "def compute_mask(D, H, W, window_size, shift_size):\n",
        "\n",
        "    img_mask = np.zeros((1, D, H, W, 1)) \n",
        "\n",
        " \n",
        "    cnt = 0\n",
        "\n",
        "    for d in slice(-window_size[0]), slice(-window_size[0], -shift_size[0]), slice(-shift_size[0],None):\n",
        "        for h in slice(-window_size[1]), slice(-window_size[1], -shift_size[1]), slice(-shift_size[1],None):\n",
        "            for w in slice(-window_size[2]), slice(-window_size[2], -shift_size[2]), slice(-shift_size[2],None):\n",
        "                img_mask[:, d, h, w, :] = cnt\n",
        "                cnt = cnt + 1\n",
        "    img_mask = tf.convert_to_tensor(img_mask, dtype=\"float32\")\n",
        "\n",
        "    # print(\"basic compute\", img_mask.shape, window_size, shift_size, D, H, W)\n",
        "    # print(\"compute mask cm tf\")\n",
        "    mask_windows = window_partition(img_mask, window_size)  # nW, ws[0]*ws[1]*ws[2], 1\n",
        "\n",
        "    mask_windows = tf.squeeze(mask_windows, axis = -1)  # nW, ws[0]*ws[1]*ws[2] ??\n",
        "    attn_mask = tf.expand_dims(mask_windows, axis=1) - tf.expand_dims(mask_windows, axis=2)\n",
        "    \n",
        "\n",
        "    attn_mask = tf.cast(attn_mask, dtype=\"float64\")\n",
        "\n",
        "    attn_mask = tf.where(attn_mask != 0, -100.0, attn_mask)\n",
        "    attn_mask = tf.where(attn_mask == 0, 0.0 , attn_mask)\n",
        "\n",
        "    return attn_mask\n",
        "\n",
        "\n",
        "class SwinTransformerBlock3D(tf.keras.Model):\n",
        "\n",
        "\n",
        "    def __init__(self, dim, compute_mask_info, num_heads, window_size=(2,7,7), shift_size=(0,0,0),\n",
        "                 mlp_ratio=4., qkv_bias=True, qk_scale=None, drop=0., attn_drop=0., drop_path=0.,\n",
        "                 act_layer=tf.keras.activations.gelu, norm_layer=LayerNormalization, use_checkpoint=False):\n",
        "        super().__init__()\n",
        "\n",
        "        print(\"3d block\",  dim, compute_mask_info,  num_heads, window_size, shift_size,\n",
        "                 mlp_ratio, qkv_bias, qk_scale, drop, attn_drop, drop_path,\n",
        "                 act_layer, norm_layer, use_checkpoint)\n",
        "\n",
        "        self.dim = dim\n",
        "        self.num_heads = num_heads\n",
        "        self.window_size = window_size\n",
        "        self.shift_size = shift_size\n",
        "        self.mlp_ratio = mlp_ratio\n",
        "        self.use_checkpoint=use_checkpoint\n",
        "        self.compute_mask_info = compute_mask_info\n",
        "        \n",
        "\n",
        "        # delete this\n",
        "        self.drop_path_val = drop_path\n",
        " \n",
        "        assert 0 <= self.shift_size[0] < self.window_size[0], \"shift_size must in 0-window_size\"\n",
        "        assert 0 <= self.shift_size[1] < self.window_size[1], \"shift_size must in 0-window_size\"\n",
        "        assert 0 <= self.shift_size[2] < self.window_size[2], \"shift_size must in 0-window_size\"\n",
        "\n",
        "        self.norm1 = norm_layer( epsilon=1e-5)\n",
        "        self.attn = WindowAttention3D(\n",
        "            dim, window_size=self.window_size, num_heads=num_heads,\n",
        "            qkv_bias=qkv_bias, qk_scale=qk_scale, attn_drop=attn_drop, proj_drop=drop)\n",
        "\n",
        "        # compute mask\n",
        "        B, C, D, H, W = self.compute_mask_info[\"shape_of_input\"]\n",
        "        D = 4\n",
        "        mask_window_size, mask_shift_size = get_window_size((D,H,W), self.compute_mask_info[\"window_size\"], self.compute_mask_info[\"shift_size\"])  #### change\n",
        "         \n",
        "        Dp = int(tf.math.ceil(D/ mask_window_size[0])) * mask_window_size[0]\n",
        "        Hp = int(tf.math.ceil(H / mask_window_size[1])) * mask_window_size[1]\n",
        "        Wp = int(tf.math.ceil(W / mask_window_size[2])) * mask_window_size[2]\n",
        "        \n",
        "        self.attn_mask = compute_mask(Dp, Hp, Wp, mask_window_size, mask_shift_size)\n",
        "        # print(\"compute mask parameters\", (Dp, Hp, Wp, mask_window_size, mask_shift_size))\n",
        "        # print(\"attn_mask\", self.attn_mask.shape)\n",
        "\n",
        "        self.drop_path = DropPath(drop_path) if drop_path > 0. else tf.identity\n",
        "        self.norm2 = norm_layer(epsilon=1e-5)\n",
        "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
        "        self.mlp = mlp_block(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)\n",
        "\n",
        "        self.outputs = {}\n",
        "\n",
        "    def forward_part1(self, x):\n",
        "        \n",
        "        B, D, H, W, C = tf.shape(x)[0], tf.shape(x)[1], tf.shape(x)[2] , tf.shape(x)[3] , tf.shape(x)[4] \n",
        "        \n",
        "        b, c, d, h ,w = self.compute_mask_info['shape_of_input']\n",
        "        d = 4       #### change\n",
        "        \n",
        "\n",
        "        window_size, shift_size = get_window_size((d, h, w), self.window_size, self.shift_size)\n",
        "        print(\"get window size\", window_size, shift_size, (d, h, w), self.window_size, self.shift_size, (D, H,W))\n",
        "\n",
        "        x = self.norm1(x)\n",
        "\n",
        "        pad_l = pad_t = pad_d0 = 0\n",
        " \n",
        "        pad_d1 = (window_size[0] - d % window_size[0]) % window_size[0]\n",
        "        pad_b = (window_size[1] - h % window_size[1]) % window_size[1]\n",
        "        pad_r = (window_size[2] - w % window_size[2]) % window_size[2]\n",
        "\n",
        "  \n",
        "\n",
        "        paddings = [[0,0] , [pad_d0, pad_d1] , [pad_t, pad_b] , [pad_l, pad_r], [0, 0] ]\n",
        "\n",
        "\n",
        "        x = tf.pad(x, paddings)\n",
        "        self.outputs[\"paddings\"] = x\n",
        "        \n",
        "        _, Dp, Hp, Wp, _ = tf.shape(x)[0], tf.shape(x)[1], tf.shape(x)[2] , tf.shape(x)[3] , tf.shape(x)[4] \n",
        "\n",
        "        if any(i > 0 for i in shift_size):\n",
        "            shifted_x = tf.roll(x, shift=[-self.shift_size[0], -self.shift_size[1], -self.shift_size[2]], axis=[1, 2, 3]) #?\n",
        "            attn_mask = self.attn_mask\n",
        "        else:\n",
        "            shifted_x = x\n",
        "            attn_mask = None\n",
        "\n",
        "        self.outputs[\"shifted_x\"] = shifted_x\n",
        "        self.outputs[\"attn_mask\"] = attn_mask\n",
        "\n",
        "        x_windows = window_partition(shifted_x, window_size)  # B*nW, Wd*Wh*Ww, C\n",
        "\n",
        "        # W-MSA/SW-MSA\n",
        "        attn_windows = self.attn(x_windows, mask=attn_mask)  # B*nW, Wd*Wh*Ww, C\n",
        "        # merge windows\n",
        "        attn_windows = tf.reshape( attn_windows ,  [-1, *(window_size+(C,))] )\n",
        "        shifted_x = window_reverse(attn_windows, window_size, B, Dp, Hp, Wp)  # B D' H' W' C\n",
        "\n",
        "        self.outputs[\"shifted_x final\"] = shifted_x\n",
        "        self.outputs[\"attn_windows\"] = attn_windows\n",
        "        self.outputs[\"x_windowns\"] = x_windows\n",
        "\n",
        "        if any(i > 0 for i in shift_size):\n",
        "            x = tf.roll(shifted_x, shift=[self.shift_size[0], self.shift_size[1], self.shift_size[2]], axis=[1, 2, 3]) #?\n",
        "        else:\n",
        "            x = shifted_x\n",
        "\n",
        "        self.outputs[\"after roll\"] = x\n",
        "\n",
        "        if pad_d1 >0 or pad_r > 0 or pad_b > 0:\n",
        "            x = x[:, :D, :H, :W, :]\n",
        "        self.outputs[\"forward1 output\"] = x\n",
        "        return x\n",
        "\n",
        "    def forward_part2(self, x):\n",
        "        x = self.norm2(x)\n",
        "        self.outputs[\"norm2\"] =x\n",
        "        x = self.mlp(x)\n",
        "        self.outputs[\"mlp\"] = x\n",
        "        x= self.drop_path(x)\n",
        "        self.outputs['drop_path'] = x\n",
        "        return x\n",
        "\n",
        "\n",
        "    def call(self, x):\n",
        "\n",
        "\n",
        "        shortcut = x\n",
        "        x = self.forward_part1(x)\n",
        "\n",
        "\n",
        "        x = shortcut + self.drop_path(x)\n",
        "\n",
        "        x = x + self.forward_part2(x)\n",
        "        \n",
        "\n",
        "        return x, self.outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3d block 768 24 (8, 7, 7) (4, 3, 3) 4.0 True None 0.4 0.0 0.0 <class 'torch.nn.modules.activation.GELU'> <class 'torch.nn.modules.normalization.LayerNorm'> False\n",
            "attention===== 768 (8, 7, 7) 24\n",
            "3d block 768 {'shape_of_input': (2, 768, 2, 7, 7), 'window_size': (8, 7, 7), 'shift_size': (4, 3, 3)} 24 (8, 7, 7) (4, 3, 3) 4.0 True None 0.4 0.0 0.0 <function gelu at 0x000001DE5DE76EE0> <class 'keras.layers.normalization.layer_normalization.LayerNormalization'> False\n"
          ]
        }
      ],
      "source": [
        "b4_3d_pt = SwinTransformerBlock3D_pt(  768, 24, (8, 7, 7), (4, 3, 3), 4.0, True, None, 0.4, 0.0, 0.0, nn.GELU, nn.LayerNorm, False)\n",
        "b4_3d_tf = SwinTransformerBlock3D(  768, {'shape_of_input': (2, 768, 2, 7, 7), 'window_size': (8, 7, 7), 'shift_size': (4, 3, 3)} , 24, (8, 7, 7), (4, 3, 3), 4.0, True, None, 0.4, 0.0, 0.0, tf.keras.activations.gelu, tf.keras.layers.LayerNormalization, False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "get window size (4, 7, 7) (0, 0, 0) (4, 7, 7) (8, 7, 7) (4, 3, 3)\n",
            "attn mask None (0, 0, 0)\n",
            "get window size (4, 7, 7) (0, 0, 0) (4, 7, 7) (8, 7, 7) (4, 3, 3) (<tf.Tensor: shape=(), dtype=int32, numpy=4>, <tf.Tensor: shape=(), dtype=int32, numpy=7>, <tf.Tensor: shape=(), dtype=int32, numpy=7>)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(1, 1, 1, 1, 10), dtype=float32, numpy=\n",
              " array([[[[[ 0.48156175,  0.40172303,  0.78638935,  0.2893533 ,\n",
              "             0.35498217,  1.3804607 , -0.5288415 ,  0.53186584,\n",
              "             0.8213533 , -0.05060408]]]]], dtype=float32)>,\n",
              " tensor([[[[[-0.2615,  1.1421,  0.1509,  0.1677,  0.8113,  0.5971,  1.1334,\n",
              "              0.6903,  0.5719,  0.0708]]]]]))"
            ]
          },
          "execution_count": 151,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_tf , x_pt = get_x((2, 4, 7, 7, 768))\n",
        "out_pt, layers_3d_pt = b4_3d_pt(x_pt, outputs_pt[\"attn_mask\"])\n",
        "out_tf, layers_3d_pt = b4_3d_tf(x_tf)\n",
        "\n",
        "\n",
        "out_tf[:1,:1,:1,:1,:10], out_pt[:1,:1,:1,:1,:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(dict_keys(['attn_mask', 'block_1', 'block_2']), torch.Size([1, 196, 196]))"
            ]
          },
          "execution_count": 152,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "outputs_pt.keys() , outputs_pt[\"attn_mask\"].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['norm1.weight', 'norm1.bias', 'attn.relative_position_bias_table', 'attn.relative_position_index', 'attn.qkv.weight', 'attn.qkv.bias', 'attn.proj.weight', 'attn.proj.bias', 'norm2.weight', 'norm2.bias', 'mlp.fc1.weight', 'mlp.fc1.bias', 'mlp.fc2.weight', 'mlp.fc2.bias'])"
            ]
          },
          "execution_count": 153,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b4_3d_pt.eval()\n",
        "\n",
        "np_state_dict = b4_3d_pt.state_dict()\n",
        "np_state_dict = {k: np_state_dict[k].numpy() for k in np_state_dict}\n",
        "np_state_dict.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_layers = {}\n",
        "def modify_block3D(np_state_dict, pt_weights_prefix, outer_layer):\n",
        "  # PatchMerging\n",
        "    global i\n",
        "\n",
        "\n",
        "    layernorm_idx = 1\n",
        "    mlp_layer_idx = 1\n",
        "\n",
        "    if isinstance(outer_layer, SwinTransformerBlock3D):\n",
        "        for inner_layer in outer_layer.layers:\n",
        "            print(inner_layer)\n",
        "            # Layer norm.\n",
        "            if isinstance(inner_layer, tf.keras.layers.LayerNormalization):\n",
        "                #print(\"layer norm\")\n",
        "                layer_norm_prefix = (\n",
        "                    f\"norm{layernorm_idx}\"\n",
        "                )\n",
        "                inner_layer.gamma.assign(\n",
        "                    tf.Variable(\n",
        "                        np_state_dict[f\"{layer_norm_prefix}.weight\"]\n",
        "                    )\n",
        "                )\n",
        "            #   print(i)\n",
        "            #   i += 1\n",
        "\n",
        "                model_layers[f\"{layer_norm_prefix}.weight\"] = inner_layer.gamma.name \n",
        "\n",
        "\n",
        "                inner_layer.beta.assign(\n",
        "                    tf.Variable(np_state_dict[f\"{layer_norm_prefix}.bias\"])\n",
        "                )\n",
        "            #   print(i)\n",
        "            #   i += 1  \n",
        "                model_layers[f\"{layer_norm_prefix}.bias\"] = inner_layer.beta.name \n",
        "                layernorm_idx += 1\n",
        "\n",
        "            # Window attention.\n",
        "            elif isinstance(inner_layer, WindowAttention3D):\n",
        "                #print(\"window attention\")\n",
        "                attn_prefix = f\"attn\"\n",
        "\n",
        "                # Relative position.\n",
        "                inner_layer.relative_position_bias_table = (\n",
        "                    modify_tf_block(\n",
        "                        inner_layer.relative_position_bias_table,\n",
        "                        np_state_dict[\n",
        "                            f\"{attn_prefix}.relative_position_bias_table\"\n",
        "                        ] ,\n",
        "                        wn =f\"{attn_prefix}.relative_position_bias_table\" ,\n",
        "                    )\n",
        "                )\n",
        "                inner_layer.relative_position_index = (\n",
        "                    modify_tf_block(\n",
        "                        inner_layer.relative_position_index,\n",
        "                        np_state_dict[\n",
        "                            f\"{attn_prefix}.relative_position_index\"\n",
        "                        ],\n",
        "                        wn = f\"{attn_prefix}.relative_position_index\"\n",
        "                    )\n",
        "                )\n",
        "\n",
        "                # QKV.\n",
        "                inner_layer.qkv = modify_tf_block(\n",
        "                    inner_layer.qkv,\n",
        "                    np_state_dict[f\"{attn_prefix}.qkv.weight\"],\n",
        "                    np_state_dict[f\"{attn_prefix}.qkv.bias\"],\n",
        "                    wn = f\"{attn_prefix}.qkv.weight\",\n",
        "                    bn = f\"{attn_prefix}.qkv.bias\"\n",
        "                )\n",
        "\n",
        "                # Projection.\n",
        "                inner_layer.proj = modify_tf_block(\n",
        "                    inner_layer.proj,\n",
        "                    np_state_dict[f\"{attn_prefix}.proj.weight\"],\n",
        "                    np_state_dict[f\"{attn_prefix}.proj.bias\"],\n",
        "                    wn = f\"{attn_prefix}.proj.weight\",\n",
        "                    bn = f\"{attn_prefix}.proj.bias\"\n",
        "                )\n",
        "\n",
        "            # MLP.\n",
        "            elif isinstance(inner_layer, tf.keras.Model):\n",
        "                #print(\"mlp\")\n",
        "                mlp_prefix = f\"mlp\"\n",
        "                for mlp_layer in inner_layer.layers:\n",
        "                    if isinstance(mlp_layer, tf.keras.layers.Dense):\n",
        "                        mlp_layer = modify_tf_block(\n",
        "                            mlp_layer,\n",
        "                            np_state_dict[\n",
        "                                f\"{mlp_prefix}.fc{mlp_layer_idx}.weight\"\n",
        "                            ],\n",
        "                            np_state_dict[\n",
        "                                f\"{mlp_prefix}.fc{mlp_layer_idx}.bias\"\n",
        "                            ],\n",
        "                            wn =  f\"{mlp_prefix}.fc{mlp_layer_idx}.weight\" ,\n",
        "                            bn =  f\"{mlp_prefix}.fc{mlp_layer_idx}.bias\"\n",
        "                        )\n",
        "                        mlp_layer_idx += 1\n",
        "\n",
        "\n",
        "    return outer_layer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<keras.layers.normalization.layer_normalization.LayerNormalization object at 0x000001DE03E8D460>\n",
            "<VideoSwinTransformer.WindowAttention3D.WindowAttention3D object at 0x000001DE03E8D1C0>\n",
            "<keras.layers.normalization.layer_normalization.LayerNormalization object at 0x000001DE03E8DDF0>\n",
            "<keras.engine.sequential.Sequential object at 0x000001DE00C37190>\n"
          ]
        }
      ],
      "source": [
        "_ = modify_block3D(np_state_dict, \"\",b4_3d_tf )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "get window size (4, 7, 7) (0, 0, 0) (4, 7, 7) (8, 7, 7) (4, 3, 3)\n",
            "attn mask None (0, 0, 0)\n",
            "get window size (4, 7, 7) (0, 0, 0) (4, 7, 7) (8, 7, 7) (4, 3, 3) (<tf.Tensor: shape=(), dtype=int32, numpy=4>, <tf.Tensor: shape=(), dtype=int32, numpy=7>, <tf.Tensor: shape=(), dtype=int32, numpy=7>)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(1, 1, 1, 1, 10), dtype=float32, numpy=\n",
              " array([[[[[-0.04404575,  0.78626347,  0.3264048 ,  0.20774746,\n",
              "             0.61750996,  0.45249033,  0.5748977 ,  0.6990183 ,\n",
              "             0.678704  ,  0.4859593 ]]]]], dtype=float32)>,\n",
              " tensor([[[[[-0.0440,  0.7863,  0.3264,  0.2077,  0.6175,  0.4525,  0.5749,\n",
              "              0.6990,  0.6787,  0.4860]]]]]))"
            ]
          },
          "execution_count": 156,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out_pt, layers_3d_pt = b4_3d_pt(x_pt, outputs_pt[\"attn_mask\"])\n",
        "out_tf, layers_3d_tf = b4_3d_tf(x_tf)\n",
        "\n",
        "\n",
        "out_tf[:1,:1,:1,:1,:10], out_pt[:1,:1,:1,:1,:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.026587386\n"
          ]
        }
      ],
      "source": [
        "rtol = 1e-4\n",
        "etol = 1e-4\n",
        "\n",
        "print(np.sum(np.absolute(out_tf.numpy() - out_pt.detach().numpy())))\n",
        "\n",
        "np.testing.assert_allclose(out_tf.numpy(), out_pt.detach().numpy(), etol, rtol)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "paddings\n",
            "0.04095733 paddings\n",
            "shifted_x\n",
            "0.04095733 shifted_x\n",
            "attn_mask\n",
            "----  None None \n",
            "\n",
            "shifted_x final\n",
            "0.0042701275 shifted_x final\n",
            "attn_windows\n",
            "0.0042701275 attn_windows\n",
            "x_windowns\n",
            "0.04095733 x_windowns\n",
            "after roll\n",
            "0.0042701275 after roll\n",
            "forward1 output\n",
            "0.0042701275 forward1 output\n",
            "norm2\n",
            "0.045048773 norm2\n",
            "mlp\n",
            "0.02588562 mlp\n",
            "drop_path\n",
            "0.02588562 drop_path\n"
          ]
        }
      ],
      "source": [
        "rtol = 1e-4\n",
        "etol = 1e-4\n",
        "\n",
        "for layer in layers_3d_pt:\n",
        "    print(layer)\n",
        "    try:\n",
        "        print( np.sum(np.absolute(layers_3d_tf[layer].numpy() - layers_3d_pt[layer].detach().numpy())), layer)\n",
        "    except:\n",
        "        print(\"---- \",layers_3d_tf[layer] , layers_3d_pt[layer], \"\\n\")\n",
        "\n",
        "    # np.testing.assert_allclose(layers_3d_tf[layer].numpy(), layers_3d_pt[layer].detach().numpy(), etol, rtol)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Basic layer 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_tf, x_pt = get_x((2,768,4,7,7))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "from traceback import print_tb\n",
        "from scipy.fftpack import shift\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import LayerNormalization\n",
        "from tensorflow.python.ops.gen_math_ops import imag\n",
        "\n",
        "\n",
        "\n",
        "class BasicLayer(tf.keras.Model):\n",
        "\n",
        "\n",
        "    def __init__(self,dim,shape_of_input,depth,num_heads,window_size=(1,7,7),mlp_ratio=4.,qkv_bias=False,qk_scale=None,drop=0.,attn_drop=0.,drop_path=0.,norm_layer=LayerNormalization,downsample=None,use_checkpoint=False):\n",
        "        super().__init__()\n",
        "\n",
        "        print(self, dim, shape_of_input,depth,num_heads,window_size, mlp_ratio,qkv_bias,qk_scale,drop,attn_drop,drop_path,norm_layer,downsample,use_checkpoint )\n",
        "\n",
        "        self.window_size = window_size\n",
        "        self.shift_size = tuple(i // 2 for i in window_size)\n",
        "        self.depth = depth\n",
        "        self.use_checkpoint = use_checkpoint\n",
        "        self.shape_of_input = shape_of_input\n",
        "\n",
        "        self.compute_mask_info = {\n",
        "            \"shape_of_input\": self.shape_of_input,\n",
        "            \"window_size\": self.window_size, \n",
        "            \"shift_size\": self.shift_size\n",
        "        }\n",
        "\n",
        "        # build \n",
        "        self.blocks = [\n",
        "            SwinTransformerBlock3D(\n",
        "                dim=dim,\n",
        "                compute_mask_info = self.compute_mask_info,\n",
        "                num_heads=num_heads,\n",
        "                window_size=window_size,\n",
        "                shift_size=(0,0,0) if (i % 2 == 0) else self.shift_size,\n",
        "                mlp_ratio=mlp_ratio,\n",
        "                qkv_bias=qkv_bias,\n",
        "                qk_scale=qk_scale,\n",
        "                drop=drop,\n",
        "                attn_drop=attn_drop,\n",
        "                drop_path=drop_path[i] if isinstance(drop_path, list) else drop_path,\n",
        "                norm_layer=norm_layer,\n",
        "                use_checkpoint=use_checkpoint,\n",
        "            )\n",
        "            for i in range(depth)]\n",
        "        \n",
        "        self.downsample = downsample\n",
        "        if self.downsample is not None:\n",
        "            self.downsample = downsample(dim=dim, norm_layer=norm_layer, shape_of_input = self.compute_mask_info['shape_of_input'])\n",
        "\n",
        "        self.outputs = {}\n",
        "\n",
        "    def call(self, x):\n",
        "        \"\"\" Forward function.\n",
        "        Args:\n",
        "            x: Input feature, tensor size (B, C, D, H, W).\n",
        "        \"\"\"\n",
        "        print(self.name, x.shape)\n",
        "\n",
        "        # calculate attention mask for SW-MSA\n",
        "        B, C, D, H, W = tf.shape(x)[0], tf.shape(x)[1], tf.shape(x)[2] , tf.shape(x)[3] , tf.shape(x)[4] \n",
        "\n",
        "        x = tf.transpose(x, perm=[0, 2,3,4, 1 ])\n",
        "        # print()\n",
        "        # print(\"self.compute_mask_info\", self.compute_mask_info)\n",
        "\n",
        "\n",
        "        i = 1\n",
        "        for blk in self.blocks:\n",
        "            x = blk(x)\n",
        "            self.outputs[f\"block_{i}\"] = x\n",
        "            i += 1\n",
        "\n",
        "\n",
        "        x = tf.reshape(x, [B, D, H, W, -1])\n",
        "\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            x = self.downsample(x)\n",
        "        x = tf.transpose(x, perm=[0, 4,1,2,3  ])\n",
        "\n",
        "        return x ,self.outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<__main__.BasicLayer object at 0x000001DE66B7EEE0> 768 (2, 768, 2, 7, 7) 2 24 (8, 7, 7) 4.0 True None 0.4 0.0 [0.0, 0.0] <class 'keras.layers.normalization.layer_normalization.LayerNormalization'> None False\n",
            "3d block 768 {'shape_of_input': (2, 768, 2, 7, 7), 'window_size': (8, 7, 7), 'shift_size': (4, 3, 3)} 24 (8, 7, 7) (0, 0, 0) 4.0 True None 0.4 0.0 0.0 <function gelu at 0x000001DE5DE76EE0> <class 'keras.layers.normalization.layer_normalization.LayerNormalization'> False\n",
            "3d block 768 {'shape_of_input': (2, 768, 2, 7, 7), 'window_size': (8, 7, 7), 'shift_size': (4, 3, 3)} 24 (8, 7, 7) (4, 3, 3) 4.0 True None 0.4 0.0 0.0 <function gelu at 0x000001DE5DE76EE0> <class 'keras.layers.normalization.layer_normalization.LayerNormalization'> False\n",
            "\n",
            "-------------\n",
            "\n",
            "BasicLayer_pt() 768 2 24 (8, 7, 7) 4.0 True None 0.4 0.0 [0.0, 0.0] <class 'torch.nn.modules.normalization.LayerNorm'> None False\n",
            "3d block 768 24 (8, 7, 7) (0, 0, 0) 4.0 True None 0.4 0.0 0.0 <class 'torch.nn.modules.activation.GELU'> <class 'torch.nn.modules.normalization.LayerNorm'> False\n",
            "attention===== 768 (8, 7, 7) 24\n",
            "3d block 768 24 (8, 7, 7) (4, 3, 3) 4.0 True None 0.4 0.0 0.0 <class 'torch.nn.modules.activation.GELU'> <class 'torch.nn.modules.normalization.LayerNorm'> False\n",
            "attention===== 768 (8, 7, 7) 24\n"
          ]
        }
      ],
      "source": [
        "basic4_tf  = BasicLayer(768 ,(2, 768, 2, 7, 7) ,2, 24, (8, 7, 7), 4.0, True, None, 0.4, 0.0, [0.0, 0.0], tf.keras.layers.LayerNormalization , None ,False )\n",
        "print(\"\\n-------------\\n\")\n",
        "basic4_pt = BasicLayer_pt(768 ,2, 24, (8, 7, 7), 4.0, True, None, 0.4, 0.0, [0.0, 0.0],  nn.LayerNorm , None ,False )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "basic_layer_3 (2, 768, 4, 7, 7)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(1, 1, 1, 1, 7), dtype=float32, numpy=\n",
              " array([[[[[ 1.0491765 ,  1.5227097 ,  0.7710688 , -0.10421112,\n",
              "             0.8301559 ,  0.36222416,  0.55345994]]]]], dtype=float32)>,\n",
              " tensor([[[[[ 0.8394,  0.1789,  0.6574,  0.0293, -0.8521,  0.6441,  0.0583]]]]]))"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out_pt , outputs_pt= basic4_pt(x_pt)\n",
        "out_tf, outputs_tf = basic4_tf(x_tf)\n",
        "\n",
        "out_tf[:1,:1,:1,:1,:10], out_pt[:1,:1,:1,:1,:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['blocks.0.norm1.weight', 'blocks.0.norm1.bias', 'blocks.0.attn.relative_position_bias_table', 'blocks.0.attn.relative_position_index', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.norm2.weight', 'blocks.0.norm2.bias', 'blocks.0.mlp.fc1.weight', 'blocks.0.mlp.fc1.bias', 'blocks.0.mlp.fc2.weight', 'blocks.0.mlp.fc2.bias', 'blocks.1.norm1.weight', 'blocks.1.norm1.bias', 'blocks.1.attn.relative_position_bias_table', 'blocks.1.attn.relative_position_index', 'blocks.1.attn.qkv.weight', 'blocks.1.attn.qkv.bias', 'blocks.1.attn.proj.weight', 'blocks.1.attn.proj.bias', 'blocks.1.norm2.weight', 'blocks.1.norm2.bias', 'blocks.1.mlp.fc1.weight', 'blocks.1.mlp.fc1.bias', 'blocks.1.mlp.fc2.weight', 'blocks.1.mlp.fc2.bias'])"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "basic4_pt.eval()\n",
        "\n",
        "np_state_dict = basic4_pt.state_dict()\n",
        "np_state_dict = {k: np_state_dict[k].numpy() for k in np_state_dict}\n",
        "np_state_dict.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_layers = {}\n",
        "def modify_basic_block(np_state_dict, pt_weights_prefix, tf_block):\n",
        "  # PatchMerging\n",
        "  global i\n",
        "  for layer in tf_block:\n",
        "    if isinstance(layer, PatchMerging):\n",
        "      patch_merging_idx = f\"{pt_weights_prefix}.downsample\"\n",
        "  \n",
        "      layer.reduction = modify_tf_block( layer.reduction,\n",
        "                          np_state_dict[f\"{patch_merging_idx}.reduction.weight\"] , wn = f\"{patch_merging_idx}.reduction.weight\")\n",
        "      \n",
        "      layer.norm = modify_tf_block( layer.norm,\n",
        "                        np_state_dict[f\"{patch_merging_idx}.norm.weight\"],\n",
        "                        np_state_dict[f\"{patch_merging_idx}.norm.bias\"],\n",
        "                        \n",
        "                        wn = f\"{patch_merging_idx}.norm.weight\",\n",
        "                        bn = f\"{patch_merging_idx}.norm.bias\"\n",
        "                        )\n",
        "      \n",
        "  # Swin Layers\n",
        "      # Swin layers.\n",
        "  common_prefix = f\"blocks\"\n",
        "  block_idx = 0\n",
        "\n",
        "  for outer_layer in tf_block:\n",
        "\n",
        "      layernorm_idx = 1\n",
        "      mlp_layer_idx = 1\n",
        "\n",
        "      if isinstance(outer_layer, SwinTransformerBlock3D):\n",
        "          for inner_layer in outer_layer.layers:\n",
        "        \n",
        "              # Layer norm.\n",
        "              if isinstance(inner_layer, tf.keras.layers.LayerNormalization):\n",
        "                  #print(\"layer norm\")\n",
        "                  layer_norm_prefix = (\n",
        "                      f\"{common_prefix}.{block_idx}.norm{layernorm_idx}\"\n",
        "                  )\n",
        "                  inner_layer.gamma.assign(\n",
        "                      tf.Variable(\n",
        "                          np_state_dict[f\"{layer_norm_prefix}.weight\"]\n",
        "                      )\n",
        "                  )\n",
        "                #   print(i)\n",
        "                #   i += 1\n",
        "\n",
        "                  model_layers[f\"{layer_norm_prefix}.weight\"] = inner_layer.gamma.name \n",
        "\n",
        "\n",
        "                  inner_layer.beta.assign(\n",
        "                      tf.Variable(np_state_dict[f\"{layer_norm_prefix}.bias\"])\n",
        "                  )\n",
        "                #   print(i)\n",
        "                #   i += 1  \n",
        "                  model_layers[f\"{layer_norm_prefix}.bias\"] = inner_layer.beta.name \n",
        "                  layernorm_idx += 1\n",
        "\n",
        "              # Window attention.\n",
        "              elif isinstance(inner_layer, WindowAttention3D):\n",
        "                  #print(\"window attention\")\n",
        "                  attn_prefix = f\"{common_prefix}.{block_idx}.attn\"\n",
        "\n",
        "                  # Relative position.\n",
        "                  inner_layer.relative_position_bias_table = (\n",
        "                      modify_tf_block(\n",
        "                          inner_layer.relative_position_bias_table,\n",
        "                          np_state_dict[\n",
        "                              f\"{attn_prefix}.relative_position_bias_table\"\n",
        "                          ] ,\n",
        "                          wn =f\"{attn_prefix}.relative_position_bias_table\" ,\n",
        "                      )\n",
        "                  )\n",
        "                  inner_layer.relative_position_index = (\n",
        "                      modify_tf_block(\n",
        "                          inner_layer.relative_position_index,\n",
        "                          np_state_dict[\n",
        "                              f\"{attn_prefix}.relative_position_index\"\n",
        "                          ],\n",
        "                          wn = f\"{attn_prefix}.relative_position_index\"\n",
        "                      )\n",
        "                  )\n",
        "\n",
        "                  # QKV.\n",
        "                  inner_layer.qkv = modify_tf_block(\n",
        "                      inner_layer.qkv,\n",
        "                      np_state_dict[f\"{attn_prefix}.qkv.weight\"],\n",
        "                      np_state_dict[f\"{attn_prefix}.qkv.bias\"],\n",
        "                      wn = f\"{attn_prefix}.qkv.weight\",\n",
        "                       bn = f\"{attn_prefix}.qkv.bias\"\n",
        "                  )\n",
        "\n",
        "                  # Projection.\n",
        "                  inner_layer.proj = modify_tf_block(\n",
        "                      inner_layer.proj,\n",
        "                      np_state_dict[f\"{attn_prefix}.proj.weight\"],\n",
        "                      np_state_dict[f\"{attn_prefix}.proj.bias\"],\n",
        "                      wn = f\"{attn_prefix}.proj.weight\",\n",
        "                      bn = f\"{attn_prefix}.proj.bias\"\n",
        "                  )\n",
        "\n",
        "              # MLP.\n",
        "              elif isinstance(inner_layer, tf.keras.Model):\n",
        "                  #print(\"mlp\")\n",
        "                  mlp_prefix = f\"{common_prefix}.{block_idx}.mlp\"\n",
        "                  for mlp_layer in inner_layer.layers:\n",
        "                      if isinstance(mlp_layer, tf.keras.layers.Dense):\n",
        "                          mlp_layer = modify_tf_block(\n",
        "                              mlp_layer,\n",
        "                              np_state_dict[\n",
        "                                  f\"{mlp_prefix}.fc{mlp_layer_idx}.weight\"\n",
        "                              ],\n",
        "                              np_state_dict[\n",
        "                                  f\"{mlp_prefix}.fc{mlp_layer_idx}.bias\"\n",
        "                              ],\n",
        "                              wn =  f\"{mlp_prefix}.fc{mlp_layer_idx}.weight\" ,\n",
        "                              bn =  f\"{mlp_prefix}.fc{mlp_layer_idx}.bias\"\n",
        "                          )\n",
        "                          mlp_layer_idx += 1\n",
        "\n",
        "          block_idx += 1\n",
        "  return tf_block\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "_ = modify_basic_block(np_state_dict,\n",
        "                            f\"\",\n",
        "                            basic4_tf.layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "basic_layer_3 (2, 768, 4, 7, 7)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(1, 1, 1, 1, 7), dtype=float32, numpy=\n",
              " array([[[[[ 0.43193895,  0.29549426,  0.5472083 , -0.01044163,\n",
              "            -0.09997699,  0.44570723,  0.13647887]]]]], dtype=float32)>,\n",
              " tensor([[[[[ 0.4309,  0.2961,  0.5464, -0.0112, -0.1007,  0.4458,  0.1369]]]]]))"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out_pt , outputs_pt= basic4_pt(x_pt)\n",
        "out_tf, outputs_tf = basic4_tf(x_tf)\n",
        "\n",
        "out_tf[:1,:1,:1,:1,:10], out_pt[:1,:1,:1,:1,:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "162.63649"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rtol = 1e-2\n",
        "etol = 1e-2\n",
        "\n",
        "np.testing.assert_allclose(out_tf.numpy(), out_pt.detach().numpy(), etol, rtol)\n",
        "\n",
        "np.sum(np.absolute(out_tf.numpy() - out_pt.detach().numpy()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "block_1 (2, 4, 7, 7, 768)\n",
            "0.026922584 block_1\n",
            "block_2 (2, 4, 7, 7, 768)\n"
          ]
        },
        {
          "ename": "AssertionError",
          "evalue": "\nNot equal to tolerance rtol=0.0001, atol=0.0001\n\nMismatched elements: 246642 / 301056 (81.9%)\nMax absolute difference: 0.00329328\nMax relative difference: 484.48334\n x: array([[[[[ 4.319389e-01,  6.729322e-01,  7.018082e-01, ...,\n            1.888613e-01,  6.746922e-01,  5.654435e-01],\n          [ 2.954943e-01,  9.648725e-01,  1.154772e-01, ...,...\n y: array([[[[[ 4.308684e-01,  6.721190e-01,  7.019879e-01, ...,\n            1.892169e-01,  6.749927e-01,  5.646459e-01],\n          [ 2.961192e-01,  9.659395e-01,  1.155303e-01, ...,...",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9360/3400556366.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moutputs_tf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs_tf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_allclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs_tf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs_pt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabsolute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs_tf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0moutputs_pt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[1;32mc:\\Python\\Python396\\lib\\site-packages\\numpy\\testing\\_private\\utils.py\u001b[0m in \u001b[0;36massert_array_compare\u001b[1;34m(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf)\u001b[0m\n\u001b[0;32m    844\u001b[0m                                 \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    845\u001b[0m                                 names=('x', 'y'), precision=precision)\n\u001b[1;32m--> 846\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    847\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    848\u001b[0m         \u001b[1;32mimport\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mAssertionError\u001b[0m: \nNot equal to tolerance rtol=0.0001, atol=0.0001\n\nMismatched elements: 246642 / 301056 (81.9%)\nMax absolute difference: 0.00329328\nMax relative difference: 484.48334\n x: array([[[[[ 4.319389e-01,  6.729322e-01,  7.018082e-01, ...,\n            1.888613e-01,  6.746922e-01,  5.654435e-01],\n          [ 2.954943e-01,  9.648725e-01,  1.154772e-01, ...,...\n y: array([[[[[ 4.308684e-01,  6.721190e-01,  7.019879e-01, ...,\n            1.892169e-01,  6.749927e-01,  5.646459e-01],\n          [ 2.961192e-01,  9.659395e-01,  1.155303e-01, ...,..."
          ]
        }
      ],
      "source": [
        "rtol = 1e-4\n",
        "etol = 1e-4\n",
        "\n",
        "for layer in outputs_tf:\n",
        "    print(layer, outputs_tf[layer].shape)\n",
        "    np.testing.assert_allclose(outputs_tf[layer].numpy(), outputs_pt[layer].detach().numpy(), etol, rtol)\n",
        "\n",
        "    print( np.sum(np.absolute(outputs_tf[layer].numpy() - outputs_pt[layer].detach().numpy())), layer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5yLk_n3J5JR"
      },
      "source": [
        "# Patch Embed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kum9GK-cfsVD"
      },
      "outputs": [],
      "source": [
        "pt_model.eval()\n",
        "np_state_dict = pt_model.state_dict()\n",
        "np_state_dict = {k: np_state_dict[k].numpy() for k in np_state_dict}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZzjJrGLQVQT"
      },
      "source": [
        "## Conv3D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0bjaD6xHCfV"
      },
      "outputs": [],
      "source": [
        "patch_size = (2, 4,4)\n",
        "embed_dim = 96\n",
        "window_size = (8, 7, 7)\n",
        "layer_norm = tf.keras.layers.LayerNormalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1E_un3nUIVxp"
      },
      "outputs": [],
      "source": [
        "tf_conv3D = tf.keras.layers.Conv3D(embed_dim, kernel_size = patch_size, strides= patch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-KVutaoInrB"
      },
      "outputs": [],
      "source": [
        "pt_conv3D = nn.Conv3d(3, embed_dim, kernel_size = patch_size, stride= patch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FP6XiJJJdWN"
      },
      "outputs": [],
      "source": [
        "x_tf, x_pt = get_x()\n",
        "x_tf = tf.transpose(x_tf, perm=(0,2,3,4,1))\n",
        "\n",
        "output_of_conv3d_tf = tf_conv3D(x_tf)\n",
        "output_of_conv3d_pt = pt_conv3D(x_pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lo6T32ESKxJI",
        "outputId": "a70296d5-a549-40f9-8884-18bd0d5fab91"
      },
      "outputs": [],
      "source": [
        "pt_conv3D.eval()\n",
        "np_state_dict = pt_conv3D.state_dict()\n",
        "np_state_dict = {k: np_state_dict[k].numpy() for k in np_state_dict}\n",
        "np_state_dict.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SR4J2cyyKPaP",
        "outputId": "c0c2c86e-39d2-4e59-baa4-b5ff6886af2e"
      },
      "outputs": [],
      "source": [
        "tf_conv3D = modify_tf_block(tf_conv3D, np_state_dict[\"weight\"], np_state_dict[\"bias\"])\n",
        "tf_conv3D.weights[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SJLJUZsMYoh"
      },
      "outputs": [],
      "source": [
        "x_tf, x_pt = get_x()\n",
        "x_tf = tf.transpose(x_tf, perm=(0,2,3,4,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4GoqAdWNaoR"
      },
      "outputs": [],
      "source": [
        "output_of_conv3d_tf = tf_conv3D(x_tf)\n",
        "output_of_conv3d_tf = tf.transpose(output_of_conv3d_tf, perm=[0, 4, 1, 2,3 ])\n",
        "\n",
        "output_of_conv3d_pt = pt_conv3D(x_pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnSCkGwiOYqe",
        "outputId": "70194f8e-341b-4edb-ef08-11ec7e687515"
      },
      "outputs": [],
      "source": [
        "output_of_conv3d_tf[:1,:1,:1,:1,:10] , output_of_conv3d_pt[:1,:1,:1,:1,:10] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_of_conv3d_tf[:1,:1,:1,:1,:10] , output_of_conv3d_pt[:1,:1,:1,:1,:10] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ar5sWDMMNdpo"
      },
      "outputs": [],
      "source": [
        "rtol = 1e-4\n",
        "etol = 1e-4\n",
        "\n",
        "np.testing.assert_allclose(output_of_conv3d_tf.numpy(), output_of_conv3d_pt.detach().numpy(), etol, rtol)\n",
        "\n",
        "np.sum(np.absolute(output_of_conv3d_tf.numpy() - output_of_conv3d_pt.detach().numpy()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rtFNKvjZ7hZ"
      },
      "source": [
        "## Norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "McostjEeZ96Z"
      },
      "outputs": [],
      "source": [
        "tf_norm = layer_norm(epsilon = 1e-5)\n",
        "pt_norm = nn.LayerNorm(embed_dim)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4aiCq-GNmUd",
        "outputId": "43933759-76a4-4c2a-f01c-2e7918ebea85"
      },
      "outputs": [],
      "source": [
        "B, C, D, Wh, Ww = output_of_conv3d_tf.shape\n",
        "input_norm_tf  = tf.reshape(output_of_conv3d_tf, shape=[B, C, -1]) \n",
        "input_norm_tf = tf.transpose(input_norm_tf, perm=[0 , 2, 1]) \n",
        "\n",
        "norm_layer_output_tf = tf_norm(input_norm_tf)\n",
        "norm_layer_output_tf   = tf.transpose(norm_layer_output_tf, perm=[0,2,1])\n",
        "norm_layer_output_tf = tf.reshape(norm_layer_output_tf, shape=[-1, embed_dim, D, Wh, Ww])\n",
        "\n",
        "_, _, D, Wh, Ww = output_of_conv3d_pt.size()\n",
        "input_norm_pt =  output_of_conv3d_pt.flatten(2).transpose(1, 2)\n",
        "norm_layer_output_pt = pt_norm(input_norm_pt)\n",
        "print(norm_layer_output_pt.shape)\n",
        "norm_layer_output_pt = norm_layer_output_pt.transpose(1, 2).view(-1, embed_dim, D, Wh, Ww)\n",
        "\n",
        "norm_layer_output_pt.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4C7U_mCGcK_V",
        "outputId": "f2c99014-106b-4fcb-f91b-bc36ee9440a1"
      },
      "outputs": [],
      "source": [
        "pt_norm.eval()\n",
        "np_state_dict = pt_norm.state_dict()\n",
        "np_state_dict = {k: np_state_dict[k].numpy() for k in np_state_dict}\n",
        "np_state_dict.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SaloZesWTltO",
        "outputId": "5d3322b7-d111-450e-c322-19431aad42eb"
      },
      "outputs": [],
      "source": [
        "tf_norm = modify_tf_block(tf_norm, np_state_dict[\"weight\"], np_state_dict[\"bias\"])\n",
        "tf_norm.weights[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zrz2rYO1cYqX",
        "outputId": "6c03db1a-0a3f-4f38-bc3e-3eb400724a6f"
      },
      "outputs": [],
      "source": [
        "B, C, D, Wh, Ww = output_of_conv3d_tf.shape\n",
        "norm_layer_output_tf = tf_norm(input_norm_tf)\n",
        "norm_layer_output_tf   = tf.transpose(norm_layer_output_tf, perm=[0,2,1])\n",
        "norm_layer_output_tf = tf.reshape(norm_layer_output_tf, shape=[-1, embed_dim, D, Wh, Ww])\n",
        "\n",
        "_, _, D, Wh, Ww = output_of_conv3d_pt.size()\n",
        "norm_layer_output_pt = pt_norm(input_norm_pt)\n",
        "print(norm_layer_output_pt.shape)\n",
        "\n",
        "norm_layer_output_pt = norm_layer_output_pt.transpose(1, 2).view(-1, embed_dim, D, Wh, Ww)\n",
        "\n",
        "norm_layer_output_pt.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6nZO8fLcyjT"
      },
      "outputs": [],
      "source": [
        "rtol = 1e-4\n",
        "etol = 1e-4\n",
        "# asserts error at 1e-7\n",
        "\n",
        "np.testing.assert_allclose(norm_layer_output_tf.numpy(), norm_layer_output_pt.detach().numpy(), etol, rtol)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vn3AlveBxhzJ"
      },
      "source": [
        "## SwinTransformerBlock3D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_bV_Ua7x2kg"
      },
      "outputs": [],
      "source": [
        "dim= 96\n",
        "compute_mask_info={'shape_of_input': (2, 96, 2, 56, 56), 'window_size': (8, 7, 7), 'shift_size': (4, 3, 3)} \n",
        "num_heads=3\n",
        "window_size=   (8, 7, 7) \n",
        "shift_size= (0, 0, 0)\n",
        "mlp_ratio=  4.0\n",
        "qkv_bias= True\n",
        "qk_scale= None\n",
        "drop= 0.0\n",
        "attn_drop= 0.0\n",
        "drop_path = 0.0\n",
        "act_layer = tf.keras.activations.gelu \n",
        "norm_layer = tf.keras.layers.LayerNormalization\n",
        "use_checkpoint=False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NctH8unuLNA"
      },
      "source": [
        "define input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WM9rkpVic207"
      },
      "outputs": [],
      "source": [
        "basic_layer_input_tf = tf.transpose(norm_layer_output_tf, perm=[0, 2,3,4, 1 ])\n",
        "\n",
        "# norm_layer_output_pt= norm_layer_output_pt.contiguous()\n",
        "\n",
        "B, C, D, H, W = norm_layer_output_pt.shape\n",
        "basic_layer_input_pt = rearrange(norm_layer_output_pt, 'b c d h w -> b d h w c ')\n",
        "basic_layer_input_pt.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ilt9Kstauq0b",
        "outputId": "09c51923-d041-4a99-9e07-80e64d1a92a8"
      },
      "outputs": [],
      "source": [
        "basic_layer_input_tf, basic_layer_input_pt = get_x((2,4,56,56,96))\n",
        "basic_layer_input_tf.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddwS8Ck9BiV5"
      },
      "outputs": [],
      "source": [
        "Dp = int(np.ceil(D / window_size[0])) * window_size[0]\n",
        "Hp = int(np.ceil(H / window_size[1])) * window_size[1]\n",
        "Wp = int(np.ceil(W / window_size[2])) * window_size[2]\n",
        "attn_mask_pt = compute_mask_pt(Dp, Hp, Wp, window_size, shift_size, basic_layer_input_pt.device)\n",
        "\n",
        "attn_mask_pt.shape, Dp, Hp, Wp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-E_hBOfq1zat"
      },
      "outputs": [],
      "source": [
        "##@title SwinTransformerBlock3D tf\n",
        "\n",
        "from tensorflow.keras.layers import LayerNormalization\n",
        "import numpy as np\n",
        "\n",
        "class SwinTransformerBlock3D(tf.keras.Model):\n",
        "    def __init__(self, dim, compute_mask_info, num_heads, window_size=(2,7,7), shift_size=(0,0,0),\n",
        "                 mlp_ratio=4., qkv_bias=True, qk_scale=None, drop=0., attn_drop=0., drop_path=0.,\n",
        "                 act_layer=tf.keras.activations.gelu, norm_layer=LayerNormalization, use_checkpoint=False):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "        self.num_heads = num_heads\n",
        "        self.window_size = window_size\n",
        "        self.shift_size = shift_size\n",
        "        self.mlp_ratio = mlp_ratio\n",
        "        self.use_checkpoint=use_checkpoint\n",
        "        self.compute_mask_info = compute_mask_info\n",
        "\n",
        "        self.layer_wise_output = {}\n",
        "        \n",
        "        assert 0 <= self.shift_size[0] < self.window_size[0], \"shift_size must in 0-window_size\"\n",
        "        assert 0 <= self.shift_size[1] < self.window_size[1], \"shift_size must in 0-window_size\"\n",
        "        assert 0 <= self.shift_size[2] < self.window_size[2], \"shift_size must in 0-window_size\"\n",
        "\n",
        "        self.norm1 = norm_layer(axis=-1, epsilon=1e-5)\n",
        "\n",
        "        self.attn = WindowAttention3D(\n",
        "            dim, window_size=self.window_size, num_heads=num_heads,\n",
        "            qkv_bias=qkv_bias, qk_scale=qk_scale, attn_drop=attn_drop, proj_drop=drop)\n",
        "\n",
        "        # compute mask\n",
        "        print(compute_mask_info)\n",
        "        mask_window_size, mask_shift_size = get_window_size((4,56,56), self.compute_mask_info[\"window_size\"], self.compute_mask_info[\"shift_size\"])\n",
        "        \n",
        "\n",
        "        Dp = int(tf.math.ceil(D/ mask_window_size[0])) * mask_window_size[0]\n",
        "        Hp = int(tf.math.ceil(H / mask_window_size[1])) * mask_window_size[1]\n",
        "        Wp = int(tf.math.ceil(W / mask_window_size[2])) * mask_window_size[2]\n",
        "\n",
        "        self.attn_mask = compute_mask(Dp, Hp, Wp, mask_window_size, mask_shift_size)\n",
        "        print(self.attn_mask.shape)\n",
        "        self.drop_path = DropPath(drop_path) if drop_path > 0. else tf.identity\n",
        "        self.norm2 = norm_layer(epsilon=1e-5)\n",
        "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
        "        self.mlp = mlp_block(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)\n",
        "\n",
        "    def forward_part1(self, x):\n",
        "        \n",
        "        B, D, H, W, C = tf.shape(x)[0], tf.shape(x)[1], tf.shape(x)[2] , tf.shape(x)[3] , tf.shape(x)[4] \n",
        "        b, c, d, h ,w = self.compute_mask_info['shape_of_input']\n",
        "\n",
        "        #####\n",
        "        print(\"window pt\",self.window_size, self.shift_size)\n",
        "        window_size, shift_size = get_window_size((D , H, w), self.window_size, self.shift_size)\n",
        "        print(window_size, shift_size)\n",
        "\n",
        "        x = self.norm1(x)\n",
        "        self.layer_wise_output[\"norm1\"] = x[:]\n",
        "        print(\"norm\", x.shape)\n",
        "\n",
        "        pad_l = pad_t = pad_d0 = 0\n",
        "        pad_d1 = (window_size[0] - D % window_size[0]) % window_size[0]\n",
        "        pad_b = (window_size[1] - H % window_size[1]) % window_size[1]\n",
        "        pad_r = (window_size[2] - W % window_size[2]) % window_size[2]\n",
        "        paddings = [[0,0] , [pad_d0, pad_d1] , [pad_t, pad_b] , [pad_l, pad_r], [0, 0] ]\n",
        "\n",
        "        x = tf.pad(x, paddings)\n",
        "        self.layer_wise_output[\"pad_feature_map\"] = x[:]\n",
        "        print(\"padding\", x.shape)\n",
        "\n",
        "\n",
        "        _, Dp, Hp, Wp, _ = tf.shape(x)[0], tf.shape(x)[1], tf.shape(x)[2] , tf.shape(x)[3] , tf.shape(x)[4] \n",
        "\n",
        "        # cyclic shift\n",
        "        # print(self.shift_size)\n",
        "        if any(i > 0 for i in self.shift_size):\n",
        "            shifted_x = tf.roll(x, shift=[-self.shift_size[0], -self.shift_size[1], -self.shift_size[2]], axis=[1, 2, 3]) #?\n",
        "            attn_mask = self.attn_mask\n",
        "            print(\"inside any cyclic shift\")\n",
        "        else:\n",
        "            shifted_x = x\n",
        "            attn_mask = None\n",
        "\n",
        "        print(\"shifted_x\", x.shape)\n",
        "        self.layer_wise_output[\"shifted_x\"] = shifted_x[:]\n",
        "        self.layer_wise_output[\"attn_mask\"] = attn_mask\n",
        "\n",
        "        print(\"window_partion\",shifted_x.shape, window_size)\n",
        "        x_windows = window_partition(shifted_x, window_size)  # B*nW, Wd*Wh*Ww, C\n",
        "        \n",
        "        self.layer_wise_output[\"partion_windows\"] = x_windows[:]\n",
        "\n",
        "        attn_windows = self.attn(x_windows, mask=attn_mask)  # B*nW, Wd*Wh*Ww, C\n",
        "        attn_windows = tf.reshape( attn_windows ,  [-1, *(window_size+(C,))] )\n",
        "        shifted_x = window_reverse(attn_windows, window_size, B, Dp, Hp, Wp)  # B D' H' W' C\n",
        "\n",
        "        if any(i > 0 for i in self.shift_size):\n",
        "            x = tf.roll(shifted_x, shift=[self.shift_size[0], self.shift_size[1], self.shift_size[2]], axis=[1, 2, 3]) #?\n",
        "        else:\n",
        "            x = shifted_x\n",
        "        self.layer_wise_output[\"reverse cyclic shift\"] = x[:]\n",
        "        \n",
        "\n",
        "        if pad_d1 >0 or pad_r > 0 or pad_b > 0:\n",
        "            x = x[:, :D, :H, :W, :]\n",
        "        return x\n",
        "\n",
        "    def forward_part2(self, x):\n",
        "        return self.drop_path(self.mlp(self.norm2(x)))\n",
        "\n",
        "    def call(self, x):\n",
        "        layer_wise_output = {}\n",
        "\n",
        "        shortcut = x\n",
        "        x = self.forward_part1(x)\n",
        "        x = shortcut + self.drop_path(x)\n",
        "        x = x + self.forward_part2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wekG8TIf5MsI",
        "outputId": "d2682d56-422c-449b-9088-dc52357b55cd"
      },
      "outputs": [],
      "source": [
        "swin_block3d_tf_1 = SwinTransformerBlock3D(dim, compute_mask_info, num_heads, window_size, shift_size,\n",
        "                 mlp_ratio, qkv_bias, qk_scale, drop, attn_drop, drop_path,\n",
        "                 act_layer, norm_layer, use_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "l4xe5EoH-_a0"
      },
      "outputs": [],
      "source": [
        "#@title SwinTransformerBlock3D pt\n",
        "\n",
        "class SwinTransformerBlock3D_pt(nn.Module):\n",
        "\n",
        "    def __init__(self, dim, num_heads, window_size=(2,7,7), shift_size=(0,0,0),\n",
        "                 mlp_ratio=4., qkv_bias=True, qk_scale=None, drop=0., attn_drop=0., drop_path=0.,\n",
        "                 act_layer=nn.GELU, norm_layer=nn.LayerNorm, use_checkpoint=False):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "        self.num_heads = num_heads\n",
        "        self.window_size = window_size\n",
        "        self.shift_size = shift_size\n",
        "        self.mlp_ratio = mlp_ratio\n",
        "        self.use_checkpoint=use_checkpoint\n",
        "\n",
        "        self.layer_wise_output = {}\n",
        "        assert 0 <= self.shift_size[0] < self.window_size[0], \"shift_size must in 0-window_size\"\n",
        "        assert 0 <= self.shift_size[1] < self.window_size[1], \"shift_size must in 0-window_size\"\n",
        "        assert 0 <= self.shift_size[2] < self.window_size[2], \"shift_size must in 0-window_size\"\n",
        "\n",
        "        self.norm1 = norm_layer(dim)\n",
        "        self.attn = WindowAttention3D_pt(\n",
        "            dim, window_size=self.window_size, num_heads=num_heads,\n",
        "            qkv_bias=qkv_bias, qk_scale=qk_scale, attn_drop=attn_drop, proj_drop=drop)\n",
        "\n",
        "        self.drop_path = DropPath_pt(drop_path) if drop_path > 0. else nn.Identity()\n",
        "        self.norm2 = norm_layer(dim)\n",
        "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
        "        self.mlp = Mlp_pt(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)\n",
        "\n",
        "    def forward_part1(self, x, mask_matrix):\n",
        "        B, D, H, W, C = x.shape\n",
        "        print(\"window pt\",self.window_size, self.shift_size)\n",
        "        print(D,H,W)\n",
        "        window_size, shift_size = get_window_size_pt((D, H, W), self.window_size, self.shift_size)\n",
        "        print(window_size, shift_size)\n",
        "        \n",
        "        x = self.norm1(x)\n",
        "\n",
        "        self.layer_wise_output[\"norm1\"] = x[:]\n",
        "\n",
        "        # pad feature maps to multiples of window size\n",
        "        pad_l = pad_t = pad_d0 = 0\n",
        "        pad_d1 = (window_size[0] - D % window_size[0]) % window_size[0]\n",
        "        pad_b = (window_size[1] - H % window_size[1]) % window_size[1]\n",
        "        pad_r = (window_size[2] - W % window_size[2]) % window_size[2]\n",
        "        x = F.pad(x, (0, 0, pad_l, pad_r, pad_t, pad_b, pad_d0, pad_d1))\n",
        "\n",
        "        self.layer_wise_output[\"pad_feature_map\"] = x[:]\n",
        "\n",
        "\n",
        "        _, Dp, Hp, Wp, _ = x.shape\n",
        "        # cyclic shift\n",
        "        if any(i > 0 for i in shift_size):\n",
        "            shifted_x = torch.roll(x, shifts=(-shift_size[0], -shift_size[1], -shift_size[2]), dims=(1, 2, 3))\n",
        "            attn_mask = mask_matrix\n",
        "        else:\n",
        "            print(\"else\",x.shape)\n",
        "            shifted_x = x\n",
        "            attn_mask = None\n",
        "\n",
        "        self.layer_wise_output[\"shifted_x\"] = shifted_x[:]\n",
        "        self.layer_wise_output[\"attn_mask\"] = attn_mask\n",
        "        # partition windows\n",
        "        print(\"window_partion\",shifted_x.shape, window_size)\n",
        "        x_windows = window_partition_pt(shifted_x, window_size)  # B*nW, Wd*Wh*Ww, C\n",
        "        self.layer_wise_output[\"partion_windows\"] = x_windows[:]\n",
        "        \n",
        "        # W-MSA/SW-MSA\n",
        "        attn_windows = self.attn(x_windows, mask=attn_mask)  # B*nW, Wd*Wh*Ww, C\n",
        "        # merge windows\n",
        "        attn_windows = attn_windows.view(-1, *(window_size+(C,)))\n",
        "        shifted_x = window_reverse_pt(attn_windows, window_size, B, Dp, Hp, Wp)  # B D' H' W' C\n",
        "        # reverse cyclic shift\n",
        "        if any(i > 0 for i in shift_size):\n",
        "            x = torch.roll(shifted_x, shifts=(shift_size[0], shift_size[1], shift_size[2]), dims=(1, 2, 3))\n",
        "        else:\n",
        "            x = shifted_x\n",
        "        self.layer_wise_output[\"reverse cyclic shift\"] = x[:]\n",
        "\n",
        "        if pad_d1 >0 or pad_r > 0 or pad_b > 0:\n",
        "            x = x[:, :D, :H, :W, :].contiguous()\n",
        "        return x\n",
        "\n",
        "    def forward_part2(self, x):\n",
        "        return self.drop_path(self.mlp(self.norm2(x)))\n",
        "\n",
        "    def forward(self, x, mask_matrix):\n",
        "\n",
        "\n",
        "        shortcut = x\n",
        "        if self.use_checkpoint:\n",
        "            x = checkpoint.checkpoint(self.forward_part1, x, mask_matrix)\n",
        "        else:\n",
        "            x = self.forward_part1(x, mask_matrix)\n",
        "\n",
        "        x = shortcut + self.drop_path(x)\n",
        "\n",
        "        if self.use_checkpoint:\n",
        "            x = x + checkpoint.checkpoint(self.forward_part2, x)\n",
        "        else:\n",
        "            x = x + self.forward_part2(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xa7t0xPTA362",
        "outputId": "8e69caef-a576-42ef-99ac-c32b33b4b3b3"
      },
      "outputs": [],
      "source": [
        "swin_block3d_pt_1 = SwinTransformerBlock3D_pt(dim , num_heads, window_size, shift_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__0WpDL5Jbbu",
        "outputId": "8a979129-94f0-4297-a06b-1c01eab330c2"
      },
      "outputs": [],
      "source": [
        "swin_block3d_tf_1_output = swin_block3d_tf_1(basic_layer_input_tf)\n",
        "print()\n",
        "swin_block3d_pt_1_output = swin_block3d_pt_1(basic_layer_input_pt, attn_mask_pt)\n",
        "\n",
        "swin_block3d_tf_1_output[:1,:1,:1,:1,:10], swin_block3d_pt_1_output[:1,:1,:1,:1,:10] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TB-PcMAG0sI",
        "outputId": "00bd9e97-18b6-41e1-aee8-f3fb591e65ab"
      },
      "outputs": [],
      "source": [
        "swin_block3d_tf_1_output = swin_block3d_tf_1(basic_layer_input_tf)\n",
        "print()\n",
        "swin_block3d_pt_1_output = swin_block3d_pt_1(basic_layer_input_pt, attn_mask_pt)\n",
        "\n",
        "swin_block3d_tf_1_output[:1,:1,:1,:1,:10], swin_block3d_pt_1_output[:1,:1,:1,:1,:10] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-kjGXDSFuTF",
        "outputId": "84adca12-1d97-4385-a808-b488a3497475"
      },
      "outputs": [],
      "source": [
        "swin_block3d_pt_1.eval()\n",
        "np_state_dict = swin_block3d_pt_1.state_dict()\n",
        "np_state_dict = {k: np_state_dict[k].numpy() for k in np_state_dict}\n",
        "np_state_dict.keys()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6Gu5fNWUuGz",
        "outputId": "18ce5fa9-e3ba-4c19-cadb-71c87e84b52a"
      },
      "outputs": [],
      "source": [
        "swinBlockWeights = {}\n",
        "ptModelWeights = pt_model.state_dict()\n",
        "for layer in ptModelWeights:\n",
        "  if \"layers.0.blocks.0\" in layer:\n",
        "    swinBlockWeights[layer[18:]] = ptModelWeights[layer]\n",
        "swinBlockWeights.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spNZBCxLVBsr",
        "outputId": "52a54e68-b079-4df3-a003-7d0cd6b0794e"
      },
      "outputs": [],
      "source": [
        "swin_block3d_pt_1.load_state_dict(swinBlockWeights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXu1aIrpXO5O",
        "outputId": "53e2abb3-8db5-4a05-fcdd-3af29161b9b5"
      },
      "outputs": [],
      "source": [
        "_ = modify_swin_block3D(np_state_dict,\n",
        "                            f\"\",\n",
        "                            swin_block3d_tf_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTcHWfmBkB8J",
        "outputId": "f26dcc74-6292-4652-927a-26c4c9deb26a"
      },
      "outputs": [],
      "source": [
        "swin_block3d_tf_1_output = swin_block3d_tf_1(basic_layer_input_tf)\n",
        "swin_block3d_pt_1_output = swin_block3d_pt_1(basic_layer_input_pt, attn_mask_pt)\n",
        "\n",
        "swin_block3d_tf_1_output[:1,:1,:1,:1,:10], swin_block3d_pt_1_output[:1,:1,:1,:1,:10] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sD0_myB13NoI",
        "outputId": "0397a14e-c9dc-4ef8-b3c6-2c1a21a8745c"
      },
      "outputs": [],
      "source": [
        "block3D_layers_output_tf = swin_block3d_tf_1.layer_wise_output\n",
        "block3D_layers_output_pt = swin_block3d_pt_1.layer_wise_output\n",
        "print(block3D_layers_output_pt[\"attn_mask\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_71bHAJ3YGV",
        "outputId": "bd79b41d-9edf-4c00-feb5-33b31dd6c779"
      },
      "outputs": [],
      "source": [
        "rtol = 1e-4\n",
        "etol = 1e-4\n",
        "# asserts error at 1e-7\n",
        "for layer in block3D_layers_output_pt:\n",
        "  print(\"\\n\",layer, end=\"\")\n",
        "  if block3D_layers_output_tf[layer] is None and block3D_layers_output_pt[layer] is None:\n",
        "    continue\n",
        "  np.testing.assert_allclose(block3D_layers_output_tf[layer].numpy(), block3D_layers_output_pt[layer].detach().numpy(), etol, rtol)\n",
        "  print(\" has passed the test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNQKicp-ttoF"
      },
      "outputs": [],
      "source": [
        "rtol = 1e-4\n",
        "etol = 1e-4\n",
        "# asserts error at 1e-7\n",
        "\n",
        "np.testing.assert_allclose(swin_block3d_tf_1_output.numpy(), swin_block3d_pt_1_output.detach().numpy(), etol, rtol)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8g-XH502kIWb"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "def get_window_size(x_size, window_size, shift_size=None):\n",
        "    #print(\"get window\",x_size, window_size, shift_size)\n",
        "    use_window_size = list(window_size)\n",
        "    if shift_size is not None:\n",
        "        use_shift_size = list(shift_size)\n",
        "    for i in range(len(x_size)):\n",
        "        if x_size[i] <= window_size[i]:\n",
        "            use_window_size[i] = x_size[i]\n",
        "            if shift_size is not None:\n",
        "                use_shift_size[i] = 0\n",
        "\n",
        "\n",
        "\n",
        "    if shift_size is None:\n",
        "        return tuple(use_window_size)\n",
        "    else:\n",
        "        return tuple(use_window_size), tuple(use_shift_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6-8mzRbmOG7",
        "outputId": "f5eb4f7d-fd16-45d7-9b86-067cf3484860"
      },
      "outputs": [],
      "source": [
        "get_window_size((4,56,56), (8,7,7), (0,0,0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "def get_window_size(x_size, window_size, shift_size=None):\n",
        "    #print(\"get window\",x_size, window_size, shift_size)\n",
        "\n",
        "    print(\"get_window_size parameters\",x_size, window_size, shift_size)\n",
        "\n",
        "    use_window_size = list(window_size)\n",
        "    if shift_size is not None:\n",
        "        use_shift_size = list(shift_size)\n",
        "    for i in range(len(x_size)):\n",
        "        if x_size[i] <= window_size[i]:\n",
        "            use_window_size[i] = x_size[i]\n",
        "            if shift_size is not None:\n",
        "                use_shift_size[i] = 0\n",
        "\n",
        "\n",
        "\n",
        "    if shift_size is None:\n",
        "        return tuple(use_window_size)\n",
        "    else:\n",
        "        print(tuple(use_window_size), tuple(use_shift_size))\n",
        "        return tuple(use_window_size), tuple(use_shift_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "get_window_size((4,56,56), (8,7,7), (4,3,3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnEpDrI6I5ZP"
      },
      "source": [
        "# Windows Partition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_d25LPN6IiZs"
      },
      "outputs": [],
      "source": [
        "x_tf , x_pt = get_x((2, 6, 56, 56, 96))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fp_G2gI5JKKv"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from functools import reduce\n",
        "\n",
        "\n",
        "def window_partition(x, window_size):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        x: (B, D, H, W, C)\n",
        "        window_size (tuple[int]): window size\n",
        "    Returns:\n",
        "        windows: (B*num_windows, window_size*window_size, C)\n",
        "    \"\"\"\n",
        "    B, D, H, W, C = tf.shape(x)[0], tf.shape(x)[1], tf.shape(x)[2], tf.shape(x)[3] , tf.shape(x)[4] \n",
        "    \n",
        "    x = tf.reshape(x, [B, D // window_size[0], window_size[0], H // window_size[1], window_size[1], W // window_size[2], window_size[2], C])\n",
        "\n",
        "    windows = tf.reshape(tf.transpose(x, perm=[0, 1, 3, 5, 2, 4, 6, 7]), [-1, reduce((lambda x, y: x * y), window_size), C])  \n",
        "                             \n",
        "                                               \n",
        "    return windows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "3jvyoPgPJKN6",
        "outputId": "d992a866-17e4-4fd4-d8e7-c0fa1fa4c854"
      },
      "outputs": [],
      "source": [
        "window_partition(x_tf, (4,7,7))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_p1RLl6gN1HR"
      },
      "source": [
        "# cehck attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJHSnyUDN29_"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "import numpy as np\n",
        "\n",
        "class WindowAttention3D(tf.keras.layers.Layer):\n",
        "    def __init__(self, dim, window_size, num_heads, qkv_bias=True, qk_scale=None, attn_drop=0., proj_drop=0.):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "        self.window_size = window_size\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        self.scale = qk_scale or head_dim ** -0.5\n",
        "\n",
        "        print(\"win attn params\",dim, window_size, num_heads)\n",
        "\n",
        "        self.qkv = Dense(dim * 3, use_bias=qkv_bias)\n",
        "        self.attn_drop = Dropout(attn_drop)\n",
        "        self.proj = Dense(dim)\n",
        "        self.proj_drop = Dropout(proj_drop)\n",
        "\n",
        "\n",
        "    def build(self, shape_of_input):\n",
        "        self.relative_position_bias_table = self.add_weight(shape=((2 * self.window_size[0] - 1) * (2 * self.window_size[1] - 1)* (2 * self.window_size[2] - 1), self.num_heads),\n",
        "                                                            initializer=tf.initializers.Zeros(), trainable=True, name=\"relative_position_bias_table\") # 2*Wd-1 * 2*Wh-1 * 2*Ww-1, nH\n",
        "\n",
        "        coords_d = np.arange(self.window_size[0])\n",
        "        coords_h = np.arange(self.window_size[1])\n",
        "        coords_w = np.arange(self.window_size[2])\n",
        "        coords = np.stack(np.meshgrid(coords_d, coords_h, coords_w, indexing='ij')) # 3, Wd, Wh, Ww\n",
        "        coords_flatten = coords.reshape(3, -1)\n",
        "        relative_coords = coords_flatten[:, :,\n",
        "                                         None] - coords_flatten[:, None, :]\n",
        "        relative_coords = relative_coords.transpose([1, 2, 0])\n",
        "        relative_coords[:, :, 0] += self.window_size[0] - 1\n",
        "        relative_coords[:, :, 1] += self.window_size[1] - 1\n",
        "        relative_coords[:, :, 2] += self.window_size[2] - 1\n",
        "\n",
        "        relative_coords[:, :, 0] *= (2 * self.window_size[1] - 1) * (2 * self.window_size[2] - 1)\n",
        "        relative_coords[:, :, 1] *= (2 * self.window_size[2] - 1)\n",
        "        relative_position_index = relative_coords.sum(-1).astype(np.int64)\n",
        "        \n",
        "\n",
        "        self.relative_position_index = tf.Variable(initial_value=tf.convert_to_tensor(\n",
        "            relative_position_index), trainable=False)\n",
        "        self.built = True\n",
        "\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        # #print(x.shape, \"attention\")\n",
        "        B_, N, C = tf.shape(x)[0], tf.shape(x)[1], tf.shape(x)[2]\n",
        "        qkv = tf.transpose(tf.reshape(self.qkv(\n",
        "            x), shape=[-1, N, 3, self.num_heads, C // self.num_heads]), perm=[2, 0, 3, 1, 4])\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
        "\n",
        "        q = q * self.scale\n",
        "        attn = (q @ tf.transpose(k, perm=[0, 1, 3, 2]))\n",
        "        index = tf.reshape(self.relative_position_index[:N, :N], shape=[-1])\n",
        "        relative_position_bias = tf.gather(self.relative_position_bias_table, index)\n",
        "        relative_position_bias = tf.reshape(relative_position_bias, shape=[N, N, -1])\n",
        "        relative_position_bias = tf.transpose(relative_position_bias, perm=[2, 0, 1])\n",
        "        attn = attn + tf.expand_dims(relative_position_bias, axis=0)\n",
        "\n",
        "        if mask is not None:\n",
        "\n",
        "\n",
        "            nW = tf.shape(mask)[0]  # tf.shape(mask)[0]\n",
        "            attn = tf.reshape(attn, shape=[-1, nW, self.num_heads, N, N]) + tf.cast(\n",
        "                tf.expand_dims(tf.expand_dims(mask, axis=1), axis=0), attn.dtype)\n",
        "\n",
        "            attn = tf.reshape(attn, shape=[-1, self.num_heads, N, N])\n",
        "            attn = tf.nn.softmax(attn, axis=-1)\n",
        "        else:\n",
        "            attn = tf.nn.softmax(attn, axis=-1)\n",
        "\n",
        "        attn = self.attn_drop(attn)\n",
        "\n",
        "        x = tf.transpose((attn @ v), perm=[0, 2, 1, 3])\n",
        "        x = tf.reshape(x, shape=[-1, N, C])\n",
        "        x = self.proj(x)\n",
        "        x = self.proj_drop(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8zSZkw6N4vG"
      },
      "outputs": [],
      "source": [
        "atten = WindowAttention3D(96, (8,7,7),3 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUjNLYPHOHI9"
      },
      "outputs": [],
      "source": [
        "x_tf, x_pt = get_x((64,196,96))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79dxL-pTOP4u"
      },
      "outputs": [],
      "source": [
        "atten(x_tf, tf.zeros((64,98,98)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQw4_ZHCQyMP"
      },
      "outputs": [],
      "source": [
        "atten = WindowAttention3D_pt(96, (8,7,7),3 )\n",
        "atten(x_pt, torch.zeros((64,98,98)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faH5phoxI73W"
      },
      "source": [
        "# practice"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "D5yLk_n3J5JR"
      ],
      "name": "Block wise  check swin.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "5ed124f2b279c186db57d0ede455df2b109954ad4fa1a5a2c59adb747c894aa2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
