{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install  -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "from VideoSwinTransformer import *\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model = tf.keras.models.load_model('/Users/mohammadshoaib/Codes/tensorflow-test/GSOC-22-Video-Swin-Transformers/swin_tiny_patch244_window877_kinetics400_1k_tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_function = tf.function(lambda inputs: tf_model(inputs),\n",
    "                               [tf.TensorSpec(tf.TensorShape([None, 3, 8 ,224, 224]),dtype=tf.float64,\n",
    "    name=\"x\")])\n",
    "\n",
    "# network_function = tf.function(lambda inputs: tf_model(inputs),\n",
    "#                                [tf.TensorSpec(tf.keras.Input((3,8,224,224), dtype=tf.float64))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = list(map(lambda tname: network_function.get_concrete_function().graph.get_tensor_by_name(tname), [\n",
    "    \"conv_projection\"\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 8, 224, 224, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pt = torch.rand( (2,3, 8,224,224)) * 255\n",
    "x_np = x_pt.numpy()\n",
    "x_tf = tf.convert_to_tensor(x_np)\n",
    "x_tf = tf.transpose(x_tf, perm=(0,2,3,4,1))\n",
    "x_tf = tf.cast(x_tf, dtype= tf.float32)\n",
    "\n",
    "x_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-14 18:24:26.781147: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-08-14 18:24:26.781262: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n",
      "---- <VideoSwinTransformer.SwinTransformer3D.SwinTransformer3D object at 0x167517ca0> (2, 96, 2, 56, 56)\n",
      "\n",
      " basic input (2, 2, 56, 56, 96)\n",
      "swin_transformer_block3d_12 (2, 2, 56, 56, 96)\n",
      "swin_transformer_block3d_13 (2, 2, 56, 56, 96)\n",
      "\n",
      " basic input (2, 2, 28, 28, 192)\n",
      "swin_transformer_block3d_14 (2, 2, 28, 28, 192)\n",
      "swin_transformer_block3d_15 (2, 2, 28, 28, 192)\n",
      "\n",
      " basic input (2, 2, 14, 14, 384)\n",
      "swin_transformer_block3d_16 (2, 2, 14, 14, 384)\n",
      "swin_transformer_block3d_17 (2, 2, 14, 14, 384)\n",
      "swin_transformer_block3d_18 (2, 2, 14, 14, 384)\n",
      "swin_transformer_block3d_19 (2, 2, 14, 14, 384)\n",
      "swin_transformer_block3d_20 (2, 2, 14, 14, 384)\n",
      "swin_transformer_block3d_21 (2, 2, 14, 14, 384)\n",
      "\n",
      " basic input (2, 2, 7, 7, 768)\n",
      "swin_transformer_block3d_22 (2, 2, 7, 7, 768)\n",
      "swin_transformer_block3d_23 (2, 2, 7, 7, 768)\n",
      "output shape:  (2, 768, 2, 7, 7)\n",
      "KerasTensor(type_spec=TensorSpec(shape=(2, 3, 8, 224, 224), dtype=tf.float32, name=None), description=\"created by layer 'input_2'\")\n"
     ]
    }
   ],
   "source": [
    "from VideoSwinTransformer import model_configs , SwinTransformer3D\n",
    "swin = SwinTransformer3D()\n",
    "\n",
    "input_shape = (2,3, 8,224, 224)\n",
    "x = tf.keras.Input((8,224,224,3))\n",
    "swin = SwinTransformer3D(shape_of_input = x.shape)\n",
    "x = tf.random.normal(input_shape,   dtype=\"float32\")\n",
    "# swin = SwinTransformer3D(x)\n",
    "x  = tf.keras.layers.Input(tensor=x)\n",
    "\n",
    "output = swin(x, training= False)\n",
    "print(\"output shape: \",output.shape)\n",
    "# print(swin.get_layer(\"basic_layer\").layers)\n",
    "\n",
    "print(swin.input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- <VideoSwinTransformer.SwinTransformer3D.SwinTransformer3D object at 0x1748a6760> (None, 96, 2, 56, 56)\n",
      "\n",
      " basic input (None, 2, 56, 56, 96)\n",
      "swin_transformer_block3d_12 (None, 2, 56, 56, 96)\n",
      "swin_transformer_block3d_13 (None, 2, 56, 56, 96)\n",
      "\n",
      " basic input (None, 2, 28, 28, 192)\n",
      "swin_transformer_block3d_14 (None, 2, 28, 28, 192)\n",
      "swin_transformer_block3d_15 (None, 2, 28, 28, 192)\n",
      "\n",
      " basic input (None, 2, 14, 14, 384)\n",
      "swin_transformer_block3d_16 (None, 2, 14, 14, 384)\n",
      "swin_transformer_block3d_17 (None, 2, 14, 14, 384)\n",
      "swin_transformer_block3d_18 (None, 2, 14, 14, 384)\n",
      "swin_transformer_block3d_19 (None, 2, 14, 14, 384)\n",
      "swin_transformer_block3d_20 (None, 2, 14, 14, 384)\n",
      "swin_transformer_block3d_21 (None, 2, 14, 14, 384)\n",
      "\n",
      " basic input (None, 2, 7, 7, 768)\n",
      "swin_transformer_block3d_22 (None, 2, 7, 7, 768)\n",
      "swin_transformer_block3d_23 (None, 2, 7, 7, 768)\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 3, 8, 224, 224)]  0         \n",
      "                                                                 \n",
      " tf.compat.v1.transpose (TFO  (None, 8, 224, 224, 3)   0         \n",
      " pLambda)                                                        \n",
      "                                                                 \n",
      " projection (Sequential)     (None, 2, 56, 56, 96)     18528     \n",
      "                                                                 \n",
      " tf.compat.v1.transpose_1 (T  (None, 96, 2, 56, 56)    0         \n",
      " FOpLambda)                                                      \n",
      "                                                                 \n",
      " dropout_49 (Dropout)        (None, 96, 2, 56, 56)     0         \n",
      "                                                                 \n",
      " basic_layer_4 (BasicLayer)  (None, 192, 2, 28, 28)    320426    \n",
      "                                                                 \n",
      " basic_layer_5 (BasicLayer)  (None, 384, 2, 14, 14)    1211468   \n",
      "                                                                 \n",
      " basic_layer_6 (BasicLayer)  (None, 768, 2, 7, 7)      11923632  \n",
      "                                                                 \n",
      " basic_layer_7 (BasicLayer)  (None, None, 2, 7, 7)     14219288  \n",
      "                                                                 \n",
      " tf.compat.v1.transpose_2 (T  (None, 2, 7, 7, None)    0         \n",
      " FOpLambda)                                                      \n",
      "                                                                 \n",
      " layer_normalization_55 (Lay  (None, 2, 7, 7, 768)     1536      \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " tf.compat.v1.transpose_3 (T  (None, 768, 2, 7, 7)     0         \n",
      " FOpLambda)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27,694,878\n",
      "Trainable params: 27,579,630\n",
      "Non-trainable params: 115,248\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "swin.build_graph().summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydot\n",
      "  Downloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
      "Collecting graphviz\n",
      "  Downloading graphviz-0.20.1-py3-none-any.whl (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.0/47.0 kB\u001b[0m \u001b[31m738.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.1.4 in /Users/mohammadshoaib/Codes/tensorflow-test/env/lib/python3.8/site-packages (from pydot) (3.0.9)\n",
      "Installing collected packages: pydot, graphviz\n",
      "Successfully installed graphviz-0.20.1 pydot-1.4.2\n"
     ]
    }
   ],
   "source": [
    "! pip install pydot graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- <VideoSwinTransformer.SwinTransformer3D.SwinTransformer3D object at 0x167517ca0> (None, 96, 2, 56, 56)\n",
      "\n",
      " basic input (None, 2, 56, 56, 96)\n",
      "swin_transformer_block3d_12 (None, 2, 56, 56, 96)\n",
      "swin_transformer_block3d_13 (None, 2, 56, 56, 96)\n",
      "\n",
      " basic input (None, 2, 28, 28, 192)\n",
      "swin_transformer_block3d_14 (None, 2, 28, 28, 192)\n",
      "swin_transformer_block3d_15 (None, 2, 28, 28, 192)\n",
      "\n",
      " basic input (None, 2, 14, 14, 384)\n",
      "swin_transformer_block3d_16 (None, 2, 14, 14, 384)\n",
      "swin_transformer_block3d_17 (None, 2, 14, 14, 384)\n",
      "swin_transformer_block3d_18 (None, 2, 14, 14, 384)\n",
      "swin_transformer_block3d_19 (None, 2, 14, 14, 384)\n",
      "swin_transformer_block3d_20 (None, 2, 14, 14, 384)\n",
      "swin_transformer_block3d_21 (None, 2, 14, 14, 384)\n",
      "\n",
      " basic input (None, 2, 7, 7, 768)\n",
      "swin_transformer_block3d_22 (None, 2, 7, 7, 768)\n",
      "swin_transformer_block3d_23 (None, 2, 7, 7, 768)\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "# Just showing all possible argument for newcomer.  \n",
    "tf.keras.utils.plot_model(\n",
    "    swin.build_graph(),                      # here is the trick (for now)\n",
    "             # saving  \n",
    "    show_shapes=True, show_layer_names=True,  # show shapes and layer name\n",
    "    expand_nested=False                       # will show nested block\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_method = model_configs.MODEL_MAP[\"swin_tiny_patch244_window877_kinetics400_1k\"]\n",
    "cfg = cfg_method()\n",
    "\n",
    "name = cfg[\"name\"]\n",
    "link = cfg['link']\n",
    "del cfg[\"name\"]\n",
    "del cfg['link']\n",
    "\n",
    "pt_model = SwinTransformer3D_pt(**cfg)\n",
    "\n",
    "checkpoint = torch.load(f'{name}.pth')\n",
    "\n",
    "\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in checkpoint['state_dict'].items():\n",
    "    if 'backbone' in k:\n",
    "        name = k[9:]\n",
    "        new_state_dict[name] = v \n",
    "\n",
    "pt_model.load_state_dict(new_state_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf_model.predict(x_tf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = pt_model(x_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.round(y, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "z.shape , y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_state_dict = pt_model.state_dict()\n",
    "np_state_dict = {k: np_state_dict[k].numpy() for k in np_state_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(np_state_dict['patch_embed.proj.bias'] ,tf_model.projection.layers[0].bias.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "for weight in tf_model.weights:\n",
    "    i +=1\n",
    "    if \"dense\" in weight.name:\n",
    "        \n",
    "        isEqual = np.array_equal(weight.numpy(),np_state_dict[tf_pt[weight.name]].transpose() )\n",
    "    else:\n",
    "        isEqual = np.array_equal(weight.numpy(),np_state_dict[tf_pt[weight.name]] )\n",
    "\n",
    "    if not isEqual:\n",
    "        print(weight.name, weight.numpy().shape , np_state_dict[tf_pt[weight.name]].shape )\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "tf_pt = {}\n",
    "  \n",
    "# Opening JSON file\n",
    "f = open('data.json')\n",
    "  \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "f.close()\n",
    "# Iterating through the json\n",
    "# list\n",
    "for idx, layer in enumerate(data):\n",
    "    # print(idx, layer, \"------\" ,  data[layer])\n",
    "    tf_pt[data[layer]] = layer\n",
    "  \n",
    "# Closing file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(SwinTransformer3D())\n",
    "model.add(tf.keras.layers.Dense(6))\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "# This builds the model for the first time:\n",
    "model.fit(x, y, batch_size=10, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.normal([100,8, 32,32, 3])\n",
    "y = tf.random.uniform(shape=[100], minval=0, maxval=5, dtype='int64')\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x  = swin(x)\n",
    "#print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# swin.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.constant(-100, dtype= 'float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "from keras.layers import Conv3D , LayerNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 96\n",
    "patch_size = (2,7,7)\n",
    "\n",
    "projection = tf.keras.Sequential(\n",
    "[\n",
    "    Conv3D(\n",
    "        embed_dim ,kernel_size = patch_size , strides= patch_size , padding=\"valid\", name= \"conv_projection\"\n",
    "    )\n",
    "],\n",
    "name = \"projection\"\n",
    ")   # data_format= \"channels_first\"\n",
    "\n",
    "projection.add(LayerNormalization(epsilon=1e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pt = torch.rand( (1,3, 8,224,224)) * 255\n",
    "x_np = x_pt.numpy()\n",
    "x_tf = tf.convert_to_tensor(x_np)\n",
    "x_tf = tf.transpose(x_tf, perm=(0,2,3,4,1))\n",
    "x_tf = tf.cast(x_tf, dtype= tf.float32)\n",
    "\n",
    "x_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "18e9ffd7bdaebed3141c5f1e6e3ffefff8dc763f7fe0a2903683245d14d535a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
