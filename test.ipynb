{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install  -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "from VideoSwinTransformer import model_configs , SwinTransformer3D_pt\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "tf_model = tf.keras.models.load_model('tf_weights/swin_tiny_patch244_window877_kinetics400_1k_tf.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 8, 224, 224, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pt = torch.rand( (1,3, 8,224,224)) * 255\n",
    "x_np = x_pt.numpy()\n",
    "x_tf = tf.convert_to_tensor(x_np)\n",
    "x_tf = tf.transpose(x_tf, perm=(0,2,3,4,1))\n",
    "x_tf = tf.cast(x_tf, dtype= tf.float32)\n",
    "\n",
    "x_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Python396\\lib\\site-packages\\torch\\functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:2895.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg_method = model_configs.MODEL_MAP[\"swin_tiny_patch244_window877_kinetics400_1k\"]\n",
    "cfg = cfg_method()\n",
    "\n",
    "name = cfg[\"name\"]\n",
    "link = cfg['link']\n",
    "del cfg[\"name\"]\n",
    "del cfg['link']\n",
    "\n",
    "pt_model = SwinTransformer3D_pt(**cfg)\n",
    "\n",
    "checkpoint = torch.load(f'{name}.pth')\n",
    "\n",
    "\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in checkpoint['state_dict'].items():\n",
    "    if 'backbone' in k:\n",
    "        name = k[9:]\n",
    "        new_state_dict[name] = v \n",
    "\n",
    "pt_model.load_state_dict(new_state_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf_model.predict(x_tf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = pt_model(x_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.round(y, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 768, 4, 7, 7]), (1, 768, 4, 7, 7))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "z.shape , y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.248 ,  0.8429,  0.0625,  0.2547,  0.0038,  0.7321,  0.3114],\n",
       "       [ 0.011 ,  0.8426,  0.9979,  0.286 ,  0.4211,  0.7433, -0.0207],\n",
       "       [ 0.2046,  0.4651, -0.0248,  0.2616, -0.0525, -0.038 ,  0.2936],\n",
       "       [ 0.0567,  0.2358, -0.0883,  0.2856, -0.0103,  0.1148, -0.0598],\n",
       "       [-0.0037,  0.6302, -0.0902, -0.112 ,  0.0935,  0.0058, -0.0441],\n",
       "       [ 0.244 ,  0.118 , -0.043 , -0.0969,  0.2323,  0.2088,  0.104 ],\n",
       "       [-0.1388, -0.0188,  0.2547, -0.101 ,  0.2865,  0.7858,  0.2629]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1783,  0.9666,  0.1493,  0.1831,  0.2065,  0.3020,  0.2416],\n",
       "        [ 0.0587,  0.5428,  0.9314,  0.2074,  0.3606,  0.2332, -0.0233],\n",
       "        [ 0.1550,  0.0723, -0.0436,  0.1668, -0.0259, -0.0210,  0.2261],\n",
       "        [ 0.0297,  0.0195,  0.0520,  0.2142, -0.0212, -0.0434, -0.0255],\n",
       "        [ 0.0119,  0.8422, -0.0031, -0.0719,  0.0650, -0.0663, -0.0116],\n",
       "        [ 0.1824,  0.1240, -0.0262, -0.0766,  0.5365, -0.0499,  0.0837],\n",
       "        [-0.1141, -0.0665,  0.1776, -0.1135,  0.2927,  0.2539,  0.2005]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_state_dict = pt_model.state_dict()\n",
    "np_state_dict = {k: np_state_dict[k].numpy() for k in np_state_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(np_state_dict['patch_embed.proj.bias'] ,tf_model.projection.layers[0].bias.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_projection/kernel:0 (2, 4, 4, 3, 96) (96, 3, 2, 4, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "184"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 1\n",
    "for weight in tf_model.weights:\n",
    "    i +=1\n",
    "    if \"dense\" in weight.name:\n",
    "        \n",
    "        isEqual = np.array_equal(weight.numpy(),np_state_dict[tf_pt[weight.name]].transpose() )\n",
    "    else:\n",
    "        isEqual = np.array_equal(weight.numpy(),np_state_dict[tf_pt[weight.name]] )\n",
    "\n",
    "    if not isEqual:\n",
    "        print(weight.name, weight.numpy().shape , np_state_dict[tf_pt[weight.name]].shape )\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "tf_pt = {}\n",
    "  \n",
    "# Opening JSON file\n",
    "f = open('data.json')\n",
    "  \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "f.close()\n",
    "# Iterating through the json\n",
    "# list\n",
    "for idx, layer in enumerate(data):\n",
    "    # print(idx, layer, \"------\" ,  data[layer])\n",
    "    tf_pt[data[layer]] = layer\n",
    "  \n",
    "# Closing file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(SwinTransformer3D())\n",
    "model.add(tf.keras.layers.Dense(6))\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "# This builds the model for the first time:\n",
    "model.fit(x, y, batch_size=10, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.normal([100,8, 32,32, 3])\n",
    "y = tf.random.uniform(shape=[100], minval=0, maxval=5, dtype='int64')\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x  = swin(x)\n",
    "#print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# swin.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.constant(-100, dtype= 'float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "from keras.layers import Conv3D , LayerNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-10 09:18:11.553807: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-08-10 09:18:11.554322: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 96\n",
    "patch_size = (2,7,7)\n",
    "\n",
    "projection = tf.keras.Sequential(\n",
    "[\n",
    "    Conv3D(\n",
    "        embed_dim ,kernel_size = patch_size , strides= patch_size , padding=\"valid\", name= \"conv_projection\"\n",
    "    )\n",
    "],\n",
    "name = \"projection\"\n",
    ")   # data_format= \"channels_first\"\n",
    "\n",
    "projection.add(LayerNormalization(epsilon=1e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/mohammadshoaib/Codes/tensorflow-test/GSOC-22-Video-Swin-Transformers/test.ipynb Cell 28\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mohammadshoaib/Codes/tensorflow-test/GSOC-22-Video-Swin-Transformers/test.ipynb#ch0000028?line=0'>1</a>\u001b[0m x_pt \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrand( (\u001b[39m1\u001b[39m,\u001b[39m3\u001b[39m, \u001b[39m8\u001b[39m,\u001b[39m224\u001b[39m,\u001b[39m224\u001b[39m)) \u001b[39m*\u001b[39m \u001b[39m255\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mohammadshoaib/Codes/tensorflow-test/GSOC-22-Video-Swin-Transformers/test.ipynb#ch0000028?line=1'>2</a>\u001b[0m x_np \u001b[39m=\u001b[39m x_pt\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mohammadshoaib/Codes/tensorflow-test/GSOC-22-Video-Swin-Transformers/test.ipynb#ch0000028?line=2'>3</a>\u001b[0m x_tf \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconvert_to_tensor(x_np)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "x_pt = torch.rand( (1,3, 8,224,224)) * 255\n",
    "x_np = x_pt.numpy()\n",
    "x_tf = tf.convert_to_tensor(x_np)\n",
    "x_tf = tf.transpose(x_tf, perm=(0,2,3,4,1))\n",
    "x_tf = tf.cast(x_tf, dtype= tf.float32)\n",
    "\n",
    "x_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "18e9ffd7bdaebed3141c5f1e6e3ffefff8dc763f7fe0a2903683245d14d535a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
