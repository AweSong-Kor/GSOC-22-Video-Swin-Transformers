{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install  -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "from VideoSwinTransformer import *\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-03 18:50:28.188801: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-10-03 18:50:28.189418: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "swin = tf.keras.models.load_model('/Users/mohammadshoaib/Codes/tensorflow-test/GSOC-22-Video-Swin-Transformers/swin_tiny_patch244_window877_kinetics400_1k_tf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-03 18:51:08.786707: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-10-03 18:51:09.781084: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 768, 16, 7, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.normal((2,3,32,224,224),   dtype=\"float32\")\n",
    "\n",
    "y = swin.predict(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from VideoSwinTransformer import model_configs , SwinTransformer3D\n",
    "swin = SwinTransformer3D()\n",
    "\n",
    "input_shape = (2,3, 8,224, 224)\n",
    "x = tf.keras.Input((8,224,224,3))\n",
    "swin = SwinTransformer3D(shape_of_input = x.shape)\n",
    "x = tf.random.normal(input_shape,   dtype=\"float32\")\n",
    "\n",
    "swin.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Swin Trnsformer3D input size (2, 3, 8, 224, 224)\n",
      "output shape:  (2, 768, 2, 7, 7)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4, 768, 4, 7, 7)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-03 14:13:37.085956: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 768, 16, 7, 7])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = swin(x)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers = swin.get_layer_output()\n",
    "len(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Received incompatible tensor with shape (2535, 3) when attempting to restore variable with shape (507, 3) and name layers3D/0/blocks/0/attn/relative_position_bias_table/.ATTRIBUTES/VARIABLE_VALUE.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/mohammadshoaib/Codes/tensorflow-test/GSOC-22-Video-Swin-Transformers/test.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mohammadshoaib/Codes/tensorflow-test/GSOC-22-Video-Swin-Transformers/test.ipynb#ch0000049?line=0'>1</a>\u001b[0m swin\u001b[39m.\u001b[39;49mload_weights(\u001b[39m'\u001b[39;49m\u001b[39m./checkpoints/my_checkpoint\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/Codes/tensorflow-test/env/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Codes/tensorflow-test/env/lib/python3.8/site-packages/tensorflow/python/training/saving/saveable_object_util.py:133\u001b[0m, in \u001b[0;36mResourceVariableSaveable.restore\u001b[0;34m(self, restored_tensors, restored_shapes)\u001b[0m\n\u001b[1;32m    130\u001b[0m   assigned_variable \u001b[39m=\u001b[39m resource_variable_ops\u001b[39m.\u001b[39mshape_safe_assign_variable_handle(\n\u001b[1;32m    131\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_op, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_var_shape, restored_tensor)\n\u001b[1;32m    132\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 133\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    134\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReceived incompatible tensor with shape \u001b[39m\u001b[39m{\u001b[39;00mrestored_tensor\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    135\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwhen attempting to restore variable with shape \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_var_shape\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    136\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mand name \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[39mreturn\u001b[39;00m assigned_variable\n",
      "\u001b[0;31mValueError\u001b[0m: Received incompatible tensor with shape (2535, 3) when attempting to restore variable with shape (507, 3) and name layers3D/0/blocks/0/attn/relative_position_bias_table/.ATTRIBUTES/VARIABLE_VALUE."
     ]
    }
   ],
   "source": [
    "swin.load_weights('./checkpoints/my_checkpoint')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swin_transformer3d_3/basic_layer_12/swin_transformer_block3d_36/window_attention3d_36/relative_position_bias_table:0 (507, 3)\n",
      "swin_transformer3d_3/basic_layer_12/swin_transformer_block3d_37/window_attention3d_37/relative_position_bias_table:0 (507, 3)\n",
      "swin_transformer3d_3/basic_layer_13/swin_transformer_block3d_38/window_attention3d_38/relative_position_bias_table:0 (507, 6)\n",
      "swin_transformer3d_3/basic_layer_13/swin_transformer_block3d_39/window_attention3d_39/relative_position_bias_table:0 (507, 6)\n",
      "swin_transformer3d_3/basic_layer_14/swin_transformer_block3d_40/window_attention3d_40/relative_position_bias_table:0 (507, 12)\n",
      "swin_transformer3d_3/basic_layer_14/swin_transformer_block3d_41/window_attention3d_41/relative_position_bias_table:0 (507, 12)\n",
      "swin_transformer3d_3/basic_layer_14/swin_transformer_block3d_42/window_attention3d_42/relative_position_bias_table:0 (507, 12)\n",
      "swin_transformer3d_3/basic_layer_14/swin_transformer_block3d_43/window_attention3d_43/relative_position_bias_table:0 (507, 12)\n",
      "swin_transformer3d_3/basic_layer_14/swin_transformer_block3d_44/window_attention3d_44/relative_position_bias_table:0 (507, 12)\n",
      "swin_transformer3d_3/basic_layer_14/swin_transformer_block3d_45/window_attention3d_45/relative_position_bias_table:0 (507, 12)\n",
      "swin_transformer3d_3/basic_layer_15/swin_transformer_block3d_46/window_attention3d_46/relative_position_bias_table:0 (507, 24)\n",
      "swin_transformer3d_3/basic_layer_15/swin_transformer_block3d_47/window_attention3d_47/relative_position_bias_table:0 (507, 24)\n"
     ]
    }
   ],
   "source": [
    "for l in swin.weights:\n",
    "    if \"relative_position_bias_table\" in  l.name :\n",
    "        print(l.name, l.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SwinTransformer3D' object has no attribute 'get_layer_output'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/mohammadshoaib/Codes/tensorflow-test/GSOC-22-Video-Swin-Transformers/test.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mohammadshoaib/Codes/tensorflow-test/GSOC-22-Video-Swin-Transformers/test.ipynb#ch0000050?line=0'>1</a>\u001b[0m layers \u001b[39m=\u001b[39m swin\u001b[39m.\u001b[39;49mget_layer_output()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mohammadshoaib/Codes/tensorflow-test/GSOC-22-Video-Swin-Transformers/test.ipynb#ch0000050?line=1'>2</a>\u001b[0m \u001b[39mlen\u001b[39m(layers)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SwinTransformer3D' object has no attribute 'get_layer_output'"
     ]
    }
   ],
   "source": [
    "layers = swin.get_layer_output()\n",
    "len(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = swin(x)\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers = tf_model.layer_output\n",
    "layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Intermediate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_function = tf.function(lambda inputs: tf_model(inputs),\n",
    "                               [tf.TensorSpec(tf.TensorShape([None, 3, 8 ,224, 224]),dtype=tf.float64,\n",
    "    name=\"x\")])\n",
    "\n",
    "# network_function = tf.function(lambda inputs: tf_model(inputs),\n",
    "#                                [tf.TensorSpec(tf.keras.Input((3,8,224,224), dtype=tf.float64))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = list(map(lambda tname: network_function.get_concrete_function().graph.get_tensor_by_name(tname), [\n",
    "    \"conv_projection\"\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-15 20:42:40.057064: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-08-15 20:42:40.057208: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "x_pt = torch.rand( (2,3, 8,224,224)) * 255\n",
    "x_np = x_pt.numpy()\n",
    "x_tf = tf.convert_to_tensor(x_np)\n",
    "x_tf = tf.transpose(x_tf, perm=(0,2,3,4,1))\n",
    "x_tf = tf.cast(x_tf, dtype= tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Swin Trnsformer3D input size (2, 3, 8, 224, 224)\n",
      "output shape:  (2, 768, 2, 7, 7)\n",
      "KerasTensor(type_spec=TensorSpec(shape=(2, 3, 8, 224, 224), dtype=tf.float32, name=None), description=\"created by layer 'input_9'\")\n"
     ]
    }
   ],
   "source": [
    "from VideoSwinTransformer import model_configs , SwinTransformer3D\n",
    "swin = SwinTransformer3D()\n",
    "\n",
    "input_shape = (2,3, 8,224, 224)\n",
    "x = tf.keras.Input((8,224,224,3))\n",
    "swin = SwinTransformer3D(shape_of_input = x.shape)\n",
    "x = tf.random.normal(input_shape,   dtype=\"float32\")\n",
    "# swin = SwinTransformer3D(x)\n",
    "x  = tf.keras.layers.Input(tensor=x)\n",
    "\n",
    "output = swin(x, training= False)\n",
    "print(\"output shape: \",output.shape)\n",
    "# print(swin.get_layer(\"basic_layer\").layers)\n",
    "\n",
    "print(swin.input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Swin Trnsformer3D input size (None, 3, 8, 224, 224)\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 3, 8, 224, 224)]  0         \n",
      "                                                                 \n",
      " tf.compat.v1.transpose (TFO  (None, 8, 224, 224, 3)   0         \n",
      " pLambda)                                                        \n",
      "                                                                 \n",
      " projection (Sequential)     (None, 2, 56, 56, 96)     18528     \n",
      "                                                                 \n",
      " tf.compat.v1.transpose_1 (T  (None, 96, 2, 56, 56)    0         \n",
      " FOpLambda)                                                      \n",
      "                                                                 \n",
      " dropout_49 (Dropout)        (None, 96, 2, 56, 56)     0         \n",
      "                                                                 \n",
      " basic_layer_4 (BasicLayer)  (None, 192, 2, 28, 28)    320426    \n",
      "                                                                 \n",
      " basic_layer_5 (BasicLayer)  (None, 384, 2, 14, 14)    1211468   \n",
      "                                                                 \n",
      " basic_layer_6 (BasicLayer)  (None, 768, 2, 7, 7)      11923632  \n",
      "                                                                 \n",
      " basic_layer_7 (BasicLayer)  (None, None, 2, 7, 7)     14219288  \n",
      "                                                                 \n",
      " tf.compat.v1.transpose_2 (T  (None, 2, 7, 7, None)    0         \n",
      " FOpLambda)                                                      \n",
      "                                                                 \n",
      " layer_normalization_55 (Lay  (None, 2, 7, 7, 768)     1536      \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " tf.compat.v1.transpose_3 (T  (None, 768, 2, 7, 7)     0         \n",
      " FOpLambda)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27,694,878\n",
      "Trainable params: 27,579,630\n",
      "Non-trainable params: 115,248\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "swin.build_graph().summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 2, 56, 56, 96) dtype=float32 (created by layer 'conv_projection')>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = swin.layers[0].layers[0].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Swin Trnsformer3D input size (None, 3, 8, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "model  = swin.build_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x  = tf.keras.layers.Input(tensor=x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 2, 56, 56, 96) dtype=float32 (created by layer 'dropout_57')>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = swin.layers[2].layers[1].layers[4].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found unexpected instance while processing input tensors for keras functional model. Expecting KerasTensor which is from tf.keras.Input() or output from keras layer call(). Got: <VideoSwinTransformer.BasicLayer.BasicLayer object at 0x292b99eb0>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/mohammadshoaib/Codes/tensorflow-test/GSOC-22-Video-Swin-Transformers/test.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mohammadshoaib/Codes/tensorflow-test/GSOC-22-Video-Swin-Transformers/test.ipynb#ch0000043?line=2'>3</a>\u001b[0m inp \u001b[39m=\u001b[39m     swin\u001b[39m.\u001b[39mget_layer(\u001b[39m\"\u001b[39m\u001b[39mbasic_layer_4\u001b[39m\u001b[39m\"\u001b[39m)                         \u001b[39m# input placeholder\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mohammadshoaib/Codes/tensorflow-test/GSOC-22-Video-Swin-Transformers/test.ipynb#ch0000043?line=3'>4</a>\u001b[0m outputs \u001b[39m=\u001b[39m [output]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mohammadshoaib/Codes/tensorflow-test/GSOC-22-Video-Swin-Transformers/test.ipynb#ch0000043?line=5'>6</a>\u001b[0m functors \u001b[39m=\u001b[39m [K\u001b[39m.\u001b[39mfunction([inp], [out]) \u001b[39mfor\u001b[39;00m out \u001b[39min\u001b[39;00m outputs]    \u001b[39m# evaluation functions\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mohammadshoaib/Codes/tensorflow-test/GSOC-22-Video-Swin-Transformers/test.ipynb#ch0000043?line=7'>8</a>\u001b[0m \u001b[39m#Testing\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mohammadshoaib/Codes/tensorflow-test/GSOC-22-Video-Swin-Transformers/test.ipynb#ch0000043?line=8'>9</a>\u001b[0m input_shape \u001b[39m=\u001b[39m (\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m,\u001b[39m8\u001b[39m,\u001b[39m224\u001b[39m,\u001b[39m224\u001b[39m)\n",
      "\u001b[1;32m/Users/mohammadshoaib/Codes/tensorflow-test/GSOC-22-Video-Swin-Transformers/test.ipynb Cell 16\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mohammadshoaib/Codes/tensorflow-test/GSOC-22-Video-Swin-Transformers/test.ipynb#ch0000043?line=2'>3</a>\u001b[0m inp \u001b[39m=\u001b[39m     swin\u001b[39m.\u001b[39mget_layer(\u001b[39m\"\u001b[39m\u001b[39mbasic_layer_4\u001b[39m\u001b[39m\"\u001b[39m)                         \u001b[39m# input placeholder\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mohammadshoaib/Codes/tensorflow-test/GSOC-22-Video-Swin-Transformers/test.ipynb#ch0000043?line=3'>4</a>\u001b[0m outputs \u001b[39m=\u001b[39m [output]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mohammadshoaib/Codes/tensorflow-test/GSOC-22-Video-Swin-Transformers/test.ipynb#ch0000043?line=5'>6</a>\u001b[0m functors \u001b[39m=\u001b[39m [K\u001b[39m.\u001b[39;49mfunction([inp], [out]) \u001b[39mfor\u001b[39;00m out \u001b[39min\u001b[39;00m outputs]    \u001b[39m# evaluation functions\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mohammadshoaib/Codes/tensorflow-test/GSOC-22-Video-Swin-Transformers/test.ipynb#ch0000043?line=7'>8</a>\u001b[0m \u001b[39m#Testing\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mohammadshoaib/Codes/tensorflow-test/GSOC-22-Video-Swin-Transformers/test.ipynb#ch0000043?line=8'>9</a>\u001b[0m input_shape \u001b[39m=\u001b[39m (\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m,\u001b[39m8\u001b[39m,\u001b[39m224\u001b[39m,\u001b[39m224\u001b[39m)\n",
      "File \u001b[0;32m~/Codes/tensorflow-test/env/lib/python3.8/site-packages/keras/backend.py:4327\u001b[0m, in \u001b[0;36mfunction\u001b[0;34m(inputs, outputs, updates, name, **kwargs)\u001b[0m\n\u001b[1;32m   4325\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m models  \u001b[39m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[1;32m   4326\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m tf_utils  \u001b[39m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[0;32m-> 4327\u001b[0m model \u001b[39m=\u001b[39m models\u001b[39m.\u001b[39;49mModel(inputs\u001b[39m=\u001b[39;49minputs, outputs\u001b[39m=\u001b[39;49moutputs)\n\u001b[1;32m   4329\u001b[0m wrap_outputs \u001b[39m=\u001b[39m \u001b[39misinstance\u001b[39m(outputs, \u001b[39mlist\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(outputs) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   4330\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfunc\u001b[39m(model_inputs):\n",
      "File \u001b[0;32m~/Codes/tensorflow-test/env/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py:587\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    586\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 587\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    588\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    589\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/Codes/tensorflow-test/env/lib/python3.8/site-packages/keras/engine/functional.py:145\u001b[0m, in \u001b[0;36mFunctional.__init__\u001b[0;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39m# Check if the inputs contain any intermediate `KerasTensor` (not created\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[39m# by tf.keras.Input()). In this case we need to clone the `Node` and\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[39m# `KerasTensor` objects to mimic rebuilding a new model from new inputs.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[39m# This feature is only enabled in TF2 not in v1 graph mode.\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mexecuting_eagerly_outside_functions():\n\u001b[0;32m--> 145\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m([functional_utils\u001b[39m.\u001b[39mis_input_keras_tensor(t)\n\u001b[1;32m    146\u001b[0m               \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(inputs)]):\n\u001b[1;32m    147\u001b[0m     inputs, outputs \u001b[39m=\u001b[39m functional_utils\u001b[39m.\u001b[39mclone_graph_nodes(inputs, outputs)\n\u001b[1;32m    148\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_graph_network(inputs, outputs)\n",
      "File \u001b[0;32m~/Codes/tensorflow-test/env/lib/python3.8/site-packages/keras/engine/functional.py:145\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39m# Check if the inputs contain any intermediate `KerasTensor` (not created\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[39m# by tf.keras.Input()). In this case we need to clone the `Node` and\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[39m# `KerasTensor` objects to mimic rebuilding a new model from new inputs.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[39m# This feature is only enabled in TF2 not in v1 graph mode.\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mexecuting_eagerly_outside_functions():\n\u001b[0;32m--> 145\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m([functional_utils\u001b[39m.\u001b[39;49mis_input_keras_tensor(t)\n\u001b[1;32m    146\u001b[0m               \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(inputs)]):\n\u001b[1;32m    147\u001b[0m     inputs, outputs \u001b[39m=\u001b[39m functional_utils\u001b[39m.\u001b[39mclone_graph_nodes(inputs, outputs)\n\u001b[1;32m    148\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_graph_network(inputs, outputs)\n",
      "File \u001b[0;32m~/Codes/tensorflow-test/env/lib/python3.8/site-packages/keras/engine/functional_utils.py:47\u001b[0m, in \u001b[0;36mis_input_keras_tensor\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39m\"\"\"Check if tensor is directly generated from `tf.keras.Input`.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[39mThis check is useful when constructing the functional model, since we will\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39m  ValueError: if the tensor is not a KerasTensor instance.\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m node_module\u001b[39m.\u001b[39mis_keras_tensor(tensor):\n\u001b[0;32m---> 47\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(_KERAS_TENSOR_TYPE_CHECK_ERROR_MSG\u001b[39m.\u001b[39mformat(tensor))\n\u001b[1;32m     48\u001b[0m \u001b[39mreturn\u001b[39;00m tensor\u001b[39m.\u001b[39mnode\u001b[39m.\u001b[39mis_input\n",
      "\u001b[0;31mValueError\u001b[0m: Found unexpected instance while processing input tensors for keras functional model. Expecting KerasTensor which is from tf.keras.Input() or output from keras layer call(). Got: <VideoSwinTransformer.BasicLayer.BasicLayer object at 0x292b99eb0>"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "inp =     swin.get_layer(\"basic_layer_4\")                         # input placeholder\n",
    "outputs = [output]\n",
    "\n",
    "functors = [K.function([inp], [out]) for out in outputs]    # evaluation functions\n",
    "\n",
    "#Testing\n",
    "input_shape = (2,3,8,224,224)\n",
    "test = np.random.random(input_shape)[np.newaxis,...]\n",
    "layer_outs = [func([test]) for func in functors]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.normalization.layer_normalization.LayerNormalization at 0x292b7d9a0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"swin_transformer3d_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " projection (Sequential)     (None, 2, 56, 56, 96)     18528     \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| conv_projection (Conv3D)  (None, 2, 56, 56, 96)     18528     |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " dropout_49 (Dropout)        (None, 96, 2, 56, 56)     0         \n",
      "                                                                 \n",
      " basic_layer_4 (BasicLayer)  (None, 192, 2, 28, 28)    320426    \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| swin_transformer_block3d_12  multiple               122965    |\n",
      "|  (SwinTransformerBlock3D)                                     |\n",
      "||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\n",
      "|| layer_normalization_28 (Lay  multiple             192       ||\n",
      "|| erNormalization)                                            ||\n",
      "||                                                             ||\n",
      "|| window_attention3d_12 (Wind  multiple             48373     ||\n",
      "|| owAttention3D)                                              ||\n",
      "||                                                             ||\n",
      "|| layer_normalization_29 (Lay  multiple             192       ||\n",
      "|| erNormalization)                                            ||\n",
      "||                                                             ||\n",
      "|| mlp (Sequential)        (None, 2, 56, 56, 96)     74208     ||\n",
      "|||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|||\n",
      "||| dense_53 (Dense)      (None, 2, 56, 56, 384)    37248     |||\n",
      "|||                                                           |||\n",
      "||| dropout_52 (Dropout)  (None, 2, 56, 56, 384)    0         |||\n",
      "|||                                                           |||\n",
      "||| dense_54 (Dense)      (None, 2, 56, 56, 96)     36960     |||\n",
      "|||                                                           |||\n",
      "||| dropout_53 (Dropout)  (None, 2, 56, 56, 96)     0         |||\n",
      "||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| swin_transformer_block3d_13  multiple               122965    |\n",
      "|  (SwinTransformerBlock3D)                                     |\n",
      "||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\n",
      "|| layer_normalization_30 (Lay  multiple             192       ||\n",
      "|| erNormalization)                                            ||\n",
      "||                                                             ||\n",
      "|| window_attention3d_13 (Wind  multiple             48373     ||\n",
      "|| owAttention3D)                                              ||\n",
      "||                                                             ||\n",
      "|| drop_path_11 (DropPath)  multiple                 0         ||\n",
      "||                                                             ||\n",
      "|| layer_normalization_31 (Lay  multiple             192       ||\n",
      "|| erNormalization)                                            ||\n",
      "||                                                             ||\n",
      "|| mlp (Sequential)        (None, 2, 56, 56, 96)     74208     ||\n",
      "|||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|||\n",
      "||| dense_57 (Dense)      (None, 2, 56, 56, 384)    37248     |||\n",
      "|||                                                           |||\n",
      "||| dropout_56 (Dropout)  (None, 2, 56, 56, 384)    0         |||\n",
      "|||                                                           |||\n",
      "||| dense_58 (Dense)      (None, 2, 56, 56, 96)     36960     |||\n",
      "|||                                                           |||\n",
      "||| dropout_57 (Dropout)  (None, 2, 56, 56, 96)     0         |||\n",
      "||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| patch_merging_3 (PatchMergi  multiple               74496     |\n",
      "| ng)                                                           |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " basic_layer_5 (BasicLayer)  (None, 384, 2, 14, 14)    1211468   \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| swin_transformer_block3d_14  multiple               457510    |\n",
      "|  (SwinTransformerBlock3D)                                     |\n",
      "||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\n",
      "|| layer_normalization_33 (Lay  multiple             384       ||\n",
      "|| erNormalization)                                            ||\n",
      "||                                                             ||\n",
      "|| window_attention3d_14 (Wind  multiple             160870    ||\n",
      "|| owAttention3D)                                              ||\n",
      "||                                                             ||\n",
      "|| drop_path_12 (DropPath)  multiple                 0         ||\n",
      "||                                                             ||\n",
      "|| layer_normalization_34 (Lay  multiple             384       ||\n",
      "|| erNormalization)                                            ||\n",
      "||                                                             ||\n",
      "|| mlp (Sequential)        (None, 2, 28, 28, 192)    295872    ||\n",
      "|||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|||\n",
      "||| dense_62 (Dense)      (None, 2, 28, 28, 768)    148224    |||\n",
      "|||                                                           |||\n",
      "||| dropout_60 (Dropout)  (None, 2, 28, 28, 768)    0         |||\n",
      "|||                                                           |||\n",
      "||| dense_63 (Dense)      (None, 2, 28, 28, 192)    147648    |||\n",
      "|||                                                           |||\n",
      "||| dropout_61 (Dropout)  (None, 2, 28, 28, 192)    0         |||\n",
      "||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| swin_transformer_block3d_15  multiple               457510    |\n",
      "|  (SwinTransformerBlock3D)                                     |\n",
      "||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\n",
      "|| layer_normalization_35 (Lay  multiple             384       ||\n",
      "|| erNormalization)                                            ||\n",
      "||                                                             ||\n",
      "|| window_attention3d_15 (Wind  multiple             160870    ||\n",
      "|| owAttention3D)                                              ||\n",
      "||                                                             ||\n",
      "|| drop_path_13 (DropPath)  multiple                 0         ||\n",
      "||                                                             ||\n",
      "|| layer_normalization_36 (Lay  multiple             384       ||\n",
      "|| erNormalization)                                            ||\n",
      "||                                                             ||\n",
      "|| mlp (Sequential)        (None, 2, 28, 28, 192)    295872    ||\n",
      "|||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|||\n",
      "||| dense_66 (Dense)      (None, 2, 28, 28, 768)    148224    |||\n",
      "|||                                                           |||\n",
      "||| dropout_64 (Dropout)  (None, 2, 28, 28, 768)    0         |||\n",
      "|||                                                           |||\n",
      "||| dense_67 (Dense)      (None, 2, 28, 28, 192)    147648    |||\n",
      "|||                                                           |||\n",
      "||| dropout_65 (Dropout)  (None, 2, 28, 28, 192)    0         |||\n",
      "||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| patch_merging_4 (PatchMergi  multiple               296448    |\n",
      "| ng)                                                           |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " basic_layer_6 (BasicLayer)  (None, 768, 2, 7, 7)      11923632  \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| swin_transformer_block3d_16  multiple               1790152   |\n",
      "|  (SwinTransformerBlock3D)                                     |\n",
      "||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\n",
      "|| layer_normalization_38 (Lay  multiple             768       ||\n",
      "|| erNormalization)                                            ||\n",
      "||                                                             ||\n",
      "|| window_attention3d_16 (Wind  multiple             607048    ||\n",
      "|| owAttention3D)                                              ||\n",
      "||                                                             ||\n",
      "|| drop_path_14 (DropPath)  multiple                 0         ||\n",
      "||                                                             ||\n",
      "|| layer_normalization_39 (Lay  multiple             768       ||\n",
      "|| erNormalization)                                            ||\n",
      "||                                                             ||\n",
      "|| mlp (Sequential)        (None, 2, 14, 14, 384)    1181568   ||\n",
      "|||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|||\n",
      "||| dense_71 (Dense)      (None, 2, 14, 14, 1536)   591360    |||\n",
      "|||                                                           |||\n",
      "||| dropout_68 (Dropout)  (None, 2, 14, 14, 1536)   0         |||\n",
      "|||                                                           |||\n",
      "||| dense_72 (Dense)      (None, 2, 14, 14, 384)    590208    |||\n",
      "|||                                                           |||\n",
      "||| dropout_69 (Dropout)  (None, 2, 14, 14, 384)    0         |||\n",
      "||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| swin_transformer_block3d_17  multiple               1790152   |\n",
      "|  (SwinTransformerBlock3D)                                     |\n",
      "||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\n",
      "|| layer_normalization_40 (Lay  multiple             768       ||\n",
      "|| erNormalization)                                            ||\n",
      "||                                                             ||\n",
      "|| window_attention3d_17 (Wind  multiple             607048    ||\n",
      "|| owAttention3D)                                              ||\n",
      "||                                                             ||\n",
      "|| drop_path_15 (DropPath)  multiple                 0         ||\n",
      "||                                                             ||\n",
      "|| layer_normalization_41 (Lay  multiple             768       ||\n",
      "|| erNormalization)                                            ||\n",
      "||                                                             ||\n",
      "|| mlp (Sequential)        (None, 2, 14, 14, 384)    1181568   ||\n",
      "|||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|||\n",
      "||| dense_75 (Dense)      (None, 2, 14, 14, 1536)   591360    |||\n",
      "|||                                                           |||\n",
      "||| dropout_72 (Dropout)  (None, 2, 14, 14, 1536)   0         |||\n",
      "|||                                                           |||\n",
      "||| dense_76 (Dense)      (None, 2, 14, 14, 384)    590208    |||\n",
      "|||                                                           |||\n",
      "||| dropout_73 (Dropout)  (None, 2, 14, 14, 384)    0         |||\n",
      "||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| swin_transformer_block3d_18  multiple               1790152   |\n",
      "|  (SwinTransformerBlock3D)                                     |\n",
      "||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\n",
      "|| layer_normalization_42 (Lay  multiple             768       ||\n",
      "|| erNormalization)                                            ||\n",
      "||                                                             ||\n",
      "|| window_attention3d_18 (Wind  multiple             607048    ||\n",
      "|| owAttention3D)                                              ||\n",
      "||                                                             ||\n",
      "|| drop_path_16 (DropPath)  multiple                 0         ||\n",
      "||                                                             ||\n",
      "|| layer_normalization_43 (Lay  multiple             768       ||\n",
      "|| erNormalization)                                            ||\n",
      "||                                                             ||\n",
      "|| mlp (Sequential)        (None, 2, 14, 14, 384)    1181568   ||\n",
      "|||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|||\n",
      "||| dense_79 (Dense)      (None, 2, 14, 14, 1536)   591360    |||\n",
      "|||                                                           |||\n",
      "||| dropout_76 (Dropout)  (None, 2, 14, 14, 1536)   0         |||\n",
      "|||                                                           |||\n",
      "||| dense_80 (Dense)      (None, 2, 14, 14, 384)    590208    |||\n",
      "|||                                                           |||\n",
      "||| dropout_77 (Dropout)  (None, 2, 14, 14, 384)    0         |||\n",
      "||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| swin_transformer_block3d_19  multiple               1790152   |\n",
      "|  (SwinTransformerBlock3D)                                     |\n",
      "||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\n",
      "|| layer_normalization_44 (Lay  multiple             768       ||\n",
      "|| erNormalization)                                            ||\n",
      "||                                                             ||\n",
      "|| window_attention3d_19 (Wind  multiple             607048    ||\n",
      "|| owAttention3D)                                              ||\n",
      "||                                                             ||\n",
      "|| drop_path_17 (DropPath)  multiple                 0         ||\n",
      "||                                                             ||\n",
      "|| layer_normalization_45 (Lay  multiple             768       ||\n",
      "|| erNormalization)                                            ||\n",
      "||                                                             ||\n",
      "|| mlp (Sequential)        (None, 2, 14, 14, 384)    1181568   ||\n",
      "|||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|||\n",
      "||| dense_83 (Dense)      (None, 2, 14, 14, 1536)   591360    |||\n",
      "|||                                                           |||\n",
      "||| dropout_80 (Dropout)  (None, 2, 14, 14, 1536)   0         |||\n",
      "|||                                                           |||\n",
      "||| dense_84 (Dense)      (None, 2, 14, 14, 384)    590208    |||\n",
      "|||                                                           |||\n",
      "||| dropout_81 (Dropout)  (None, 2, 14, 14, 384)    0         |||\n",
      "||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| swin_transformer_block3d_20  multiple               1790152   |\n",
      "|  (SwinTransformerBlock3D)                                     |\n",
      "||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\n",
      "|| layer_normalization_46 (Lay  multiple             768       ||\n",
      "|| erNormalization)                                            ||\n",
      "||                                                             ||\n",
      "|| window_attention3d_20 (Wind  multiple             607048    ||\n",
      "|| owAttention3D)                                              ||\n",
      "||                                                             ||\n",
      "|| drop_path_18 (DropPath)  multiple                 0         ||\n",
      "||                                                             ||\n",
      "|| layer_normalization_47 (Lay  multiple             768       ||\n",
      "|| erNormalization)                                            ||\n",
      "||                                                             ||\n",
      "|| mlp (Sequential)        (None, 2, 14, 14, 384)    1181568   ||\n",
      "|||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|||\n",
      "||| dense_87 (Dense)      (None, 2, 14, 14, 1536)   591360    |||\n",
      "|||                                                           |||\n",
      "||| dropout_84 (Dropout)  (None, 2, 14, 14, 1536)   0         |||\n",
      "|||                                                           |||\n",
      "||| dense_88 (Dense)      (None, 2, 14, 14, 384)    590208    |||\n",
      "|||                                                           |||\n",
      "||| dropout_85 (Dropout)  (None, 2, 14, 14, 384)    0         |||\n",
      "||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| swin_transformer_block3d_21  multiple               1790152   |\n",
      "|  (SwinTransformerBlock3D)                                     |\n",
      "||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\n",
      "|| layer_normalization_48 (Lay  multiple             768       ||\n",
      "|| erNormalization)                                            ||\n",
      "||                                                             ||\n",
      "|| window_attention3d_21 (Wind  multiple             607048    ||\n",
      "|| owAttention3D)                                              ||\n",
      "||                                                             ||\n",
      "|| drop_path_19 (DropPath)  multiple                 0         ||\n",
      "||                                                             ||\n",
      "|| layer_normalization_49 (Lay  multiple             768       ||\n",
      "|| erNormalization)                                            ||\n",
      "||                                                             ||\n",
      "|| mlp (Sequential)        (None, 2, 14, 14, 384)    1181568   ||\n",
      "|||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|||\n",
      "||| dense_91 (Dense)      (None, 2, 14, 14, 1536)   591360    |||\n",
      "|||                                                           |||\n",
      "||| dropout_88 (Dropout)  (None, 2, 14, 14, 1536)   0         |||\n",
      "|||                                                           |||\n",
      "||| dense_92 (Dense)      (None, 2, 14, 14, 384)    590208    |||\n",
      "|||                                                           |||\n",
      "||| dropout_89 (Dropout)  (None, 2, 14, 14, 384)    0         |||\n",
      "||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| patch_merging_5 (PatchMergi  multiple               1182720   |\n",
      "| ng)                                                           |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " basic_layer_7 (BasicLayer)  (None, None, 2, 7, 7)     14219288  \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| swin_transformer_block3d_22  multiple               7109644   |\n",
      "|  (SwinTransformerBlock3D)                                     |\n",
      "||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\n",
      "|| layer_normalization_51 (Lay  multiple             1536      ||\n",
      "|| erNormalization)                                            ||\n",
      "||                                                             ||\n",
      "|| window_attention3d_22 (Wind  multiple             2384140   ||\n",
      "|| owAttention3D)                                              ||\n",
      "||                                                             ||\n",
      "|| drop_path_20 (DropPath)  multiple                 0         ||\n",
      "||                                                             ||\n",
      "|| layer_normalization_52 (Lay  multiple             1536      ||\n",
      "|| erNormalization)                                            ||\n",
      "||                                                             ||\n",
      "|| mlp (Sequential)        (None, 2, 7, 7, 768)      4722432   ||\n",
      "|||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|||\n",
      "||| dense_96 (Dense)      (None, 2, 7, 7, 3072)     2362368   |||\n",
      "|||                                                           |||\n",
      "||| dropout_92 (Dropout)  (None, 2, 7, 7, 3072)     0         |||\n",
      "|||                                                           |||\n",
      "||| dense_97 (Dense)      (None, 2, 7, 7, 768)      2360064   |||\n",
      "|||                                                           |||\n",
      "||| dropout_93 (Dropout)  (None, 2, 7, 7, 768)      0         |||\n",
      "||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| swin_transformer_block3d_23  multiple               7109644   |\n",
      "|  (SwinTransformerBlock3D)                                     |\n",
      "||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\n",
      "|| layer_normalization_53 (Lay  multiple             1536      ||\n",
      "|| erNormalization)                                            ||\n",
      "||                                                             ||\n",
      "|| window_attention3d_23 (Wind  multiple             2384140   ||\n",
      "|| owAttention3D)                                              ||\n",
      "||                                                             ||\n",
      "|| drop_path_21 (DropPath)  multiple                 0         ||\n",
      "||                                                             ||\n",
      "|| layer_normalization_54 (Lay  multiple             1536      ||\n",
      "|| erNormalization)                                            ||\n",
      "||                                                             ||\n",
      "|| mlp (Sequential)        (None, 2, 7, 7, 768)      4722432   ||\n",
      "|||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|||\n",
      "||| dense_100 (Dense)     (None, 2, 7, 7, 3072)     2362368   |||\n",
      "|||                                                           |||\n",
      "||| dropout_96 (Dropout)  (None, 2, 7, 7, 3072)     0         |||\n",
      "|||                                                           |||\n",
      "||| dense_101 (Dense)     (None, 2, 7, 7, 768)      2360064   |||\n",
      "|||                                                           |||\n",
      "||| dropout_97 (Dropout)  (None, 2, 7, 7, 768)      0         |||\n",
      "||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " layer_normalization_55 (Lay  (None, 2, 7, 7, 768)     1536      \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27,694,878\n",
      "Trainable params: 27,579,630\n",
      "Non-trainable params: 115,248\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "swin.summary(expand_nested=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydot\n",
      "  Downloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
      "Collecting graphviz\n",
      "  Downloading graphviz-0.20.1-py3-none-any.whl (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.0/47.0 kB\u001b[0m \u001b[31m738.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.1.4 in /Users/mohammadshoaib/Codes/tensorflow-test/env/lib/python3.8/site-packages (from pydot) (3.0.9)\n",
      "Installing collected packages: pydot, graphviz\n",
      "Successfully installed graphviz-0.20.1 pydot-1.4.2\n"
     ]
    }
   ],
   "source": [
    "! pip install pydot graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "# Just showing all possible argument for newcomer.  \n",
    "tf.keras.utils.plot_model(\n",
    "    swin.build_graph(),                      # here is the trick (for now)\n",
    "             # saving  \n",
    "    show_shapes=True, show_layer_names=True,  # show shapes and layer name\n",
    "    expand_nested=False                       # will show nested block\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_method = model_configs.MODEL_MAP[\"swin_tiny_patch244_window877_kinetics400_1k\"]\n",
    "cfg = cfg_method()\n",
    "\n",
    "name = cfg[\"name\"]\n",
    "link = cfg['link']\n",
    "del cfg[\"name\"]\n",
    "del cfg['link']\n",
    "\n",
    "pt_model = SwinTransformer3D_pt(**cfg)\n",
    "\n",
    "checkpoint = torch.load(f'{name}.pth')\n",
    "\n",
    "\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in checkpoint['state_dict'].items():\n",
    "    if 'backbone' in k:\n",
    "        name = k[9:]\n",
    "        new_state_dict[name] = v \n",
    "\n",
    "pt_model.load_state_dict(new_state_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf_model.predict(x_tf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = pt_model(x_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.round(y, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "z.shape , y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_state_dict = pt_model.state_dict()\n",
    "np_state_dict = {k: np_state_dict[k].numpy() for k in np_state_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(np_state_dict['patch_embed.proj.bias'] ,tf_model.projection.layers[0].bias.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "for weight in tf_model.weights:\n",
    "    i +=1\n",
    "    if \"dense\" in weight.name:\n",
    "        \n",
    "        isEqual = np.array_equal(weight.numpy(),np_state_dict[tf_pt[weight.name]].transpose() )\n",
    "    else:\n",
    "        isEqual = np.array_equal(weight.numpy(),np_state_dict[tf_pt[weight.name]] )\n",
    "\n",
    "    if not isEqual:\n",
    "        print(weight.name, weight.numpy().shape , np_state_dict[tf_pt[weight.name]].shape )\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "tf_pt = {}\n",
    "  \n",
    "# Opening JSON file\n",
    "f = open('data.json')\n",
    "  \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "f.close()\n",
    "# Iterating through the json\n",
    "# list\n",
    "for idx, layer in enumerate(data):\n",
    "    # print(idx, layer, \"------\" ,  data[layer])\n",
    "    tf_pt[data[layer]] = layer\n",
    "  \n",
    "# Closing file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.normal([100,3,8, 224,224])\n",
    "y = tf.random.uniform(shape=[100], minval=0, maxval=5, dtype='int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-15 17:46:27.432373: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swin_transformer_block3d_24 0.0\n",
      "call\n",
      "forward_part2\n",
      "swin_transformer_block3d_25 0.018181818181818184\n",
      "call\n",
      "--------drop_path (10, 2, 56, 56, 96) (10, 1, 1, 1, 1) random (10, 1, 1, 1, 1)\n",
      "droppath output: (10, 2, 56, 56, 96)\n",
      "forward_part2\n",
      "--------drop_path (10, 2, 56, 56, 96) (10, 1, 1, 1, 1) random (10, 1, 1, 1, 1)\n",
      "droppath output: (10, 2, 56, 56, 96)\n",
      "swin_transformer_block3d_26 0.03636363636363637\n",
      "call\n",
      "--------drop_path (10, 2, 28, 28, 192) (10, 1, 1, 1, 1) random (10, 1, 1, 1, 1)\n",
      "droppath output: (10, 2, 28, 28, 192)\n",
      "forward_part2\n",
      "--------drop_path (10, 2, 28, 28, 192) (10, 1, 1, 1, 1) random (10, 1, 1, 1, 1)\n",
      "droppath output: (10, 2, 28, 28, 192)\n",
      "swin_transformer_block3d_27 0.05454545454545455\n",
      "call\n",
      "--------drop_path (10, 2, 28, 28, 192) (10, 1, 1, 1, 1) random (10, 1, 1, 1, 1)\n",
      "droppath output: (10, 2, 28, 28, 192)\n",
      "forward_part2\n",
      "--------drop_path (10, 2, 28, 28, 192) (10, 1, 1, 1, 1) random (10, 1, 1, 1, 1)\n",
      "droppath output: (10, 2, 28, 28, 192)\n",
      "swin_transformer_block3d_28 0.07272727272727274\n",
      "call\n",
      "--------drop_path (10, 2, 14, 14, 384) (10, 1, 1, 1, 1) random (10, 1, 1, 1, 1)\n",
      "droppath output: (10, 2, 14, 14, 384)\n",
      "forward_part2\n",
      "--------drop_path (10, 2, 14, 14, 384) (10, 1, 1, 1, 1) random (10, 1, 1, 1, 1)\n",
      "droppath output: (10, 2, 14, 14, 384)\n",
      "swin_transformer_block3d_29 0.09090909090909093\n",
      "call\n",
      "--------drop_path (10, 2, 14, 14, 384) (10, 1, 1, 1, 1) random (10, 1, 1, 1, 1)\n",
      "droppath output: (10, 2, 14, 14, 384)\n",
      "forward_part2\n",
      "--------drop_path (10, 2, 14, 14, 384) (10, 1, 1, 1, 1) random (10, 1, 1, 1, 1)\n",
      "droppath output: (10, 2, 14, 14, 384)\n",
      "swin_transformer_block3d_30 0.1090909090909091\n",
      "call\n",
      "--------drop_path (10, 2, 14, 14, 384) (10, 1, 1, 1, 1) random (10, 1, 1, 1, 1)\n",
      "droppath output: (10, 2, 14, 14, 384)\n",
      "forward_part2\n",
      "--------drop_path (10, 2, 14, 14, 384) (10, 1, 1, 1, 1) random (10, 1, 1, 1, 1)\n",
      "droppath output: (10, 2, 14, 14, 384)\n",
      "swin_transformer_block3d_31 0.1272727272727273\n",
      "call\n",
      "--------drop_path (10, 2, 14, 14, 384) (10, 1, 1, 1, 1) random (10, 1, 1, 1, 1)\n",
      "droppath output: (10, 2, 14, 14, 384)\n",
      "forward_part2\n",
      "--------drop_path (10, 2, 14, 14, 384) (10, 1, 1, 1, 1) random (10, 1, 1, 1, 1)\n",
      "droppath output: (10, 2, 14, 14, 384)\n",
      "swin_transformer_block3d_32 0.14545454545454548\n",
      "call\n",
      "--------drop_path (10, 2, 14, 14, 384) (10, 1, 1, 1, 1) random (10, 1, 1, 1, 1)\n",
      "droppath output: (10, 2, 14, 14, 384)\n",
      "forward_part2\n",
      "--------drop_path (10, 2, 14, 14, 384) (10, 1, 1, 1, 1) random (10, 1, 1, 1, 1)\n",
      "droppath output: (10, 2, 14, 14, 384)\n",
      "swin_transformer_block3d_33 0.16363636363636366\n",
      "call\n",
      "--------drop_path (10, 2, 14, 14, 384) (10, 1, 1, 1, 1) random (10, 1, 1, 1, 1)\n",
      "droppath output: (10, 2, 14, 14, 384)\n",
      "forward_part2\n",
      "--------drop_path (10, 2, 14, 14, 384) (10, 1, 1, 1, 1) random (10, 1, 1, 1, 1)\n",
      "droppath output: (10, 2, 14, 14, 384)\n",
      "swin_transformer_block3d_34 0.18181818181818185\n",
      "call\n",
      "--------drop_path (10, 2, 7, 7, 768) (10, 1, 1, 1, 1) random (10, 1, 1, 1, 1)\n",
      "droppath output: (10, 2, 7, 7, 768)\n",
      "forward_part2\n",
      "--------drop_path (10, 2, 7, 7, 768) (10, 1, 1, 1, 1) random (10, 1, 1, 1, 1)\n",
      "droppath output: (10, 2, 7, 7, 768)\n",
      "swin_transformer_block3d_35 0.2\n",
      "call\n",
      "--------drop_path (10, 2, 7, 7, 768) (10, 1, 1, 1, 1) random (10, 1, 1, 1, 1)\n",
      "droppath output: (10, 2, 7, 7, 768)\n",
      "forward_part2\n",
      "--------drop_path (10, 2, 7, 7, 768) (10, 1, 1, 1, 1) random (10, 1, 1, 1, 1)\n",
      "droppath output: (10, 2, 7, 7, 768)\n",
      "swin_transformer_block3d_24 0.0\n",
      "call\n",
      "forward_part2\n",
      "swin_transformer_block3d_25 0.018181818181818184\n",
      "call\n",
      "--------drop_path (10, 2, 56, 56, 96) (10, 1, 1, 1, 1) random (10, 1, 1, 1, 1)\n",
      "droppath output: (10, 2, 56, 56, 96)\n",
      "forward_part2\n",
      "--------drop_path (10, 2, 56, 56, 96) (10, 1, 1, 1, 1) random (10, 1, 1, 1, 1)\n",
      "droppath output: (10, 2, 56, 56, 96)\n",
      "swin_transformer_block3d_26 0.03636363636363637\n",
      "call\n",
      "--------drop_path (10, 2, 28, 28, 192) (10, 1, 1, 1, 1) random (10, 1, 1, 1, 1)\n",
      "droppath output: (10, 2, 28, 28, 192)\n",
      "forward_part2\n",
      "--------drop_path (10, 2, 28, 28, 192) (10, 1, 1, 1, 1) random (10, 1, 1, 1, 1)\n",
      "droppath output: (10, 2, 28, 28, 192)\n",
      "swin_transformer_block3d_27 0.05454545454545455\n",
      "call\n",
      "--------drop_path (10, 2, 28, 28, 192) (10, 1, 1, 1, 1) random (10, 1, 1, 1, 1)\n",
      "droppath output: (10, 2, 28, 28, 192)\n",
      "forward_part2\n",
      "--------drop_path (10, 2, 28, 28, 192) (10, 1, 1, 1, 1) random (10, 1, 1, 1, 1)\n",
      "droppath output: (10, 2, 28, 28, 192)\n",
      "swin_transformer_block3d_28 0.07272727272727274\n",
      "call\n",
      "--------drop_path (10, 2, 14, 14, 384) (10, 1, 1, 1, 1) random (10, 1, 1, 1, 1)\n",
      "droppath output: (10, 2, 14, 14, 384)\n",
      "forward_part2\n",
      "--------drop_path (10, 2, 14, 14, 384) (10, 1, 1, 1, 1) random (10, 1, 1, 1, 1)\n",
      "droppath output: (10, 2, 14, 14, 384)\n",
      "swin_transformer_block3d_29 0.09090909090909093\n",
      "call\n",
      "--------drop_path (10, 2, 14, 14, 384) (10, 1, 1, 1, 1) random (10, 1, 1, 1, 1)\n",
      "droppath output: (10, 2, 14, 14, 384)\n",
      "forward_part2\n",
      "--------drop_path (10, 2, 14, 14, 384) (10, 1, 1, 1, 1) random (10, 1, 1, 1, 1)\n",
      "droppath output: (10, 2, 14, 14, 384)\n",
      "swin_transformer_block3d_30 0.1090909090909091\n",
      "call\n",
      "--------drop_path (10, 2, 14, 14, 384) (10, 1, 1, 1, 1) random (10, 1, 1, 1, 1)\n",
      "droppath output: (10, 2, 14, 14, 384)\n",
      "forward_part2\n",
      "--------drop_path (10, 2, 14, 14, 384) (10, 1, 1, 1, 1) random (10, 1, 1, 1, 1)\n",
      "droppath output: (10, 2, 14, 14, 384)\n",
      "swin_transformer_block3d_31 0.1272727272727273\n",
      "call\n",
      "--------drop_path (10, 2, 14, 14, 384) (10, 1, 1, 1, 1) random (10, 1, 1, 1, 1)\n",
      "droppath output: (10, 2, 14, 14, 384)\n",
      "forward_part2\n",
      "--------drop_path (10, 2, 14, 14, 384) (10, 1, 1, 1, 1) random (10, 1, 1, 1, 1)\n",
      "droppath output: (10, 2, 14, 14, 384)\n",
      "swin_transformer_block3d_32 0.14545454545454548\n",
      "call\n",
      "--------drop_path (10, 2, 14, 14, 384) (10, 1, 1, 1, 1) random (10, 1, 1, 1, 1)\n",
      "droppath output: (10, 2, 14, 14, 384)\n",
      "forward_part2\n",
      "--------drop_path (10, 2, 14, 14, 384) (10, 1, 1, 1, 1) random (10, 1, 1, 1, 1)\n",
      "droppath output: (10, 2, 14, 14, 384)\n",
      "swin_transformer_block3d_33 0.16363636363636366\n",
      "call\n",
      "--------drop_path (10, 2, 14, 14, 384) (10, 1, 1, 1, 1) random (10, 1, 1, 1, 1)\n",
      "droppath output: (10, 2, 14, 14, 384)\n",
      "forward_part2\n",
      "--------drop_path (10, 2, 14, 14, 384) (10, 1, 1, 1, 1) random (10, 1, 1, 1, 1)\n",
      "droppath output: (10, 2, 14, 14, 384)\n",
      "swin_transformer_block3d_34 0.18181818181818185\n",
      "call\n",
      "--------drop_path (10, 2, 7, 7, 768) (10, 1, 1, 1, 1) random (10, 1, 1, 1, 1)\n",
      "droppath output: (10, 2, 7, 7, 768)\n",
      "forward_part2\n",
      "--------drop_path (10, 2, 7, 7, 768) (10, 1, 1, 1, 1) random (10, 1, 1, 1, 1)\n",
      "droppath output: (10, 2, 7, 7, 768)\n",
      "swin_transformer_block3d_35 0.2\n",
      "call\n",
      "--------drop_path (10, 2, 7, 7, 768) (10, 1, 1, 1, 1) random (10, 1, 1, 1, 1)\n",
      "droppath output: (10, 2, 7, 7, 768)\n",
      "forward_part2\n",
      "--------drop_path (10, 2, 7, 7, 768) (10, 1, 1, 1, 1) random (10, 1, 1, 1, 1)\n",
      "droppath output: (10, 2, 7, 7, 768)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/mohammadshoaib/Codes/tensorflow-test/env/lib/python3.8/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/mohammadshoaib/Codes/tensorflow-test/env/lib/python3.8/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/mohammadshoaib/Codes/tensorflow-test/env/lib/python3.8/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/mohammadshoaib/Codes/tensorflow-test/env/lib/python3.8/site-packages/keras/engine/training.py\", line 890, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Users/mohammadshoaib/Codes/tensorflow-test/env/lib/python3.8/site-packages/keras/engine/training.py\", line 948, in compute_loss\n        return self.compiled_loss(\n    File \"/Users/mohammadshoaib/Codes/tensorflow-test/env/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Users/mohammadshoaib/Codes/tensorflow-test/env/lib/python3.8/site-packages/keras/losses.py\", line 139, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/Users/mohammadshoaib/Codes/tensorflow-test/env/lib/python3.8/site-packages/keras/losses.py\", line 243, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Users/mohammadshoaib/Codes/tensorflow-test/env/lib/python3.8/site-packages/keras/losses.py\", line 1327, in mean_squared_error\n        return backend.mean(tf.math.squared_difference(y_pred, y_true), axis=-1)\n\n    ValueError: Dimensions must be equal, but are 6 and 10 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_FLOAT](sequential/dense_153/BiasAdd, mean_squared_error/Cast)' with input shapes: [10,768,2,7,6], [10].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/mohammadshoaib/Codes/tensorflow-test/GSOC-22-Video-Swin-Transformers/test.ipynb Cell 28\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mohammadshoaib/Codes/tensorflow-test/GSOC-22-Video-Swin-Transformers/test.ipynb#ch0000026?line=3'>4</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msgd\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mohammadshoaib/Codes/tensorflow-test/GSOC-22-Video-Swin-Transformers/test.ipynb#ch0000026?line=4'>5</a>\u001b[0m \u001b[39m# This builds the model for the first time:\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mohammadshoaib/Codes/tensorflow-test/GSOC-22-Video-Swin-Transformers/test.ipynb#ch0000026?line=5'>6</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(x, y, batch_size\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
      "File \u001b[0;32m~/Codes/tensorflow-test/env/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/wm/qf7lbrys65zfbzv7f458sctm0000gn/T/__autograph_generated_fileyfbx0_dt.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/mohammadshoaib/Codes/tensorflow-test/env/lib/python3.8/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/mohammadshoaib/Codes/tensorflow-test/env/lib/python3.8/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/mohammadshoaib/Codes/tensorflow-test/env/lib/python3.8/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/mohammadshoaib/Codes/tensorflow-test/env/lib/python3.8/site-packages/keras/engine/training.py\", line 890, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Users/mohammadshoaib/Codes/tensorflow-test/env/lib/python3.8/site-packages/keras/engine/training.py\", line 948, in compute_loss\n        return self.compiled_loss(\n    File \"/Users/mohammadshoaib/Codes/tensorflow-test/env/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Users/mohammadshoaib/Codes/tensorflow-test/env/lib/python3.8/site-packages/keras/losses.py\", line 139, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/Users/mohammadshoaib/Codes/tensorflow-test/env/lib/python3.8/site-packages/keras/losses.py\", line 243, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Users/mohammadshoaib/Codes/tensorflow-test/env/lib/python3.8/site-packages/keras/losses.py\", line 1327, in mean_squared_error\n        return backend.mean(tf.math.squared_difference(y_pred, y_true), axis=-1)\n\n    ValueError: Dimensions must be equal, but are 6 and 10 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_FLOAT](sequential/dense_153/BiasAdd, mean_squared_error/Cast)' with input shapes: [10,768,2,7,6], [10].\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(SwinTransformer3D())\n",
    "model.add(tf.keras.layers.Dense(6))\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "# This builds the model for the first time:\n",
    "model.fit(x, y, batch_size=10, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'swin' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/mohammadshoaib/Codes/tensorflow-test/GSOC-22-Video-Swin-Transformers/test.ipynb Cell 29\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mohammadshoaib/Codes/tensorflow-test/GSOC-22-Video-Swin-Transformers/test.ipynb#ch0000027?line=0'>1</a>\u001b[0m x  \u001b[39m=\u001b[39m swin(x)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'swin' is not defined"
     ]
    }
   ],
   "source": [
    "x  = swin(x)\n",
    "#print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# swin.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.constant(-100, dtype= 'float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "from keras.layers import Conv3D , LayerNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 96\n",
    "patch_size = (2,7,7)\n",
    "\n",
    "projection = tf.keras.Sequential(\n",
    "[\n",
    "    Conv3D(\n",
    "        embed_dim ,kernel_size = patch_size , strides= patch_size , padding=\"valid\", name= \"conv_projection\"\n",
    "    )\n",
    "],\n",
    "name = \"projection\"\n",
    ")   # data_format= \"channels_first\"\n",
    "\n",
    "projection.add(LayerNormalization(epsilon=1e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pt = torch.rand( (1,3, 8,224,224)) * 255\n",
    "x_np = x_pt.numpy()\n",
    "x_tf = tf.convert_to_tensor(x_np)\n",
    "x_tf = tf.transpose(x_tf, perm=(0,2,3,4,1))\n",
    "x_tf = tf.cast(x_tf, dtype= tf.float32)\n",
    "\n",
    "x_tf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "from VideoSwinTransformer import model_configs , SwinTransformer3D_pt\n",
    "from collections import OrderedDict\n",
    "\n",
    "tf_model = tf.keras.models.load_model('/Users/mohammadshoaib/Codes/tensorflow-test/GSOC-22-Video-Swin-Transformers/swin_tiny_patch244_window877_kinetics400_1k_tf')\n",
    "\n",
    "\n",
    "\n",
    "cfg_method = model_configs.MODEL_MAP[\"swin_tiny_patch244_window877_kinetics400_1k\"]\n",
    "cfg = cfg_method()\n",
    "\n",
    "name = cfg[\"name\"]\n",
    "link = cfg['link']\n",
    "del cfg[\"name\"]\n",
    "del cfg['link']\n",
    "\n",
    "pt_model = SwinTransformer3D_pt(**cfg)\n",
    "\n",
    "checkpoint = torch.load(f'{name}.pth')\n",
    "\n",
    "\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in checkpoint['state_dict'].items():\n",
    "    if 'backbone' in k:\n",
    "        name = k[9:]\n",
    "        new_state_dict[name] = v \n",
    "\n",
    "pt_model.load_state_dict(new_state_dict) \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 3, 8, 224, 224])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pt = torch.rand( (1,3, 8,224,224)) * 255\n",
    "x_np = x_pt.numpy()\n",
    "x_tf = tf.convert_to_tensor(x_np)\n",
    "x_tf = tf.cast(x_tf, dtype= tf.float32)\n",
    "\n",
    "x_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y = tf_model(x_tf)\n",
    "z = pt_model(x_pt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# patch embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, LayerNormalization \n",
    "\n",
    "from tensorflow.keras.layers import  Conv3D\n",
    "\n",
    "class PatchEmbed3D(tf.keras.Model):\n",
    "    def __init__(self, patch_size=(2, 4, 4), in_chans=3, embed_dim=96, norm_layer=None):\n",
    "        super().__init__(name='patch_embed')\n",
    "\n",
    "        \n",
    "        self.patch_size = patch_size\n",
    "        self.in_chans = in_chans\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "        \n",
    "        self.proj = Conv3D(embed_dim, kernel_size=patch_size,\n",
    "                           strides=patch_size, name='embed_proj')\n",
    "        \n",
    "        if norm_layer is not None:\n",
    "            self.norm = norm_layer(epsilon=1e-5, name='embed_norm')\n",
    "        else:\n",
    "            self.norm = None\n",
    "\n",
    "    def call(self, x):\n",
    "        B, C, D, H, W = x.get_shape().as_list()\n",
    "        x = tf.transpose(x, perm=[0, 2,3,4, 1 ])\n",
    "\n",
    "        x = self.proj(x)\n",
    "        x = tf.transpose(x, perm=[0, 4, 1, 2,3 ])\n",
    "\n",
    "        print(x.shape)\n",
    "        \n",
    "        if self.norm is not None:\n",
    "            \n",
    "          B, C, D, Wh, Ww = x.shape\n",
    "          x  = tf.reshape(x, shape=[B, C, -1])\n",
    "          x = tf.transpose(x, perm=[0 , 2, 1])   \n",
    "          x = self.norm(x)\n",
    "          x   = tf.transpose(x, perm=[0,2,1])\n",
    "\n",
    "          x = tf.reshape(x, shape=[-1, self.embed_dim, D, Wh, Ww])\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "\n",
    "class PatchEmbed3D_pt(nn.Module):\n",
    "    \"\"\" Video to Patch Embedding.\n",
    "    Args:\n",
    "        patch_size (int): Patch token size. Default: (2,4,4).\n",
    "        in_chans (int): Number of input video channels. Default: 3.\n",
    "        embed_dim (int): Number of linear projection output channels. Default: 96.\n",
    "        norm_layer (nn.Module, optional): Normalization layer. Default: None\n",
    "    \"\"\"\n",
    "    def __init__(self, patch_size=(2,4,4), in_chans=3, embed_dim=96, norm_layer=None):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "        self.in_chans = in_chans\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "        self.proj = nn.Conv3d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "        if norm_layer is not None:\n",
    "            self.norm = norm_layer(embed_dim)\n",
    "        else:\n",
    "            self.norm = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward function.\"\"\"\n",
    "        # padding\n",
    "        _, _, D, H, W = x.size()\n",
    "        if W % self.patch_size[2] != 0:\n",
    "            x = F.pad(x, (0, self.patch_size[2] - W % self.patch_size[2]))\n",
    "        if H % self.patch_size[1] != 0:\n",
    "            x = F.pad(x, (0, 0, 0, self.patch_size[1] - H % self.patch_size[1]))\n",
    "        if D % self.patch_size[0] != 0:\n",
    "            x = F.pad(x, (0, 0, 0, 0, 0, self.patch_size[0] - D % self.patch_size[0]))\n",
    "\n",
    "        x = self.proj(x)  # B C D Wh Ww\n",
    "        print(x.shape)\n",
    "        \n",
    "        if self.norm is not None:\n",
    "            D, Wh, Ww = x.size(2), x.size(3), x.size(4)\n",
    "            x = x.flatten(2).transpose(1, 2)\n",
    "            # print(\"befor norm\",)\n",
    "            x = self.norm(x)\n",
    "            x = x.transpose(1, 2).view(-1, self.embed_dim, D, Wh, Ww)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 3, 8, 224, 224])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pt = torch.rand( (1,3, 8,224,224)) * 255\n",
    "x = x_pt\n",
    "x_np = x_pt.numpy()\n",
    "x_tf = tf.convert_to_tensor(x_np)\n",
    "x_tf = tf.cast(x_tf, dtype= tf.float32)\n",
    "\n",
    "x_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 96, 4, 56, 56)\n",
      "before norm (1, 12544, 96)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 96, 4, 56, 56])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense, LayerNormalization \n",
    "\n",
    "embed_tf = PatchEmbed3D(norm_layer = LayerNormalization)\n",
    "y = embed_tf(x_tf)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 96, 4, 56, 56])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 96, 4, 56, 56])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_pt = PatchEmbed3D_pt(norm_layer= nn.LayerNorm)\n",
    "z = embed_pt(x_pt)\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([-1.2639916 , -0.78281635, -0.8455795 , -0.710238  , -0.19718258,\n",
       "        -0.72028524, -0.5592406 , -1.1893481 , -0.5930738 , -0.73154336],\n",
       "       dtype=float32)>,\n",
       " tensor([ 0.3762,  0.3977,  0.7044,  0.3100, -0.6468, -0.1419,  0.8184,  0.3125,\n",
       "          0.6354, -0.2273], grad_fn=<SliceBackward0>))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y[0][0][0][0][:10] , z[0][0][0][0][:10]\n",
    "# y[0][0][:10] , z[0][0][:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight =  embed_pt.proj.weight.detach().numpy().transpose(2,3,4,1, 0)\n",
    "bias =  embed_pt.proj.bias.detach().numpy()\n",
    "embed_tf.layers[0].kernel.assign(tf.Variable(weight))\n",
    "\n",
    "embed_tf.layers[0].bias.assign(tf.Variable(bias))\n",
    "2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight =  embed_pt.norm.weight.detach().numpy()\n",
    "bias =  embed_pt.norm.bias.detach().numpy()\n",
    "\n",
    "embed_tf.layers[1].gamma.assign(tf.Variable(weight))\n",
    "\n",
    "embed_tf.layers[1].beta.assign(tf.Variable(bias))\n",
    "2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 96, 4, 56, 56)\n",
      "before norm (1, 12544, 96)\n",
      "torch.Size([1, 96, 4, 56, 56])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([ 0.37624246,  0.39773557,  0.70437413,  0.3099548 , -0.64680463,\n",
       "        -0.14188464,  0.8184127 ,  0.3125044 ,  0.6353974 , -0.22726098],\n",
       "       dtype=float32)>,\n",
       " tensor([ 0.3762,  0.3977,  0.7044,  0.3100, -0.6468, -0.1419,  0.8184,  0.3125,\n",
       "          0.6354, -0.2273], grad_fn=<SliceBackward0>))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = embed_tf(x_tf)\n",
    "z= embed_pt(x_pt)\n",
    "y[0][0][0][0][:10] , z[0][0][0][0][:10]\n",
    "# y[0][0][:10] , z[0][0][:10]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 96, 4, 56, 56]), TensorShape([1, 96, 4, 56, 56]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D, Wh, Ww = 4, 56,56\n",
    "\n",
    "p = z.transpose(1, 2).view(-1, 96, D, Wh, Ww)\n",
    "# t = tf.reshape(y, shape=[-1, 96, D, Wh, Ww])\n",
    "t = tf.transpose(y, perm=[0,2,1])\n",
    "t = tf.reshape(t, shape=[-1, 96, D, Wh, Ww])\n",
    "\n",
    "p.shape , t.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([-0.20116119, -0.52701443, -1.136614  , -0.4714968 , -0.7071789 ,\n",
       "        -0.27072585, -0.88227797, -0.2475861 , -0.71975875, -0.62322253],\n",
       "       dtype=float32)>,\n",
       " tensor([-0.2012, -0.5270, -1.1366, -0.4715, -0.7072, -0.2707, -0.8823, -0.2476,\n",
       "         -0.7198, -0.6232], grad_fn=<SliceBackward0>))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0][0][0][0][:10] , p[0][0][0][0][:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 96, 4, 56, 56]),\n",
       " array([-0.20116149, -0.52701443, -1.136614  , -0.47149682, -0.70717895,\n",
       "        -0.2707259 , -0.8822782 , -0.24758588, -0.7197586 , -0.62322253],\n",
       "       dtype=float32),\n",
       " TensorShape([1, 96, 4, 56, 56]),\n",
       " array([-0.20116119,  0.12976661,  0.52783096,  1.2042438 ,  0.7386352 ,\n",
       "        -0.12640192,  0.02800749, -0.17163655, -0.8298298 , -0.89152586],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.shape, p.detach().numpy()[0][0][0][0][:10] ,t.shape, t.numpy()[0][0][0][0][:10] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, LayerNormalization \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_tf = LayerNormalization(epsilon=1e-5)\n",
    "norm_pt = nn.LayerNorm(96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 12544, 96])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pt = torch.rand((1, 12544, 96)) \n",
    "x_np = x_pt.numpy()\n",
    "x_tf = tf.convert_to_tensor(x_np)\n",
    "x_tf = tf.cast(x_tf, dtype= tf.float32)\n",
    "\n",
    "x_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 12544, 96]), torch.Size([1, 12544, 96]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_tf = LayerNormalization(epsilon=1e-5)\n",
    "\n",
    "y = norm_tf(x_tf)\n",
    "z = norm_pt(x_pt)\n",
    "\n",
    "y.shape, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([-1.4981018 , -0.21096003,  0.51682377, -1.0697355 ,  0.84019566,\n",
       "        -1.2803504 , -1.7036974 ,  0.16494644, -1.3300749 ,  1.2140329 ],\n",
       "       dtype=float32)>,\n",
       " tensor([-1.4981, -0.2110,  0.5168, -1.0697,  0.8402, -1.2804, -1.7037,  0.1649,\n",
       "         -1.3301,  1.2140], grad_fn=<SliceBackward0>))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0][0][:10] ,z[0][0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 96, 4, 56, 56])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 96, 4, 56, 56])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_pt = PatchEmbed3D_pt()\n",
    "x = embed_pt(x_pt)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12544, 96])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D, Wh, Ww = x.size(2), x.size(3), x.size(4)\n",
    "z = x.flatten(2).transpose(1, 2)\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_np = x.detach().numpy()\n",
    "x_tf = tf.convert_to_tensor(x_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "B, C, D, Wh, Ww = x_tf.shape\n",
    "y = tf.reshape(x_tf, shape=[B, C, -1])\n",
    "y = tf.transpose(y, perm=[0 , 2, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 12544, 96]), torch.Size([1, 12544, 96]))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"(1,4)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '4']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "18e9ffd7bdaebed3141c5f1e6e3ffefff8dc763f7fe0a2903683245d14d535a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
