{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7ff177839160>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from VideoSwinTransformer import *\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "torch.set_grad_enabled(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x(shape= (4,3,32,224,224)):\n",
    "    x_pt = torch.rand(shape) * 255\n",
    "    x_np = x_pt.numpy()\n",
    "    x_tf = tf.convert_to_tensor(x_np)\n",
    "\n",
    "    return x_tf, x_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-04 09:13:42.756057: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-09-04 09:13:42.756127: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (gsoc): /proc/driver/nvidia/version does not exist\n",
      "2022-09-04 09:13:42.756869: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "shape_of_input = [4,3,32,224,224]\n",
    "x_tf, x_pt = get_x(shape_of_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_method = model_configs.MODEL_MAP[\"swin_tiny_patch244_window877_kinetics400_1k\"]\n",
    "cfg = cfg_method()\n",
    "\n",
    "name = cfg[\"name\"]\n",
    "link = cfg['link']\n",
    "del cfg[\"name\"]\n",
    "del cfg['link']\n",
    "del cfg[\"drop_path_rate\"]\n",
    "# download_weight_command = f\"wget {link} -O {name}.pth\"\n",
    "# os.system(download_weight_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape_of_input [4, 3, 32, 224, 224]\n",
      "pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py38/lib/python3.8/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++\n",
      " tf\n",
      "shape_of_input:  [4, 3, 32, 224, 224]\n",
      "\n",
      "\n",
      "\n",
      " pt\n",
      "------- \n",
      " tf\n",
      "patch embed (4, 96, 16, 56, 56)\n",
      "(4, 96, 50176)\n",
      "\n",
      " loading checkpoint\n"
     ]
    }
   ],
   "source": [
    "print(\"shape_of_input\", shape_of_input)\n",
    "print(\"pt\")\n",
    "pt_model = SwinTransformer3D_pt(**cfg,drop_rate=0.4, drop_path_rate=0.)\n",
    "print(\"++++++++\\n tf\")\n",
    "tf_model = SwinTransformer3D(**cfg,shape_of_input=shape_of_input, drop_rate=0.4, drop_path_rate=0.)\n",
    "x_tf, x_pt = get_x()\n",
    "\n",
    "\n",
    "print(\"\\n\\n\\n pt\")\n",
    "z= pt_model(x_pt)\n",
    "print(\"------- \\n tf\")\n",
    "# x  = tf.keras.layers.Input(tensor=x_tf)\n",
    "\n",
    "y = tf_model(x_tf, training= False)\n",
    "\n",
    "print(\"\\n loading checkpoint\")\n",
    "checkpoint = torch.load(f'{name}.pth')\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in checkpoint['state_dict'].items():\n",
    "    if 'backbone' in k:\n",
    "        name = k[9:]\n",
    "        new_state_dict[name] = v \n",
    "\n",
    "pt_model.load_state_dict(new_state_dict) \n",
    "pt_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_transpose(w):\n",
    "    return w.transpose(2,3,4,1, 0)\n",
    "    \n",
    "\n",
    "def modify_tf_block( tf_component, pt_weight,  pt_bias = None, is_attn=False):\n",
    "    in_shape = pt_weight.shape\n",
    "\n",
    "    if isinstance(tf_component, tf.keras.layers.Conv3D) :\n",
    "      pt_weight = conv_transpose(pt_weight)\n",
    "\n",
    "    if isinstance(tf_component, tf.keras.layers.Dense) and not is_attn:\n",
    "      pt_weight =pt_weight.transpose()\n",
    "\n",
    "    if isinstance(tf_component, (tf.keras.layers.Dense, tf.keras.layers.Conv3D)):\n",
    "        tf_component.kernel.assign(tf.Variable(pt_weight))\n",
    "\n",
    "        if pt_bias is not None:\n",
    "            tf_component.bias.assign(tf.Variable(pt_bias))\n",
    "\n",
    "    elif isinstance(tf_component, tf.keras.layers.LayerNormalization):\n",
    "\n",
    "        tf_component.gamma.assign(tf.Variable(pt_weight))\n",
    "\n",
    "        tf_component.beta.assign(tf.Variable(pt_bias))\n",
    "\n",
    "    elif isinstance(tf_component, (tf.Variable)):\n",
    "        tf_component.assign(tf.Variable(pt_weight))\n",
    "\n",
    "    else:\n",
    "        return tf.convert_to_tensor(pt_weight)\n",
    "        \n",
    "        \n",
    "\n",
    "    return tf_component\n",
    "\n",
    "\n",
    "def modify_swin_blocks(np_state_dict, pt_weights_prefix, tf_block):\n",
    "\n",
    "  for layer in tf_block:\n",
    "    if isinstance(layer, PatchMerging):\n",
    "      patch_merging_idx = f\"{pt_weights_prefix}.downsample\"\n",
    "\n",
    "      layer.reduction = modify_tf_block( layer.reduction,\n",
    "                          np_state_dict[f\"{patch_merging_idx}.reduction.weight\"])\n",
    "      layer.norm = modify_tf_block( layer.norm,\n",
    "                        np_state_dict[f\"{patch_merging_idx}.norm.weight\"],\n",
    "                        np_state_dict[f\"{patch_merging_idx}.norm.bias\"]\n",
    "                        )\n",
    "      \n",
    "  # Swin Layers\n",
    "  common_prefix = f\"{pt_weights_prefix}.blocks\"\n",
    "  block_idx = 0\n",
    "\n",
    "  for outer_layer in tf_block:\n",
    "\n",
    "      layernorm_idx = 1\n",
    "      mlp_layer_idx = 1\n",
    "\n",
    "      if isinstance(outer_layer, SwinTransformerBlock3D):\n",
    "          for inner_layer in outer_layer.layers:\n",
    "        \n",
    "              # Layer norm.\n",
    "              if isinstance(inner_layer, tf.keras.layers.LayerNormalization):\n",
    "                  layer_norm_prefix = (\n",
    "                      f\"{common_prefix}.{block_idx}.norm{layernorm_idx}\"\n",
    "                  )\n",
    "                  inner_layer.gamma.assign(\n",
    "                      tf.Variable(\n",
    "                          np_state_dict[f\"{layer_norm_prefix}.weight\"]\n",
    "                      )\n",
    "                  )\n",
    "\n",
    "\n",
    "\n",
    "                  inner_layer.beta.assign(\n",
    "                      tf.Variable(np_state_dict[f\"{layer_norm_prefix}.bias\"])\n",
    "                  )\n",
    "\n",
    "                  layernorm_idx += 1\n",
    "\n",
    "              # Window attention.\n",
    "              elif isinstance(inner_layer, WindowAttention3D):\n",
    "                  attn_prefix = f\"{common_prefix}.{block_idx}.attn\"\n",
    "\n",
    "                  # Relative position.\n",
    "                  inner_layer.relative_position_bias_table = (\n",
    "                      modify_tf_block(\n",
    "                          inner_layer.relative_position_bias_table,\n",
    "                          np_state_dict[\n",
    "                              f\"{attn_prefix}.relative_position_bias_table\"\n",
    "                          ] \n",
    "                      )\n",
    "                  )\n",
    "                  inner_layer.relative_position_index = (\n",
    "                      modify_tf_block(\n",
    "                          inner_layer.relative_position_index,\n",
    "                          np_state_dict[\n",
    "                              f\"{attn_prefix}.relative_position_index\"\n",
    "                          ]\n",
    "                      )\n",
    "                  )\n",
    "\n",
    "                  # QKV.\n",
    "                  inner_layer.qkv = modify_tf_block(\n",
    "                      inner_layer.qkv,\n",
    "                      np_state_dict[f\"{attn_prefix}.qkv.weight\"],\n",
    "                      np_state_dict[f\"{attn_prefix}.qkv.bias\"]\n",
    "                  )\n",
    "\n",
    "                  # Projection.\n",
    "                  inner_layer.proj = modify_tf_block(\n",
    "                      inner_layer.proj,\n",
    "                      np_state_dict[f\"{attn_prefix}.proj.weight\"],\n",
    "                      np_state_dict[f\"{attn_prefix}.proj.bias\"]\n",
    "                  )\n",
    "\n",
    "              # MLP.\n",
    "              elif isinstance(inner_layer, tf.keras.Model):\n",
    "                  mlp_prefix = f\"{common_prefix}.{block_idx}.mlp\"\n",
    "                  for mlp_layer in inner_layer.layers:\n",
    "                      if isinstance(mlp_layer, tf.keras.layers.Dense):\n",
    "                          mlp_layer = modify_tf_block(\n",
    "                              mlp_layer,\n",
    "                              np_state_dict[\n",
    "                                  f\"{mlp_prefix}.fc{mlp_layer_idx}.weight\"\n",
    "                              ],\n",
    "                              np_state_dict[\n",
    "                                  f\"{mlp_prefix}.fc{mlp_layer_idx}.bias\"\n",
    "                              ]\n",
    "                          )\n",
    "                          mlp_layer_idx += 1\n",
    "\n",
    "          block_idx += 1\n",
    "  return tf_block\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_state_dict = pt_model.state_dict()\n",
    "np_state_dict = {k: np_state_dict[k].numpy() for k in np_state_dict}\n",
    "\n",
    "tf_model.projection.layers[0] = modify_tf_block(tf_model.projection.layers[0]\n",
    "        ,\n",
    "        np_state_dict[\"patch_embed.proj.weight\"],\n",
    "        np_state_dict[\"patch_embed.proj.bias\"])\n",
    "\n",
    "tf_model.projection.layers[1] = modify_tf_block(\n",
    "    tf_model.projection.layers[1],\n",
    "    np_state_dict[\"patch_embed.norm.weight\"],\n",
    "    np_state_dict[\"patch_embed.norm.bias\"])\n",
    "\n",
    "\n",
    "layer_normalization_idx = -1\n",
    "\n",
    "tf_model.layers[layer_normalization_idx] = modify_tf_block(\n",
    "    tf_model.layers[layer_normalization_idx] ,\n",
    "    np_state_dict[\"norm.weight\"],\n",
    "    np_state_dict[\"norm.bias\"]\n",
    "    )\n",
    "\n",
    "# swin layers\n",
    "for i in range(2, len(tf_model.layers) - 1):\n",
    "    _ = modify_swin_blocks(np_state_dict,\n",
    "                        f\"layers.{i-2}\",\n",
    "                        tf_model.layers[i].layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patch embed (4, 96, 16, 56, 56)\n",
      "(4, 96, 50176)\n",
      "------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 1, 1, 1, 7), dtype=float32, numpy=\n",
       " array([[[[[ 0.22170477,  0.8330549 , -0.02191872,  0.29629672,\n",
       "             0.04951792,  0.05335392,  0.24042714]]]]], dtype=float32)>,\n",
       " tensor([[[[[ 0.2217,  0.8331, -0.0219,  0.2963,  0.0495,  0.0534,  0.2404]]]]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = tf_model(x_tf, training= False)\n",
    "print(\"------\")\n",
    "z= pt_model(x_pt)\n",
    "\n",
    "y.shape, z.shape, \n",
    "y[:1,:1,:1,:1,:10], z[:1,:1,:1,:1,:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing the outputs\n",
    "np.testing.assert_allclose(y.numpy(), z.detach().numpy(), 1e-4, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model \n",
      " \n",
      " =============================================\n",
      "patch embed (None, 96, 16, 56, 56)\n",
      "(None, 96, 50176)\n",
      "patch embed (None, 96, 16, 56, 56)\n",
      "(None, 96, 50176)\n",
      "patch embed (None, 96, 16, 56, 56)\n",
      "(None, 96, 50176)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-04 09:14:46.429010: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patch embed (None, 96, 16, 56, 56)\n",
      "(None, 96, 50176)\n",
      "patch embed (None, 96, 16, 56, 56)\n",
      "(None, 96, 50176)\n",
      "patch embed (None, 96, 16, 56, 56)\n",
      "(None, 96, 50176)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dense_8_layer_call_fn, dense_8_layer_call_and_return_conditional_losses, layer_normalization_4_layer_call_fn, layer_normalization_4_layer_call_and_return_conditional_losses, dense_17_layer_call_fn while saving (showing 5 of 270). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/model_tiny/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/model_tiny/assets\n"
     ]
    }
   ],
   "source": [
    "print(\"saving model \\n \\n\",\"=============================================\")\n",
    "\n",
    "tf_model.save(\"weights/model_tiny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "tf_model_loaded = tf.keras.models.load_model('weights/model_tiny')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"swin_transformer3d\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " projection (PatchEmbed3D)   multiple                  9504      \n",
      "                                                                 \n",
      " dropout (Dropout)           multiple                  0         \n",
      "                                                                 \n",
      " basic_layer (BasicLayer)    multiple                  620714    \n",
      "                                                                 \n",
      " basic_layer_1 (BasicLayer)  multiple                  1523924   \n",
      "                                                                 \n",
      " basic_layer_2 (BasicLayer)  multiple                  12934008  \n",
      "                                                                 \n",
      " basic_layer_3 (BasicLayer)  multiple                  14604752  \n",
      "                                                                 \n",
      " layer_normalization_27 (Lay  multiple                 1536      \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,694,438\n",
      "Trainable params: 27,850,470\n",
      "Non-trainable params: 1,843,968\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf_model_loaded.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 1, 1, 1, 7), dtype=float32, numpy=\n",
       " array([[[[[ 0.22170477,  0.8330549 , -0.02191872,  0.29629672,\n",
       "             0.04951792,  0.05335392,  0.24042714]]]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 1, 1, 1, 7), dtype=float32, numpy=\n",
       " array([[[[[ 0.22170512,  0.8330553 , -0.02191865,  0.2962963 ,\n",
       "             0.04951816,  0.05335341,  0.2404271 ]]]]], dtype=float32)>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_loaded  = tf_model_loaded(x_tf)\n",
    "y[:1,:1,:1,:1,:10], y_loaded[:1,:1,:1,:1,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_allclose(y.numpy(), y_loaded.numpy(), 1e-4, 1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('azureml_py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d65a8c07f5b6469e0fc613f182488c0dccce05038bbda39e5ac9075c0454d11"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
