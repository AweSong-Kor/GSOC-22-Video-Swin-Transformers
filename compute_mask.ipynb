{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from VideoSwinTransformer import *\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x():\n",
    "    x_pt = torch.rand((1,3,8,224,224))\n",
    "    x_np = x_pt.numpy()\n",
    "    x_tf = tf.convert_to_tensor(x_np)\n",
    "\n",
    "    return x_tf, x_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Python396\\lib\\site-packages\\torch\\functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:2895.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      " before get window size-------mask window size (8, 7, 7) ----mask_shift_size (4, 3, 3) -----Dp Hp Wp 4 56 56\n",
      "mask window size (4, 7, 7) ----mask_shift_size (0, 3, 3) -----Dp Hp Wp 4 56 56\n",
      "attn_mask torch.Size([64, 196, 196])\n",
      "cylic shift (0, 0, 0)\n",
      "cylic shift (4, 3, 3)\n",
      "mask in not none block torch.Size([64, 3, 196, 196]) torch.Size([64, 196, 196])\n",
      "-----------------\n",
      " before get window size-------mask window size (8, 7, 7) ----mask_shift_size (4, 3, 3) -----Dp Hp Wp 4 28 28\n",
      "mask window size (4, 7, 7) ----mask_shift_size (0, 3, 3) -----Dp Hp Wp 4 28 28\n",
      "attn_mask torch.Size([16, 196, 196])\n",
      "cylic shift (0, 0, 0)\n",
      "cylic shift (4, 3, 3)\n",
      "mask in not none block torch.Size([16, 6, 196, 196]) torch.Size([16, 196, 196])\n",
      "-----------------\n",
      " before get window size-------mask window size (8, 7, 7) ----mask_shift_size (4, 3, 3) -----Dp Hp Wp 4 14 14\n",
      "mask window size (4, 7, 7) ----mask_shift_size (0, 3, 3) -----Dp Hp Wp 4 14 14\n",
      "attn_mask torch.Size([4, 196, 196])\n",
      "cylic shift (0, 0, 0)\n",
      "cylic shift (4, 3, 3)\n",
      "mask in not none block torch.Size([4, 12, 196, 196]) torch.Size([4, 196, 196])\n",
      "cylic shift (0, 0, 0)\n",
      "cylic shift (4, 3, 3)\n",
      "mask in not none block torch.Size([4, 12, 196, 196]) torch.Size([4, 196, 196])\n",
      "cylic shift (0, 0, 0)\n",
      "cylic shift (4, 3, 3)\n",
      "mask in not none block torch.Size([4, 12, 196, 196]) torch.Size([4, 196, 196])\n",
      "-----------------\n",
      " before get window size-------mask window size (8, 7, 7) ----mask_shift_size (4, 3, 3) -----Dp Hp Wp 4 7 7\n",
      "mask window size (4, 7, 7) ----mask_shift_size (0, 0, 0) -----Dp Hp Wp 4 7 7\n",
      "attn_mask torch.Size([1, 196, 196])\n",
      "cylic shift (0, 0, 0)\n",
      "cylic shift (4, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cfg_method = model_configs.MODEL_MAP[\"swin_tiny_patch244_window877_kinetics400_1k\"]\n",
    "cfg = cfg_method()\n",
    "\n",
    "name = cfg[\"name\"]\n",
    "link = cfg['link']\n",
    "del cfg[\"name\"]\n",
    "del cfg['link']\n",
    "# download_weight_command = f\"wget {link} -O {name}.pth\"\n",
    "# os.system(download_weight_command)\n",
    "x_tf, x_pt = get_x()\n",
    "\n",
    "pt_model = SwinTransformer3D_pt(**cfg, isTest= True)\n",
    "\n",
    "basic_pt, z= pt_model(x_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "Basic Layer -----------------------------\n",
      " before get window size-------mask window size (8, 7, 7) ----mask_shift_size (4, 3, 3) -----D H W tf.Tensor(4, shape=(), dtype=int32) tf.Tensor(56, shape=(), dtype=int32) tf.Tensor(56, shape=(), dtype=int32) (2, 96, 2, 56, 56)\n",
      "mask window size (4, 7, 7) ----mask_shift_size (0, 3, 3) -----Dp Hp Wp 4 56 56\n",
      "atten mask  (64, 196, 196)\n",
      "cylic shift (0, 0, 0)\n",
      "before win attn (64, 196, 96)\n",
      "cylic shift (4, 3, 3)\n",
      "before win attn (64, 196, 96)\n",
      "mask in not none block (64, 3, 196, 196) (64, 196, 196)\n",
      "Basic Layer -----------------------------\n",
      " before get window size-------mask window size (8, 7, 7) ----mask_shift_size (4, 3, 3) -----D H W tf.Tensor(4, shape=(), dtype=int32) tf.Tensor(28, shape=(), dtype=int32) tf.Tensor(28, shape=(), dtype=int32) (2, 192, 2, 28, 28)\n",
      "mask window size (4, 7, 7) ----mask_shift_size (0, 3, 3) -----Dp Hp Wp 4 28 28\n",
      "atten mask  (16, 196, 196)\n",
      "cylic shift (0, 0, 0)\n",
      "before win attn (16, 196, 192)\n",
      "cylic shift (4, 3, 3)\n",
      "before win attn (16, 196, 192)\n",
      "mask in not none block (16, 6, 196, 196) (16, 196, 196)\n",
      "Basic Layer -----------------------------\n",
      " before get window size-------mask window size (8, 7, 7) ----mask_shift_size (4, 3, 3) -----D H W tf.Tensor(4, shape=(), dtype=int32) tf.Tensor(14, shape=(), dtype=int32) tf.Tensor(14, shape=(), dtype=int32) (2, 384, 2, 14, 14)\n",
      "mask window size (4, 7, 7) ----mask_shift_size (0, 3, 3) -----Dp Hp Wp 4 14 14\n",
      "atten mask  (4, 196, 196)\n",
      "cylic shift (0, 0, 0)\n",
      "before win attn (4, 196, 384)\n",
      "cylic shift (4, 3, 3)\n",
      "before win attn (4, 196, 384)\n",
      "mask in not none block (4, 12, 196, 196) (4, 196, 196)\n",
      "cylic shift (0, 0, 0)\n",
      "before win attn (4, 196, 384)\n",
      "cylic shift (4, 3, 3)\n",
      "before win attn (4, 196, 384)\n",
      "mask in not none block (4, 12, 196, 196) (4, 196, 196)\n",
      "cylic shift (0, 0, 0)\n",
      "before win attn (4, 196, 384)\n",
      "cylic shift (4, 3, 3)\n",
      "before win attn (4, 196, 384)\n",
      "mask in not none block (4, 12, 196, 196) (4, 196, 196)\n",
      "Basic Layer -----------------------------\n",
      " before get window size-------mask window size (8, 7, 7) ----mask_shift_size (4, 3, 3) -----D H W tf.Tensor(4, shape=(), dtype=int32) tf.Tensor(7, shape=(), dtype=int32) tf.Tensor(7, shape=(), dtype=int32) (2, 768, 2, 7, 7)\n",
      "mask window size (4, 7, 7) ----mask_shift_size (0, 0, 0) -----Dp Hp Wp 4 7 7\n",
      "atten mask  (1, 196, 196)\n",
      "cylic shift (0, 0, 0)\n",
      "before win attn (1, 196, 768)\n",
      "cylic shift (4, 3, 3)\n",
      "before win attn (1, 196, 768)\n",
      "mask in not none block (1, 24, 196, 196) (1, 196, 196)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tf_model = SwinTransformer3D(**cfg, isTest= True)\n",
    "\n",
    "basic_tf, z= tf_model(x_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5ed124f2b279c186db57d0ede455df2b109954ad4fa1a5a2c59adb747c894aa2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
