# Module shoaib6174/swin_small_patch244_window877_kinetics400_1k/1
Fine-tunable Video Swin Transformer model pre-trained on the ImageNet-1K dataset and was then fine-tuned on Kinetics 400(1k) dataset.
<!-- asset-path: https://drive.google.com/drive/folders/1ZVbE5Dd2LxT8lDgNgtziyCB1RfbwzvDd/swin_small_patch244_window877_kinetics400_1k.tar.gz  -->
<!-- task: video-classification -->
<!-- network-architecture: video-swin-transformer -->
<!-- format: saved_model_2 -->
<!-- fine-tunable: true -->
<!-- colab: https://colab.research.google.com/drive/1McH0gP3UeD_fEMl4MyGM1vbLOFAS-3Vj -->
## Overview
This model is a Video Swin Transformer [1] pre-trained on the ImageNet-1K dataset and was then fine-tuned on Kinetics 400(1k) dataset. You can find the complete
collection of Swin models on TF-Hub on [this page](https://tfhub.dev/shoaib6174/collections/video-swin).
You can use this model for feature extraction. Please refer to
the Colab Notebook linked on this page for more details.
## Notes
* The original model weights are provided from [2]. They were ported to Keras models
(`tf.keras.Model`) and then serialized as TensorFlow SavedModels. The porting
steps are available in [3].
* The model can be unrolled into a standard Keras model and you can inspect its topology.
To do so, first download the model from TF-Hub and then load it using `tf.keras.models.load_model`
providing the path to the downloaded model folder.
## References
[1] [Video Swin TransformerZe et al.](https://arxiv.org/abs/2106.13230)
[2] [Video Swin Transformers GitHub](https://github.com/SwinTransformer/Video-Swin-Transformerr)
[3] [GSOC-22-Video-Swin-Transformers GitHub](https://github.com/shoaib6174/GSOC-22-Video-Swin-Transformers)

## Acknowledgements
* [Google Summer of Code 2022](https://summerofcode.withgoogle.com/)
* [Luiz GUStavo Martins](https://www.linkedin.com/in/luiz-gustavo-martins-64ab5891/)
* [Sayak Paul](https://www.linkedin.com/in/sayak-paul/)

