{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import tensorflow_addons as tfa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "dataset_name = 'ucf101'\n",
    "ucf101 = tfds.builder(dataset_name)\n",
    "config = tfds.download.DownloadConfig(verify_ssl=False)\n",
    "# ucf101.download_and_prepare(download_config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 101\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tfds.core.DatasetInfo(\n",
       "    name='ucf101',\n",
       "    full_name='ucf101/ucf101_1_256/2.0.0',\n",
       "    description=\"\"\"\n",
       "    A 101-label video classification dataset.\n",
       "    \"\"\",\n",
       "    config_description=\"\"\"\n",
       "    256x256 UCF with the first action recognition split.\n",
       "    \"\"\",\n",
       "    homepage='https://www.crcv.ucf.edu/data-sets/ucf101/',\n",
       "    data_path='~\\\\tensorflow_datasets\\\\ucf101\\\\ucf101_1_256\\\\2.0.0',\n",
       "    file_format=tfrecord,\n",
       "    download_size=Unknown size,\n",
       "    dataset_size=Unknown size,\n",
       "    features=FeaturesDict({\n",
       "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=101),\n",
       "        'video': Video(Image(shape=(256, 256, 3), dtype=tf.uint8)),\n",
       "    }),\n",
       "    supervised_keys=None,\n",
       "    disable_shuffling=False,\n",
       "    splits={\n",
       "    },\n",
       "    citation=\"\"\"@article{DBLP:journals/corr/abs-1212-0402,\n",
       "      author    = {Khurram Soomro and\n",
       "                   Amir Roshan Zamir and\n",
       "                   Mubarak Shah},\n",
       "      title     = {{UCF101:} {A} Dataset of 101 Human Actions Classes From Videos in\n",
       "                   The Wild},\n",
       "      journal   = {CoRR},\n",
       "      volume    = {abs/1212.0402},\n",
       "      year      = {2012},\n",
       "      url       = {http://arxiv.org/abs/1212.0402},\n",
       "      archivePrefix = {arXiv},\n",
       "      eprint    = {1212.0402},\n",
       "      timestamp = {Mon, 13 Aug 2018 16:47:45 +0200},\n",
       "      biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1212-0402},\n",
       "      bibsource = {dblp computer science bibliography, https://dblp.org}\n",
       "    }\"\"\",\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = ucf101.info.features['label'].num_classes\n",
    "num_examples = {\n",
    "    name: split.num_examples\n",
    "    for name, split in ucf101.info.splits.items()\n",
    "}\n",
    "\n",
    "print('Number of classes:', num_classes)\n",
    "# print('Number of examples for train:', num_examples['train'])\n",
    "# print('Number of examples for test:', num_examples['test'])\n",
    "# print()\n",
    "\n",
    "ucf101.info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the training and evaluation datasets.\n",
    "batch_size = 8\n",
    "num_frames = 32\n",
    "resolution = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def format_features(features):\n",
    "  # print(\"features\", features)\n",
    "  video = features['video']\n",
    "  print(video.shape, \"start\", features)\n",
    "\n",
    "\n",
    "  total_frames = video.shape[1]\n",
    "  if total_frames == None:\n",
    "    total_frames = 32\n",
    "  frames = 32\n",
    "\n",
    "  start_idx = random.randint(0, total_frames - frames )\n",
    "  video = video[:,start_idx:start_idx+32]\n",
    "  print(video.shape)\n",
    "  video = tf.reshape(video, [-1, video.shape[2], video.shape[3], 3])\n",
    "  print(\"reshape\",video.shape)\n",
    "\n",
    "  \n",
    "  video = tf.image.resize(video, (224, 224))\n",
    "  video = tf.reshape(video, [-1, num_frames, resolution, resolution, 3])\n",
    "  video = tf.transpose(video, perm=(0,4,1,2,3))\n",
    "\n",
    "  print(video.shape)\n",
    "\n",
    "  # video = tf.image.random_crop(video, (-1,32,224,224,3))\n",
    "\n",
    "  if video.shape[0] is not None:\n",
    "    videos = tf.unstack(video)\n",
    "    for video, i in enumerate(videos):\n",
    "      isFlip = random.choice([\"flip\", \"don't flip\"])\n",
    "      if isFlip == \"flip\":\n",
    "          videos[i]= tf.image.flip_left_right(video)\n",
    "    video = tf.stack(videos)\n",
    "  video = tf.image.per_image_standardization(video)\n",
    "\n",
    "\n",
    "  label = tf.one_hot(features['label'], num_classes)\n",
    "  return (video, label)\n",
    "\n",
    "\n",
    "# format_features(features) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ucf101.as_dataset(\n",
    "    split='train',\n",
    "    batch_size=batch_size,\n",
    "    shuffle_files=True)\n",
    "train_dataset = train_dataset.map(\n",
    "    format_features,\n",
    "    num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_dataset = train_dataset.repeat()\n",
    "train_dataset = train_dataset.prefetch(2)\n",
    "\n",
    "test_dataset = ucf101.as_dataset(\n",
    "    split='test',\n",
    "    batch_size=batch_size)\n",
    "test_dataset = test_dataset.map(\n",
    "    format_features,\n",
    "    num_parallel_calls=tf.data.AUTOTUNE,\n",
    "    deterministic=True)\n",
    "test_dataset = test_dataset.prefetch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"GSOC-22-Video-Swin-Transformers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! python \"GSOC-22-Video-Swin-Transformers/convert.py\" -m \"swin_tiny_patch244_window877_kinetics400_1k\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = tf.keras.models.load_model(\"GSOC-22-Video-Swin-Transformers/swin_tiny_patch244_window877_kinetics400_1k_tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from VideoSwinTransformer import model_configs, SwinTransformer3D, I3DHead_tf\n",
    "\n",
    "cfg_method = model_configs.MODEL_MAP[\"swin_tiny_patch244_window877_kinetics400_1k\"]\n",
    "cfg = cfg_method()\n",
    "\n",
    "name = cfg[\"name\"]\n",
    "link = cfg['link']\n",
    "del cfg[\"name\"]\n",
    "del cfg['link']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(num_classes,cfg, shape_of_input=(10,3,32,224,224)):\n",
    "    inputs = tf.keras.Input(shape_of_input[1:])\n",
    "    # backbone = SwinTransformer3D(**cfg, shape_of_input=shape_of_input)\n",
    "    x = backbone(inputs, training= True)\n",
    "    outputs = I3DHead_tf(num_classes, 768, training=True)(x)\n",
    "    return tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 768 {'type': 'CrossEntropyLoss'} avg 0.5 0.01 {'training': True}\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3, 32, 224, 224)  0         \n",
      "                             ]                                   \n",
      "                                                                 \n",
      " swin_transformer3d (SwinTra  (None, 768, 16, 7, 7)    29694438  \n",
      " nsformer3D)                                                     \n",
      "                                                                 \n",
      " i3d_head_tf (I3DHead_tf)    (None, 101)               77669     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,772,107\n",
      "Trainable params: 27,928,139\n",
      "Non-trainable params: 1,843,968\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "shape_of_input = (batch_size, 3, 32, 224,224)\n",
    "model = get_model(num_classes, cfg, shape_of_input=shape_of_input)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tfa.optimizers.AdamW(weight_decay= 0.05,learning_rate=3e-4, beta_1= 0.9, beta_2=0.999, epsilon=1e-8)\n",
    "\n",
    "metrics=[\"top_k_categorical_accuracy\", \"categorical_accuracy\"] \n",
    "loss_obj = tf.keras.losses.CategoricalCrossentropy(\n",
    "    # from_logits=True,\n",
    "    label_smoothing=0.1)\n",
    "\n",
    "model.compile(loss=loss_obj, optimizer=optimizer, metrics=metrics)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10136\\1305300368.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m ]\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mtrain_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_examples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mtotal_train_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_steps\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mtest_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_examples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'train'"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.TensorBoard(),\n",
    "]\n",
    "\n",
    "train_steps = num_examples['train'] // batch_size\n",
    "total_train_steps = train_steps * num_epochs\n",
    "test_steps = num_examples['test'] // batch_size\n",
    "\n",
    "\n",
    "# loss_obj=tf.keras.losses.SparseCategoricalCrossentropy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=test_dataset,\n",
    "    epochs=num_epochs,\n",
    "    steps_per_epoch=train_steps,\n",
    "    validation_steps=test_steps,\n",
    "    callbacks=callbacks,\n",
    "    validation_freq=1,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_of_input = (8, 3, 32, 224,224)\n",
    "\n",
    "X = tf.random.normal(shape_of_input)\n",
    "y = tf.random.uniform((shape_of_input[0],1), 0, 5, tf.dtypes.int32)\n",
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 768 {'type': 'CrossEntropyLoss'} avg 0.5 0.01 {'training': True}\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 3, 32, 224, 224)  0         \n",
      "                             ]                                   \n",
      "                                                                 \n",
      " swin_transformer3d (SwinTra  (None, 768, 16, 7, 7)    29694438  \n",
      " nsformer3D)                                                     \n",
      "                                                                 \n",
      " i3d_head_tf_1 (I3DHead_tf)  (None, 5)                 3845      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,698,283\n",
      "Trainable params: 27,854,315\n",
      "Non-trainable params: 1,843,968\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model(5, cfg, shape_of_input=shape_of_input)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=loss_obj, optimizer=optimizer, metrics=metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Program Files\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Program Files\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Program Files\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Program Files\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Program Files\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 1053, in compute_loss\n        y, y_pred, sample_weight, regularization_losses=self.losses\n    File \"c:\\Program Files\\Python37\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Program Files\\Python37\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Program Files\\Python37\\lib\\site-packages\\keras\\losses.py\", line 272, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Program Files\\Python37\\lib\\site-packages\\keras\\losses.py\", line 1991, in categorical_crossentropy\n        y_true, y_pred, from_logits=from_logits, axis=axis\n    File \"c:\\Program Files\\Python37\\lib\\site-packages\\keras\\backend.py\", line 5529, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (2, 1) and (2, 5) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10136\\3292780599.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     verbose=1)\n\u001b[0m",
      "\u001b[1;32mc:\\Program Files\\Python37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Program Files\\Python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                     \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Program Files\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Program Files\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Program Files\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Program Files\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Program Files\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 1053, in compute_loss\n        y, y_pred, sample_weight, regularization_losses=self.losses\n    File \"c:\\Program Files\\Python37\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Program Files\\Python37\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Program Files\\Python37\\lib\\site-packages\\keras\\losses.py\", line 272, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Program Files\\Python37\\lib\\site-packages\\keras\\losses.py\", line 1991, in categorical_crossentropy\n        y_true, y_pred, from_logits=from_logits, axis=axis\n    File \"c:\\Program Files\\Python37\\lib\\site-packages\\keras\\backend.py\", line 5529, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (2, 1) and (2, 5) are incompatible\n"
     ]
    }
   ],
   "source": [
    "results = model.fit(\n",
    "    X,\n",
    "    y,\n",
    "    epochs=3,\n",
    "    steps_per_epoch=5,\n",
    "    validation_steps=2,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "5109d816b82be14675a6b11f8e0f0d2e80f029176ed3710d54e125caa8520dfd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
